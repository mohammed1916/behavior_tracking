2025-12-15 17:08:23,535 ERROR Error loading model test_model
Traceback (most recent call last):
  File "C:\Users\BBBS-AI-01\d\behavior_tracking\backend\tests\..\server.py", line 908, in load_vlm_model
    p = get_captioner_for_model(model, device_override=device)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: test_load_vlm_model_with_mock.<locals>.<lambda>() got an unexpected keyword argument 'device_override'
2025-12-17 10:32:11,058 ERROR Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)
handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\asyncio\events.py", line 88, in _run
    self._context.run(self._callback, *self._args)
  File "C:\ProgramData\anaconda3\Lib\asyncio\proactor_events.py", line 165, in _call_connection_lost
    self._sock.shutdown(socket.SHUT_RDWR)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host
2025-12-17 11:31:09,449 ERROR Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)
handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\asyncio\events.py", line 88, in _run
    self._context.run(self._callback, *self._args)
  File "C:\ProgramData\anaconda3\Lib\asyncio\proactor_events.py", line 165, in _call_connection_lost
    self._sock.shutdown(socket.SHUT_RDWR)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host
2025-12-17 11:57:27,468 ERROR Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)
handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\asyncio\events.py", line 88, in _run
    self._context.run(self._callback, *self._args)
  File "C:\ProgramData\anaconda3\Lib\asyncio\proactor_events.py", line 165, in _call_connection_lost
    self._sock.shutdown(socket.SHUT_RDWR)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host
2025-12-18 12:57:18,781 ERROR Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)
handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\asyncio\events.py", line 88, in _run
    self._context.run(self._callback, *self._args)
  File "C:\ProgramData\anaconda3\Lib\asyncio\proactor_events.py", line 165, in _call_connection_lost
    self._sock.shutdown(socket.SHUT_RDWR)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host
2025-12-18 12:57:54,142 ERROR Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)
handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\asyncio\events.py", line 88, in _run
    self._context.run(self._callback, *self._args)
  File "C:\ProgramData\anaconda3\Lib\asyncio\proactor_events.py", line 165, in _call_connection_lost
    self._sock.shutdown(socket.SHUT_RDWR)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host
2025-12-18 12:57:54,460 ERROR Exception in callback _ProactorBasePipeTransport._call_connection_lost(None)
handle: <Handle _ProactorBasePipeTransport._call_connection_lost(None)>
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\asyncio\events.py", line 88, in _run
    self._context.run(self._callback, *self._args)
  File "C:\ProgramData\anaconda3\Lib\asyncio\proactor_events.py", line 165, in _call_connection_lost
    self._sock.shutdown(socket.SHUT_RDWR)
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host
2025-12-18 14:26:28,818 ERROR Error loading model Qwen/Qwen2-VL-2B-Instruct
Traceback (most recent call last):
  File "C:\Users\BBBS-AI-01\d\behavior_tracking\backend\server.py", line 1281, in load_vlm_model
    p = get_captioner_for_model(model, device_override=device)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\BBBS-AI-01\d\behavior_tracking\backend\captioner.py", line 142, in get_captioner_for_model
    adapter = QwenVLMAdapter(
              ^^^^^^^^^^^^^^^
TypeError: QwenVLMAdapter.__init__() got an unexpected keyword argument 'mode'
2025-12-19 13:23:46,959 ERROR QwenVLMAdapter inference failed: Image features and image tokens do not match: tokens: 0, features 8
Traceback (most recent call last):
  File "C:\Users\BBBS-AI-01\d\behavior_tracking\backend\vlm_qwen.py", line 123, in __call__
    output_ids = self.model.generate(
                 ^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\utils\_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\generation\utils.py", line 2564, in generate
    result = decoding_method(
             ^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\generation\utils.py", line 2784, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\utils\generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\models\qwen2_vl\modeling_qwen2_vl.py", line 1356, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\models\qwen2_vl\modeling_qwen2_vl.py", line 1189, in forward
    image_mask, _ = self.get_placeholder_mask(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\models\qwen2_vl\modeling_qwen2_vl.py", line 1135, in get_placeholder_mask
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 13:23:47,214 ERROR QwenVLMAdapter inference failed: Image features and image tokens do not match: tokens: 0, features 8
Traceback (most recent call last):
  File "C:\Users\BBBS-AI-01\d\behavior_tracking\backend\vlm_qwen.py", line 123, in __call__
    output_ids = self.model.generate(
                 ^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\utils\_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\generation\utils.py", line 2564, in generate
    result = decoding_method(
             ^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\generation\utils.py", line 2784, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\utils\generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\models\qwen2_vl\modeling_qwen2_vl.py", line 1356, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\models\qwen2_vl\modeling_qwen2_vl.py", line 1189, in forward
    image_mask, _ = self.get_placeholder_mask(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\models\qwen2_vl\modeling_qwen2_vl.py", line 1135, in get_placeholder_mask
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 13:23:47,358 ERROR QwenVLMAdapter inference failed: Image features and image tokens do not match: tokens: 0, features 8
Traceback (most recent call last):
  File "C:\Users\BBBS-AI-01\d\behavior_tracking\backend\vlm_qwen.py", line 123, in __call__
    output_ids = self.model.generate(
                 ^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\utils\_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\generation\utils.py", line 2564, in generate
    result = decoding_method(
             ^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\generation\utils.py", line 2784, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\utils\generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\models\qwen2_vl\modeling_qwen2_vl.py", line 1356, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\models\qwen2_vl\modeling_qwen2_vl.py", line 1189, in forward
    image_mask, _ = self.get_placeholder_mask(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\transformers\models\qwen2_vl\modeling_qwen2_vl.py", line 1135, in get_placeholder_mask
    raise ValueError(
ValueError: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:28:01,601 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:28:01,828 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:28:02,017 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:28:08,524 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:28:08,676 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:28:14,177 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:28:14,356 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:28:25,120 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:28:25,290 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:28:38,328 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:28:38,469 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:29:11,720 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:29:11,915 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:29:27,305 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:29:27,514 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:29:43,497 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:29:43,693 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:30:19,573 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:30:19,743 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:30:28,300 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:30:28,441 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:30:44,297 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:30:44,418 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:30:58,700 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:30:58,848 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:31:03,457 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:31:03,614 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:31:13,478 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:31:13,646 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-19 15:31:18,507 WARNING Qwen fallback generation failed: Image features and image tokens do not match: tokens: 0, features 8
2025-12-23 10:49:06,714 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:49:30,049 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:49:30,049 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:49:30,050 WARNING Skipping duplicate segment: 3.8-5.2:work (already seen)
2025-12-23 10:49:53,802 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:50:16,633 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:50:39,167 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:50:59,470 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:50:59,471 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:51:13,955 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:51:13,955 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:51:34,686 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:51:52,399 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:52:14,361 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:52:33,960 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:52:56,742 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:53:16,219 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:53:42,040 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:53:42,040 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:53:42,040 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:53:49,725 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 10:53:49,726 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:12:53,599 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:13:03,141 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:13:12,250 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:13:24,393 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:13:33,024 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:13:41,824 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:13:51,599 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:14:01,420 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:14:09,145 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:14:18,086 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:14:29,825 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:14:38,245 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:14:47,830 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:14:58,572 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:14:58,572 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:15:05,893 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:31:03,024 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:31:14,361 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:31:23,353 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:31:36,439 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:31:56,499 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:31:56,499 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:31:56,499 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:31:56,499 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:32:07,382 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:32:07,382 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:32:15,374 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:32:24,050 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:32:32,235 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:32:41,125 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:32:49,769 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:33:04,723 WARNING Skipping duplicate segment: 49.27-51.43:work (already seen)
2025-12-23 11:33:04,724 WARNING Skipping duplicate segment: 49.27-51.43:work (already seen)
2025-12-23 11:33:24,124 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:33:33,254 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:33:38,851 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:38:34,104 WARNING Skipping invalid segment: 0.0-0.0 (start >= end)
2025-12-23 11:38:34,106 WARNING Skipping invalid segment: 2.13-2.13 (start >= end)
2025-12-23 11:38:34,106 WARNING Skipping invalid segment: 4.27-4.27 (start >= end)
2025-12-23 11:38:34,106 WARNING Skipping invalid segment: 0.0-0.0 (start >= end)
2025-12-23 11:38:34,107 WARNING Skipping invalid segment: 2.13-2.13 (start >= end)
2025-12-23 11:38:34,107 WARNING Skipping invalid segment: 4.27-4.27 (start >= end)
2025-12-23 11:38:42,179 WARNING Skipping invalid segment: 6.4-6.4 (start >= end)
2025-12-23 11:38:42,179 WARNING Skipping invalid segment: 8.57-8.57 (start >= end)
2025-12-23 11:38:47,276 WARNING Skipping invalid segment: 12.83-12.83 (start >= end)
2025-12-23 11:38:51,589 WARNING Skipping invalid segment: 15.0-15.0 (start >= end)
2025-12-23 11:38:51,590 WARNING Skipping invalid segment: 17.13-17.13 (start >= end)
2025-12-23 11:39:07,867 WARNING Skipping invalid segment: 25.7-25.7 (start >= end)
2025-12-23 11:39:07,868 WARNING Skipping invalid segment: 25.7-25.7 (start >= end)
2025-12-23 11:39:07,868 WARNING Skipping invalid segment: 25.7-25.7 (start >= end)
2025-12-23 11:39:29,957 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:39:35,863 WARNING Skipping invalid segment: 42.87-5.2 (start >= end)
2025-12-23 11:39:44,226 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:39:44,226 WARNING Skipping invalid segment: 3.1-3.1 (start >= end)
2025-12-23 11:39:55,818 WARNING Skipping invalid segment: 0.5-0.5 (start >= end)
2025-12-23 11:39:55,818 WARNING Skipping invalid segment: 49.27-49.27 (start >= end)
2025-12-23 11:39:55,818 WARNING Skipping invalid segment: 51.43-51.43 (start >= end)
2025-12-23 11:40:12,397 WARNING Skipping invalid segment: 60.0-60.0 (start >= end)
2025-12-23 11:40:28,883 WARNING Skipping invalid segment: 62.13-62.13 (start >= end)
2025-12-23 11:40:28,884 WARNING Skipping invalid segment: 62.13-62.13 (start >= end)
2025-12-24 13:15:49,600 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['0.00', '2.13', '4.27', '6.40']
2025-12-24 13:15:58,900 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['8.57', '10.70', '12.83', '15.00']
2025-12-24 13:16:02,807 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['17.13', '19.27', '21.43', '23.57']
2025-12-24 13:16:08,833 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['25.70', '27.83', '30.00', '32.13']
2025-12-24 13:18:10,921 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['34.27', '36.43', '38.57', '40.70']
2025-12-24 13:33:35,025 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['42.87', '45.00', '47.13', '49.27']
2025-12-24 13:42:52,055 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['0.00', '2.00', '4.00', '6.00']
2025-12-24 13:42:53,483 INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'someone is working on a laptop with a lo', 'arafed worker working on a machine in a ', 'arafed man standing in a factory with a ']
2025-12-24 13:42:53,483 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestamp and the activity.  First obse
2025-12-24 13:42:54,425 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['8.00', '10.00', '12.00', '14.00']
2025-12-24 13:42:57,640 INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'someone is holding a cat in a glove whil', 'arafed man standing in a factory with a ', 'arafed worker working on a machine in a ']
2025-12-24 13:42:57,641 INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. So, the user provided a timeline of observations and wants me to classify each activity as either 'work' or 'idle' and then group consecutive ones.   F
2025-12-24 13:42:59,478 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['16.00', '18.00', '20.00', '22.00']
2025-12-24 13:43:02,001 INFO [LLM_INPUT] captions: ['there is a truck that is parked in a gar', 'there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ']
2025-12-24 13:43:02,001 INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. So, the task is to classify each activity observation as either 'work' or 'idle' and then group consecutive ones. Let me start by looking at the timest
2025-12-24 13:43:04,383 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['24.00', '26.00', '28.00', '30.00']
2025-12-24 13:43:08,501 INFO [LLM_INPUT] captions: ['araffes in a factory with a dog and a ma', 'there are people standing in a bus with ', 'arafed man in a factory working on a mac', 'arafed man standing in a factory with a ']
2025-12-24 13:43:08,502 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation as either 'work' or 'idle' and then group consecutive ones. Let me start by looking at the timestamps provided.  First observa
2025-12-24 13:43:10,356 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['32.00', '34.00', '36.00', '38.00']
2025-12-24 13:43:12,440 INFO [LLM_INPUT] captions: ['arafed man in a factory with a laptop an', 'arafed man in a factory holding a large ', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ']
2025-12-24 13:43:12,441 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user wants me to classify each activity observation into 'work' or 'idle' and then group consecutive ones. Let me start by looking at the timestamp
2025-12-24 13:43:14,336 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['40.00', '42.00', '44.00', '46.00']
2025-12-24 13:43:16,538 INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work', 'arafed man in a factory looking at machi', 'arafed man standing in a factory with a ']
2025-12-24 13:43:16,538 INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. So, the task is to classify each activity observation as 'work' or 'idle' and then group consecutive ones. Let me start by looking at the timestamps and
2025-12-24 13:43:18,446 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['48.00', '50.00', '52.00', '54.00']
2025-12-24 13:43:22,567 INFO [LLM_INPUT] captions: ['arafed man in blue shirt standing in fro', 'arafed man in a factory with a mask on t', 'arafed man standing in a factory with a ', 'arafed worker in a factory with a lot of']
2025-12-24 13:43:22,568 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline of activity observations and wants me to classify each as either 'work' or 'idle' and group consecutive ones. Let me start
2025-12-24 13:43:24,380 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['56.00', '58.00', '60.00', '62.00']
2025-12-24 13:45:24,446 INFO [LLM_INPUT] captions: ['arafed worker in a factory with a mask o', 'there is a man that is standing in a sto', 'arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-24 13:45:24,447 INFO [LLM_OUTPUT] 
2025-12-24 13:45:54,471 INFO [LLM_INPUT] captions: ['arafed man in a factory with a machine i']
2025-12-24 13:45:54,472 INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user provided a timeline of observations and wants me to classify each activity as 'work' or 'idle' and group consecutive ones. First, I need to parse the given observ
2025-12-24 13:46:09,436 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['0.00', '2.00', '4.00', '6.00']
2025-12-24 13:46:11,515 INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'someone is working on a laptop with a lo', 'arafed worker working on a machine in a ', 'arafed man standing in a factory with a ']
2025-12-24 13:46:11,516 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into either 'work' or 'idle' and then group consecutive ones. Let's start by looking at each timestamp.  First observation is 
2025-12-24 13:46:13,603 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['8.00', '10.00', '12.00', '14.00']
2025-12-24 13:46:16,229 INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'someone is holding a cat in a glove whil', 'arafed man standing in a factory with a ', 'arafed worker working on a machine in a ']
2025-12-24 13:46:16,230 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline of observations and wants me to classify each activity as either 'work' or 'idle' and group consecutive ones. Let me start
2025-12-24 13:46:17,790 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['16.00', '18.00', '20.00', '22.00']
2025-12-24 13:46:21,132 INFO [LLM_INPUT] captions: ['there is a truck that is parked in a gar', 'there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ']
2025-12-24 13:46:21,132 INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. The user provided a timeline of observations and wants me to classify each activity as 'work' or 'idle' and group consecutive ones. Let me start by goin
2025-12-24 13:46:22,840 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['24.00', '26.00', '28.00', '30.00']
2025-12-24 13:46:25,948 INFO [LLM_INPUT] captions: ['araffes in a factory with a dog and a ma', 'there are people standing in a bus with ', 'arafed man in a factory working on a mac', 'arafed man standing in a factory with a ']
2025-12-24 13:46:25,949 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user has given me a timeline of observations and wants me to classify each activity as 'work' or 'idle' and then group consecutive ones. Alright, f
2025-12-24 13:46:27,692 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['32.00', '34.00', '36.00', '38.00']
2025-12-24 13:46:29,821 INFO [LLM_INPUT] captions: ['arafed man in a factory with a laptop an', 'arafed man in a factory holding a large ', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ']
2025-12-24 13:46:29,821 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to classify each activity observation as either 'work' or 'idle' and then group consecutive ones with the same classification. Then, output
2025-12-24 13:46:31,672 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['40.00', '42.00', '44.00', '46.00']
2025-12-24 13:46:33,133 INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work', 'arafed man in a factory looking at machi', 'arafed man standing in a factory with a ']
2025-12-24 13:46:33,133 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation as either 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestamp.  First observation is a
2025-12-24 13:46:35,120 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['48.00', '50.00', '52.00', '54.00']
2025-12-24 13:46:39,403 INFO [LLM_INPUT] captions: ['arafed man in blue shirt standing in fro', 'arafed man in a factory with a mask on t', 'arafed man standing in a factory with a ', 'arafed worker in a factory with a lot of']
2025-12-24 13:46:39,403 INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. So, the user provided a timeline of observations and wants me to classify each activity as either 'work' or 'idle' and then group consecutive ones. Let 
2025-12-24 13:46:41,274 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['56.00', '58.00', '60.00', '62.00']
2025-12-24 13:46:44,202 INFO [LLM_INPUT] captions: ['arafed worker in a factory with a mask o', 'there is a man that is standing in a sto', 'arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-24 13:46:44,203 INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. So, the user provided a timeline of observations and wants me to classify each activity as either 'work' or 'idle' and then group consecutive ones. Let 
2025-12-24 13:46:46,625 INFO [LLM_INPUT] captions: ['arafed man in a factory with a machine i']
2025-12-24 13:46:46,625 INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user provided a timeline of observations and wants me to classify each activity as work or idle and then group consecutive ones. Hmm.  First, I need to parse the times
2025-12-24 14:11:54,411 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['0.00', '2.13', '4.27', '6.40']
2025-12-24 14:12:00,275 INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-24 14:12:00,275 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each of these activity observations into either 'work' or 'idle' and then group consecutive ones. Let me start by reading through all the timestamps and
2025-12-24 14:12:01,314 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['8.57', '10.70', '12.83', '15.00']
2025-12-24 14:12:03,778 INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-24 14:12:03,779 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into 'work' or 'idle' and then group consecutive ones with the same classification. Alright, let's start by looking at each ti
2025-12-24 14:12:04,689 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['17.13', '19.27', '21.43', '23.57']
2025-12-24 14:12:07,206 INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-24 14:12:07,206 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user wants me to classify each activity observation as either 'work' or 'idle' and then group consecutive ones. Let me start by reading through the
2025-12-24 14:12:08,290 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['25.70', '27.83', '30.00', '32.13']
2025-12-24 14:12:10,073 INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-24 14:12:10,073 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline of observations and wants me to classify each activity as 'work' or 'idle' and then group consecutive ones. Let me start b
2025-12-24 14:12:11,071 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['34.27', '36.43', '38.57', '40.70']
2025-12-24 14:12:14,453 INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-24 14:12:14,454 INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. So, the task is to classify each observation as either 'work' or 'idle' and then group consecutive ones with the same classification. Let me start by lo
2025-12-24 14:12:15,389 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['42.87', '45.00', '47.13', '49.27']
2025-12-24 14:12:20,024 INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-24 14:12:20,025 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into 'work' or 'idle' and then group consecutive ones with the same classification. The timestamps are given as 0.50, 0.00, 0.
2025-12-24 14:12:21,482 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['51.43', '53.57', '55.70', '57.87']
2025-12-24 14:12:23,530 INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-24 14:12:23,532 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation as either 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestamp.  First observation is a
2025-12-24 14:12:25,612 INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-24 14:12:25,612 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation and then group consecutive ones with the same classification. Let me start by looking at the timestamps provided.  First obser
2025-12-24 14:33:11,197 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['0.00', '2.13', '4.27', '6.40']
2025-12-24 14:33:11,199 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[0.0, 2.1333333333333333, 4.266666666666667, 6.4]
2025-12-24 14:33:17,078 INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-24 14:33:17,079 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline of observations and wants me to classify each activity as either 'work' or 'idle' and group consecutive ones. Let me start
2025-12-24 14:33:18,961 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['8.57', '10.70', '12.83', '15.00']
2025-12-24 14:33:18,962 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[8.566666666666666, 10.7, 12.833333333333334, 15.0]
2025-12-24 14:33:21,127 INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-24 14:33:21,127 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestamp.  First observation: 0.50-2.3
2025-12-24 14:33:22,929 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['17.13', '19.27', '21.43', '23.57']
2025-12-24 14:33:22,930 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[17.133333333333333, 19.266666666666666, 21.433333333333334, 23.566666666666666]
2025-12-24 14:33:28,756 INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-24 14:33:28,756 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. First, I need to classify each activity observation as either 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestamp. 
2025-12-24 14:33:30,049 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['25.70', '27.83', '30.00', '32.13']
2025-12-24 14:33:30,049 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[25.7, 27.833333333333332, 30.0, 32.13333333333333]
2025-12-24 14:33:32,573 INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-24 14:33:32,573 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation as either 'work' or 'idle' and then group consecutive ones with the same classification. Let's start by looking at each timestamp.  Fir
2025-12-24 14:33:34,391 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['34.27', '36.43', '38.57', '40.70']
2025-12-24 14:33:34,391 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[34.266666666666666, 36.43333333333333, 38.56666666666667, 40.7]
2025-12-24 14:33:36,145 INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-24 14:33:36,145 INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. So, the user provided a timeline of observations and wants me to classify each activity as either 'work' or 'idle' and then group consecutive ones. Let 
2025-12-24 14:33:37,818 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['42.87', '45.00', '47.13', '49.27']
2025-12-24 14:33:37,819 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[42.86666666666667, 45.0, 47.13333333333333, 49.266666666666666]
2025-12-24 14:33:40,011 INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-24 14:33:40,012 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to classify each observation as either 'work' or 'idle' and then group consecutive same-class entries. Then output the segments in order.  
2025-12-24 14:33:42,205 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['51.43', '53.57', '55.70', '57.87']
2025-12-24 14:33:42,205 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[51.43333333333333, 53.56666666666667, 55.7, 57.86666666666667]
2025-12-24 14:33:43,745 INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-24 14:33:43,745 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either 'work' or 'idle' and then group consecutive ones with the same classification. Let's start by looking at each timestamp.  F
2025-12-24 14:33:44,817 INFO [VLM_WINDOW_CLOSED] n_samples=2 times=[60.0, 62.13333333333333]
2025-12-24 14:33:46,348 INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-24 14:33:46,349 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into 'work' or 'idle' and then group consecutive ones. The timestamps are given as 60.00 and 62.13. Let me start by looking at
2025-12-24 15:01:51,598 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['0.00', '2.13', '4.27', '6.40']
2025-12-24 15:01:51,599 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[0.0, 2.1333333333333333, 4.266666666666667, 6.4]
2025-12-24 15:01:54,223 INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-24 15:01:54,223 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline with several observations and wants me to classify each into 'work' or 'idle' and group consecutive entries with the same 
2025-12-24 15:01:54,224 INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 15:01:54,224 INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:01:54,224 INFO [PARSE_LLM] Created segment 4.27-6.40: idle with 1 captions
2025-12-24 15:01:54,224 INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 15:01:54,225 INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:01:54,225 INFO [PARSE_LLM] Created segment 4.27-6.40: idle with 1 captions
2025-12-24 15:01:55,299 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['8.57', '10.70', '12.83', '15.00']
2025-12-24 15:01:55,299 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[8.566666666666666, 10.7, 12.833333333333334, 15.0]
2025-12-24 15:01:56,896 INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-24 15:01:56,896 INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either 'work' or 'idle' and then group consecutive ones with the same classification. The timestamps are given as t=8.57, t=10.70,
2025-12-24 15:01:56,897 INFO [PARSE_LLM] Created segment 8.57-15.00: work with 3 captions
2025-12-24 15:01:57,870 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['17.13', '19.27', '21.43', '23.57']
2025-12-24 15:01:57,871 INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[17.133333333333333, 19.266666666666666, 21.433333333333334, 23.566666666666666]
2025-12-24 15:02:00,180 INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-24 15:02:00,180 INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline with several observations, and I need to classify each into 'work' or 'idle' and group consecutive entries with the same c
2025-12-24 15:02:00,180 WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-24 15:02:00,181 WARNING [PARSE_LLM] LLM output was: 
2025-12-24 15:17:18,834 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['0.00', '2.13', '4.27', '6.40']
2025-12-24 15:17:18,834 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[0.0, 2.1333333333333333, 4.266666666666667, 6.4]
2025-12-24 15:17:25,565 backend.server - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-24 15:17:25,567 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either 'work' or 'idle' and then group consecutive ones. Let's start by looking at each timestamp and the description.  First, the
2025-12-24 15:17:25,568 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-24 15:17:25,569 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-24 15:17:25,569 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:17:25,569 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: work with 1 captions
2025-12-24 15:17:25,569 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-24 15:17:25,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:17:25,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: work with 1 captions
2025-12-24 15:17:25,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-24 15:17:25,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:17:25,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: work with 1 captions
2025-12-24 15:17:25,571 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-24 15:17:25,571 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:17:25,571 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: work with 1 captions
2025-12-24 15:17:25,571 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: idle with 1 captions
2025-12-24 15:17:27,760 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['8.57', '10.70', '12.83', '15.00']
2025-12-24 15:17:27,761 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[8.566666666666666, 10.7, 12.833333333333334, 15.0]
2025-12-24 15:17:30,783 backend.server - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-24 15:17:30,783 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user wants me to classify each activity observation into either work or idle and then group consecutive ones. Let me start by reading through the t
2025-12-24 15:17:30,783 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 15:17:30,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 15:17:30,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: idle with 2 captions
2025-12-24 15:17:30,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 15:17:30,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 15:17:30,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: idle with 2 captions
2025-12-24 15:17:30,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 15:17:30,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 15:17:30,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: idle with 2 captions
2025-12-24 15:17:30,786 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 15:17:30,786 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 15:17:30,786 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: idle with 2 captions
2025-12-24 15:17:32,641 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['17.13', '19.27', '21.43', '23.57']
2025-12-24 15:17:32,641 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[17.133333333333333, 19.266666666666666, 21.433333333333334, 23.566666666666666]
2025-12-24 15:17:34,660 backend.server - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-24 15:17:34,661 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to classify each activity observation into either 'work' or 'idle' and then group consecutive ones with the same classification. Let me sta
2025-12-24 15:17:34,661 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:17:34,661 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:17:36,653 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['25.70', '27.83', '30.00', '32.13']
2025-12-24 15:17:36,653 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[25.7, 27.833333333333332, 30.0, 32.13333333333333]
2025-12-24 15:17:40,709 backend.server - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-24 15:17:40,709 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into either 'work' or 'idle' and then group consecutive ones. Let's start by looking at each timestamp and description.  First
2025-12-24 15:17:40,709 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.83: work with 1 captions
2025-12-24 15:17:40,710 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.83-30.00: work with 2 captions
2025-12-24 15:17:40,710 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 1 captions
2025-12-24 15:17:40,710 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,710 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,711 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,711 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.13 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,712 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.83: work with 1 captions
2025-12-24 15:17:40,712 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.83-30.00: work with 2 captions
2025-12-24 15:17:40,712 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 1 captions
2025-12-24 15:17:40,712 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,712 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,713 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,713 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.13 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,713 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,713 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,713 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,713 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.13 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,715 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,716 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,716 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:40,716 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.13 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:17:43,213 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['34.27', '36.43', '38.57', '40.70']
2025-12-24 15:17:43,213 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[34.266666666666666, 36.43333333333333, 38.56666666666667, 40.7]
2025-12-24 15:17:44,741 backend.server - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-24 15:17:44,741 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either 'work' or 'idle' and group consecutive ones. Let's start by looking at each timestamp and description.  First observation: 
2025-12-24 15:17:44,742 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.27-40.70: work with 3 captions
2025-12-24 15:17:46,747 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['42.87', '45.00', '47.13', '49.27']
2025-12-24 15:17:46,747 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[42.86666666666667, 45.0, 47.13333333333333, 49.266666666666666]
2025-12-24 15:17:49,178 backend.server - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-24 15:17:49,178 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestamp and description.  First observation is
2025-12-24 15:17:49,178 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.87-45.00: work with 1 captions
2025-12-24 15:17:49,178 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-47.13: work with 1 captions
2025-12-24 15:17:49,179 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.13-49.27: work with 2 captions
2025-12-24 15:17:49,179 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.87-45.00: work with 1 captions
2025-12-24 15:17:49,179 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-47.13: work with 1 captions
2025-12-24 15:17:49,180 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.13-49.27: work with 2 captions
2025-12-24 15:17:51,555 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['51.43', '53.57', '55.70', '57.87']
2025-12-24 15:17:51,556 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[51.43333333333333, 53.56666666666667, 55.7, 57.86666666666667]
2025-12-24 15:17:54,918 backend.server - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-24 15:17:54,918 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either 'work' or 'idle' and then group consecutive ones with the same classification. Let me start by looking at each timestamp an
2025-12-24 15:17:54,919 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 15:17:54,919 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 15:17:54,920 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.57-55.70: idle with 1 captions
2025-12-24 15:17:54,920 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.57-55.70: idle with 1 captions
2025-12-24 15:17:54,920 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.57-55.70: idle with 1 captions
2025-12-24 15:17:54,920 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.43-55.70: work with 3 captions
2025-12-24 15:17:54,920 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.57-55.70: idle with 1 captions
2025-12-24 15:17:56,346 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=2 times=[60.0, 62.13333333333333]
2025-12-24 15:17:57,849 backend.server - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-24 15:17:57,850 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either work or idle and then group consecutive ones. The timestamps are given as t=60.00 and t=62.13. The first observation is an 
2025-12-24 15:17:57,850 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.13: work with 1 captions
2025-12-24 15:59:14,391 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['0.00', '2.13', '4.27', '6.40']
2025-12-24 15:59:14,392 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[0.0, 2.1333333333333333, 4.266666666666667, 6.4]
2025-12-24 15:59:23,399 backend.server - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-24 15:59:23,400 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user provided a timeline of observations and wants me to classify each into 'work' or 'idle' and group consecutive ones. Let me start by reading each timestamp and des
2025-12-24 15:59:23,400 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 15:59:23,401 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:59:23,401 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 15:59:23,402 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:59:23,402 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 15:59:23,402 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:59:23,403 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 15:59:23,403 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:59:23,403 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 15:59:23,404 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:59:23,404 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 15:59:23,404 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:59:23,404 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 15:59:23,405 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:59:23,405 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 15:59:23,405 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:59:23,405 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 15:59:23,406 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 15:59:23,406 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: work with 1 captions
2025-12-24 15:59:24,358 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['8.57', '10.70', '12.83', '15.00']
2025-12-24 15:59:24,358 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[8.566666666666666, 10.7, 12.833333333333334, 15.0]
2025-12-24 15:59:26,973 backend.server - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-24 15:59:26,973 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestamp and description.  First observa
2025-12-24 15:59:26,974 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 15:59:26,974 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 15:59:26,974 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 2 captions
2025-12-24 15:59:26,975 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 15:59:26,975 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 15:59:26,975 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 2 captions
2025-12-24 15:59:26,975 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 15:59:26,975 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 15:59:26,975 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 2 captions
2025-12-24 15:59:27,855 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['17.13', '19.27', '21.43', '23.57']
2025-12-24 15:59:27,855 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[17.133333333333333, 19.266666666666666, 21.433333333333334, 23.566666666666666]
2025-12-24 15:59:34,123 backend.server - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-24 15:59:34,123 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline of observations and wants me to classify each into 'work' or 'idle' and then group consecutive ones. Let me start by readi
2025-12-24 15:59:34,124 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,124 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,124 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,125 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,125 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,125 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,125 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,126 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,126 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,126 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,126 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,127 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:34,127 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 15:59:35,482 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['25.70', '27.83', '30.00', '32.13']
2025-12-24 15:59:35,483 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[25.7, 27.833333333333332, 30.0, 32.13333333333333]
2025-12-24 15:59:39,319 backend.server - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-24 15:59:39,319 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to classify each activity observation into 'work' or 'idle' and then group consecutive ones with the same classification. Let me start by r
2025-12-24 15:59:39,319 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-24 15:59:40,288 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['34.27', '36.43', '38.57', '40.70']
2025-12-24 15:59:40,288 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[34.266666666666666, 36.43333333333333, 38.56666666666667, 40.7]
2025-12-24 15:59:42,404 backend.server - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-24 15:59:42,404 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem step by step. First, I need to read each timestamp and description, then classify each as either 'work' or 'idle'. Then group consecutive observations with 
2025-12-24 15:59:42,405 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.27-40.70: work with 3 captions
2025-12-24 15:59:42,405 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.27-40.70: work with 3 captions
2025-12-24 15:59:43,284 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['42.87', '45.00', '47.13', '49.27']
2025-12-24 15:59:43,284 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[42.86666666666667, 45.0, 47.13333333333333, 49.266666666666666]
2025-12-24 15:59:45,339 backend.server - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-24 15:59:45,340 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into either 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestamp and the description.  
2025-12-24 15:59:45,340 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-24 15:59:45,340 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-24 15:59:45,340 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 4.0 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-24 15:59:45,340 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.13-49.27: work with 2 captions
2025-12-24 15:59:46,270 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['51.43', '53.57', '55.70', '57.87']
2025-12-24 15:59:46,272 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[51.43333333333333, 53.56666666666667, 55.7, 57.86666666666667]
2025-12-24 15:59:49,112 backend.server - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-24 15:59:49,112 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to classify each observation into either 'work' or 'idle' and then group consecutive ones with the same classification. Then, output each s
2025-12-24 15:59:49,112 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 15:59:49,113 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 15:59:49,113 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 15:59:49,113 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 15:59:49,597 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=2 times=[60.0, 62.13333333333333]
2025-12-24 15:59:51,467 backend.server - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-24 15:59:51,467 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into either 'work' or 'idle' and then group consecutive ones with the same classification. The input has two timestamps: one w
2025-12-24 16:20:07,966 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['0.00', '2.00', '4.00', '6.00']
2025-12-24 16:20:07,967 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[0.0, 2.0, 4.0, 6.0]
2025-12-24 16:20:12,969 backend.server - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'someone is working on a laptop with a lo', 'arafed worker working on a machine in a ', 'arafed man standing in a factory with a ']
2025-12-24 16:20:12,971 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either 'work' or 'idle' and then group consecutive ones. The timeline has four timestamps: t=0.00, t=2.00, t=4.00, t=6.00. Let me 
2025-12-24 16:20:12,971 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.00: work with 2 captions
2025-12-24 16:20:12,972 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-4.00: work with 2 captions
2025-12-24 16:20:12,972 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-6.00: work with 2 captions
2025-12-24 16:20:12,972 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.00: work with 2 captions
2025-12-24 16:20:12,972 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-4.00: work with 2 captions
2025-12-24 16:20:12,972 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-6.00: work with 2 captions
2025-12-24 16:20:13,874 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['8.00', '10.00', '12.00', '14.00']
2025-12-24 16:20:13,874 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[8.0, 10.0, 12.0, 14.0]
2025-12-24 16:20:16,523 backend.server - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'someone is holding a cat in a glove whil', 'arafed man standing in a factory with a ', 'arafed worker working on a machine in a ']
2025-12-24 16:20:16,523 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user wants me to classify each observation into 'work' or 'idle' and then group consecutive ones. Let me start by reading through the timeline and 
2025-12-24 16:20:16,524 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-10.00: work with 2 captions
2025-12-24 16:20:16,524 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-12.00: idle with 2 captions
2025-12-24 16:20:16,524 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-14.00: work with 2 captions
2025-12-24 16:20:16,524 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-10.00: work with 2 captions
2025-12-24 16:20:16,524 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-12.00: idle with 2 captions
2025-12-24 16:20:16,524 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-14.00: work with 2 captions
2025-12-24 16:20:17,348 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['16.00', '18.00', '20.00', '22.00']
2025-12-24 16:20:17,348 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[16.0, 18.0, 20.0, 22.0]
2025-12-24 16:20:19,335 backend.server - INFO [LLM_INPUT] captions: ['there is a truck that is parked in a gar', 'there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ']
2025-12-24 16:20:19,336 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestamp and description.  First observa
2025-12-24 16:20:19,336 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-18.00: idle with 2 captions
2025-12-24 16:20:19,336 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-20.00: work with 2 captions
2025-12-24 16:20:19,336 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-22.00: work with 2 captions
2025-12-24 16:20:19,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-18.00: idle with 2 captions
2025-12-24 16:20:19,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-20.00: work with 2 captions
2025-12-24 16:20:19,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-22.00: work with 2 captions
2025-12-24 16:20:20,252 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['24.00', '26.00', '28.00', '30.00']
2025-12-24 16:20:20,252 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[24.0, 26.0, 28.0, 30.0]
2025-12-24 16:20:25,890 backend.server - INFO [LLM_INPUT] captions: ['araffes in a factory with a dog and a ma', 'there are people standing in a bus with ', 'arafed man in a factory working on a mac', 'arafed man standing in a factory with a ']
2025-12-24 16:20:25,890 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to classify each activity observation into either 'work' or 'idle' and then group consecutive ones. Let me start by reading through the timeline
2025-12-24 16:20:25,890 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [24.0, 26.0, 28.0, 30.0])
2025-12-24 16:20:25,891 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [24.0, 26.0, 28.0, 30.0])
2025-12-24 16:20:25,891 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-24 16:20:25,891 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.00-28.00: idle with 2 captions
2025-12-24 16:20:25,891 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-24 16:20:25,891 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-24 16:20:25,891 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.00-28.00: idle with 2 captions
2025-12-24 16:20:25,891 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-24 16:20:25,891 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-24 16:20:25,891 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.00-28.00: idle with 2 captions
2025-12-24 16:20:25,892 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-24 16:20:25,892 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-24 16:20:25,892 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.00-28.00: idle with 2 captions
2025-12-24 16:20:25,892 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-24 16:20:26,808 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['32.00', '34.00', '36.00', '38.00']
2025-12-24 16:20:26,809 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[32.0, 34.0, 36.0, 38.0]
2025-12-24 16:20:29,164 backend.server - INFO [LLM_INPUT] captions: ['arafed man in a factory with a laptop an', 'arafed man in a factory holding a large ', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ']
2025-12-24 16:20:29,164 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user has provided a timeline with several observations, and I need to classify each into either 'work' or 'idle' and group consecutive ones. Let me
2025-12-24 16:20:29,165 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.00-34.00: work with 2 captions
2025-12-24 16:20:29,165 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.00-36.00: work with 2 captions
2025-12-24 16:20:29,165 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.00-38.00: work with 2 captions
2025-12-24 16:20:30,161 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['40.00', '42.00', '44.00', '46.00']
2025-12-24 16:20:30,162 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[40.0, 42.0, 44.0, 46.0]
2025-12-24 16:20:31,932 backend.server - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work', 'arafed man in a factory looking at machi', 'arafed man standing in a factory with a ']
2025-12-24 16:20:31,933 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into either 'work' or 'idle' and then group consecutive ones with the same classification. The timestamps are given as t=40.00
2025-12-24 16:20:31,933 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-46.00: work with 4 captions
2025-12-24 16:20:32,862 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['48.00', '50.00', '52.00', '54.00']
2025-12-24 16:20:32,863 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[48.0, 50.0, 52.0, 54.0]
2025-12-24 16:20:34,953 backend.server - INFO [LLM_INPUT] captions: ['arafed man in blue shirt standing in fro', 'arafed man in a factory with a mask on t', 'arafed man standing in a factory with a ', 'arafed worker in a factory with a lot of']
2025-12-24 16:20:34,953 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either 'work' or 'idle' and then group consecutive ones with the same classification. The user provided a timeline with timestamps
2025-12-24 16:20:34,953 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-54.00: work with 4 captions
2025-12-24 16:20:35,857 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['56.00', '58.00', '60.00', '62.00']
2025-12-24 16:20:35,858 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[56.0, 58.0, 60.0, 62.0]
2025-12-24 16:20:39,402 backend.server - INFO [LLM_INPUT] captions: ['arafed worker in a factory with a mask o', 'there is a man that is standing in a sto', 'arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-24 16:20:39,403 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestamp and description.  First, the fi
2025-12-24 16:20:39,403 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-58.00: work with 2 captions
2025-12-24 16:20:39,403 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-58.00: work with 2 captions
2025-12-24 16:20:39,403 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.00: work with 2 captions
2025-12-24 16:20:39,404 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-58.00: work with 2 captions
2025-12-24 16:20:39,404 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.00: work with 2 captions
2025-12-24 16:20:39,404 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-58.00: work with 2 captions
2025-12-24 16:20:39,404 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.00: work with 2 captions
2025-12-24 16:20:39,627 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=1 times=[64.0]
2025-12-24 16:20:41,322 backend.server - INFO [LLM_INPUT] captions: ['arafed man in a factory with a machine i']
2025-12-24 16:20:41,322 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline with some observations and wants me to classify them into work or idle and group consecutive ones. Let me start by reading
2025-12-24 16:24:02,130 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['0.00', '2.13', '4.27', '6.40']
2025-12-24 16:24:02,141 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[0.0, 2.1333333333333333, 4.266666666666667, 6.4]
2025-12-24 16:24:05,275 backend.server - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-24 16:24:05,276 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem step by step. The user provided a timeline with several observations and wants me to classify them into 'work' or 'idle' and group consecutive ones. Let me 
2025-12-24 16:24:05,277 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-4.27: work with 3 captions
2025-12-24 16:24:05,277 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-4.27: work with 3 captions
2025-12-24 16:24:05,278 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-4.27: work with 3 captions
2025-12-24 16:24:07,183 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['8.57', '10.70', '12.83', '15.00']
2025-12-24 16:24:07,183 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[8.566666666666666, 10.7, 12.833333333333334, 15.0]
2025-12-24 16:24:10,248 backend.server - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-24 16:24:10,248 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either work or idle and then group consecutive ones with the same classification. The input has four timestamps and descriptions. 
2025-12-24 16:24:10,250 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 16:24:10,251 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 16:24:10,252 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 2 captions
2025-12-24 16:24:10,252 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 16:24:10,253 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 16:24:10,254 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 2 captions
2025-12-24 16:24:10,255 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 16:24:10,256 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 16:24:10,257 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 2 captions
2025-12-24 16:24:10,258 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 1 captions
2025-12-24 16:24:12,333 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['17.13', '19.27', '21.43', '23.57']
2025-12-24 16:24:12,334 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[17.133333333333333, 19.266666666666666, 21.433333333333334, 23.566666666666666]
2025-12-24 16:24:16,576 backend.server - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-24 16:24:16,576 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestamp and description.  First, the timeline 
2025-12-24 16:24:16,576 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.13-19.27: idle with 2 captions
2025-12-24 16:24:16,577 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.13-19.27: idle with 2 captions
2025-12-24 16:24:16,577 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 16:24:16,577 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.13-19.27: idle with 2 captions
2025-12-24 16:24:16,577 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 16:24:16,578 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-24 16:24:18,310 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['25.70', '27.83', '30.00', '32.13']
2025-12-24 16:24:18,310 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[25.7, 27.833333333333332, 30.0, 32.13333333333333]
2025-12-24 16:24:22,312 backend.server - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-24 16:24:22,312 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline of observations and wants me to classify each into 'work' or 'idle' and group consecutive ones. Let me start by reading th
2025-12-24 16:24:22,312 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.83: work with 1 captions
2025-12-24 16:24:22,313 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.83-30.00: work with 2 captions
2025-12-24 16:24:22,313 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 1 captions
2025-12-24 16:24:22,313 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.83: work with 1 captions
2025-12-24 16:24:22,314 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.83-30.00: work with 2 captions
2025-12-24 16:24:22,314 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 1 captions
2025-12-24 16:24:22,314 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.83: work with 1 captions
2025-12-24 16:24:22,315 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.83-30.00: work with 2 captions
2025-12-24 16:24:22,315 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 1 captions
2025-12-24 16:24:24,407 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['34.27', '36.43', '38.57', '40.70']
2025-12-24 16:24:24,407 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[34.266666666666666, 36.43333333333333, 38.56666666666667, 40.7]
2025-12-24 16:24:26,540 backend.server - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-24 16:24:26,540 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either 'work' or 'idle' and then group consecutive ones. The timestamps are given as t=... and each description is about a person 
2025-12-24 16:24:26,540 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.27-38.57: work with 2 captions
2025-12-24 16:24:26,540 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.57-40.70: work with 1 captions
2025-12-24 16:24:28,473 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['42.87', '45.00', '47.13', '49.27']
2025-12-24 16:24:28,473 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[42.86666666666667, 45.0, 47.13333333333333, 49.266666666666666]
2025-12-24 16:24:30,660 backend.server - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-24 16:24:30,660 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each of these activity observations into either 'work' or 'idle' and then group consecutive ones with the same classification. Let me start by looking a
2025-12-24 16:24:30,661 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.87-45.00: work with 1 captions
2025-12-24 16:24:30,662 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-47.13: work with 1 captions
2025-12-24 16:24:30,662 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.13-49.27: work with 2 captions
2025-12-24 16:24:30,663 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.87-45.00: work with 1 captions
2025-12-24 16:24:30,664 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-47.13: work with 1 captions
2025-12-24 16:24:30,664 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.13-49.27: work with 2 captions
2025-12-24 16:24:32,421 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['51.43', '53.57', '55.70', '57.87']
2025-12-24 16:24:32,423 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[51.43333333333333, 53.56666666666667, 55.7, 57.86666666666667]
2025-12-24 16:24:37,087 backend.server - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-24 16:24:37,088 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to classify each activity observation into either 'work' or 'idle' and then group consecutive ones. Let me start by reading through the timeline
2025-12-24 16:24:37,088 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 16:24:37,089 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 16:24:37,089 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 16:24:37,090 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 16:24:37,090 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 16:24:37,091 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 16:24:37,091 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 16:24:37,092 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-24 16:24:38,065 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=2 times=[60.0, 62.13333333333333]
2025-12-24 16:24:40,296 backend.server - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-24 16:24:40,297 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into either 'work' or 'idle' and then group consecutive ones with the same classification. The input has two timestamps: one i
2025-12-24 16:32:38,974 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['0.00', '2.13', '4.27', '6.40']
2025-12-24 16:32:38,974 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[0.0, 2.1333333333333333, 4.266666666666667, 6.4]
2025-12-24 16:32:44,117 backend.server - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-24 16:32:44,117 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline with several observations, and I need to classify each into 'work' or 'idle' and group consecutive ones. Let me start by r
2025-12-24 16:32:44,118 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 16:32:44,118 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 16:32:44,118 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: idle with 1 captions
2025-12-24 16:32:44,118 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 16:32:44,118 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 16:32:44,119 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: idle with 1 captions
2025-12-24 16:32:44,119 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 16:32:44,119 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 16:32:44,119 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: idle with 1 captions
2025-12-24 16:32:44,119 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-24 16:32:44,119 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-24 16:32:44,119 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: idle with 1 captions
2025-12-24 16:32:45,064 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['8.57', '10.70', '12.83', '15.00']
2025-12-24 16:32:45,064 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[8.566666666666666, 10.7, 12.833333333333334, 15.0]
2025-12-24 16:32:47,914 backend.server - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-24 16:32:47,914 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into either work or idle and then group consecutive ones. Let me start by looking at each timestamp and description.  First observation
2025-12-24 16:32:47,915 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 16:32:47,915 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 16:32:47,915 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 2 captions
2025-12-24 16:32:47,916 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 16:32:47,916 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 16:32:47,916 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 2 captions
2025-12-24 16:32:47,917 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 1 captions
2025-12-24 16:32:47,917 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 1 captions
2025-12-24 16:32:47,917 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 2 captions
2025-12-24 16:32:49,624 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['17.13', '19.27', '21.43', '23.57']
2025-12-24 16:32:49,624 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[17.133333333333333, 19.266666666666666, 21.433333333333334, 23.566666666666666]
2025-12-24 16:32:51,686 backend.server - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-24 16:32:51,686 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. The user wants me to classify each activity observation into 'work' or 'idle' and then group consecutive ones. Let me start by looking at each timestam
2025-12-24 16:32:51,687 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-24 16:32:51,687 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-24 16:32:52,674 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['25.70', '27.83', '30.00', '32.13']
2025-12-24 16:32:52,675 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[25.7, 27.833333333333332, 30.0, 32.13333333333333]
2025-12-24 16:32:55,138 backend.server - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-24 16:32:55,138 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each activity observation into either 'work' or 'idle' and group consecutive ones. Let me start by reading each timestamp and description carefully.  Fi
2025-12-24 16:32:55,139 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-32.13: work with 3 captions
2025-12-24 16:32:56,071 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['34.27', '36.43', '38.57', '40.70']
2025-12-24 16:32:56,072 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[34.266666666666666, 36.43333333333333, 38.56666666666667, 40.7]
2025-12-24 16:33:02,029 backend.server - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-24 16:33:02,029 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user wants me to classify and group the activity observations into segments based on their timestamps and classification rules. Let me start by rea
2025-12-24 16:33:02,029 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.27-40.70: work with 3 captions
2025-12-24 16:33:02,029 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.27-40.70: work with 3 captions
2025-12-24 16:33:02,923 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['42.87', '45.00', '47.13', '49.27']
2025-12-24 16:33:02,923 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[42.86666666666667, 45.0, 47.13333333333333, 49.266666666666666]
2025-12-24 16:33:05,143 backend.server - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-24 16:33:05,143 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into 'work' or 'idle' and then group consecutive ones. Let's start by looking at each timestamp and description.  First observation: t=
2025-12-24 16:33:05,143 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.87-47.13: work with 1 captions
2025-12-24 16:33:05,144 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.13-49.27: work with 2 captions
2025-12-24 16:33:05,144 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.87-47.13: work with 1 captions
2025-12-24 16:33:05,144 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.13-49.27: work with 2 captions
2025-12-24 16:33:05,144 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.87-47.13: work with 1 captions
2025-12-24 16:33:05,144 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.13-49.27: work with 2 captions
2025-12-24 16:33:06,026 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=['51.43', '53.57', '55.70', '57.87']
2025-12-24 16:33:06,026 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=4 times=[51.43333333333333, 53.56666666666667, 55.7, 57.86666666666667]
2025-12-24 16:33:08,675 backend.server - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-24 16:33:08,676 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this. First, I need to classify each observation into either 'work' or 'idle'. Then group consecutive ones with the same classification and output each segment.  So the 
2025-12-24 16:33:08,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.43-53.57: work with 2 captions
2025-12-24 16:33:08,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.87: work with 2 captions
2025-12-24 16:33:08,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.43-53.57: work with 2 captions
2025-12-24 16:33:08,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.87: work with 2 captions
2025-12-24 16:33:08,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.43-53.57: work with 2 captions
2025-12-24 16:33:08,678 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.87: work with 2 captions
2025-12-24 16:33:08,678 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.43-53.57: work with 2 captions
2025-12-24 16:33:08,678 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.87: work with 2 captions
2025-12-24 16:33:08,678 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.43-53.57: work with 2 captions
2025-12-24 16:33:08,679 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.87: work with 2 captions
2025-12-24 16:33:10,014 backend.server - INFO [VLM_WINDOW_CLOSED] n_samples=2 times=[60.0, 62.13333333333333]
2025-12-24 16:33:12,227 backend.server - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-24 16:33:12,227 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to classify each observation into 'work' or 'idle' and then group consecutive ones. Let me start by looking at the timeline provided.  First, the timestamps are giv
2025-12-24 16:33:12,228 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.13: work with 1 captions
2025-12-26 10:57:45,925 root - INFO [VLM_WINDOW_CLOSED] t=6.40s n_samples=4 times=['0.00', '2.13', '4.27', '6.40']
2025-12-26 10:57:47,908 root - INFO [VLM_WINDOW_CLOSED] t=15.00s n_samples=4 times=['8.57', '10.70', '12.83', '15.00']
2025-12-26 10:57:49,671 root - INFO [VLM_WINDOW_CLOSED] t=23.57s n_samples=4 times=['17.13', '19.27', '21.43', '23.57']
2025-12-26 10:57:51,702 root - INFO [VLM_WINDOW_CLOSED] t=32.13s n_samples=4 times=['25.70', '27.83', '30.00', '32.13']
2025-12-26 10:57:53,672 root - INFO [VLM_WINDOW_CLOSED] t=40.70s n_samples=4 times=['34.27', '36.43', '38.57', '40.70']
2025-12-26 10:57:55,403 root - INFO [VLM_WINDOW_CLOSED] t=49.27s n_samples=4 times=['42.87', '45.00', '47.13', '49.27']
2025-12-26 10:57:57,165 root - INFO [VLM_WINDOW_CLOSED] t=57.87s n_samples=4 times=['51.43', '53.57', '55.70', '57.87']
2025-12-26 11:01:40,065 root - INFO [VLM_WINDOW_CLOSED] t=6.40s n_samples=4 times=['0.00', '2.13', '4.27', '6.40']
2025-12-26 11:01:46,756 backend.server - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-26 11:01:46,756 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. First, I need to look at the timeline of activity descriptions and identify continuous segments. The user provided timestamps and different labels. Let me 
2025-12-26 11:01:46,757 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-26 11:01:46,757 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-26 11:01:46,757 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-26 11:01:46,757 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-26 11:01:46,758 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-26 11:01:46,758 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: idle with 2 captions
2025-12-26 11:01:46,758 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: work with 1 captions
2025-12-26 11:01:46,758 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-26 11:01:46,759 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: idle with 2 captions
2025-12-26 11:01:46,759 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: work with 1 captions
2025-12-26 11:01:48,593 root - INFO [VLM_WINDOW_CLOSED] t=15.00s n_samples=4 times=['8.57', '10.70', '12.83', '15.00']
2025-12-26 11:01:51,062 backend.server - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-26 11:01:51,063 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to identify continuous activity segments based on the timeline provided. Let me start by looking at the timestamps given.  First, there's a man in front 
2025-12-26 11:01:51,063 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [8.57, 10.7, 12.83, 15.0])
2025-12-26 11:01:51,064 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [8.57, 10.7, 12.83, 15.0])
2025-12-26 11:01:51,064 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [8.57, 10.7, 12.83, 15.0])
2025-12-26 11:01:52,941 root - INFO [VLM_WINDOW_CLOSED] t=23.57s n_samples=4 times=['17.13', '19.27', '21.43', '23.57']
2025-12-26 11:01:54,682 backend.server - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-26 11:01:54,683 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze the timeline of activity descriptions and identify continuous segments. The user provided timestamps and labels, so first, I should look at each time poi
2025-12-26 11:01:54,683 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-26 11:01:54,683 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-26 11:01:54,684 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-26 11:01:56,420 root - INFO [VLM_WINDOW_CLOSED] t=32.13s n_samples=4 times=['25.70', '27.83', '30.00', '32.13']
2025-12-26 11:02:01,162 backend.server - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-26 11:02:01,162 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to identify continuous activity segments from the timeline based on temporal patterns. Let me start by looking at each timestamp provided.  First, the ti
2025-12-26 11:02:01,162 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 1 captions
2025-12-26 11:02:01,162 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-26 11:02:01,163 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-26 11:02:01,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 1 captions
2025-12-26 11:02:01,163 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-26 11:02:01,163 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-26 11:02:03,014 root - INFO [VLM_WINDOW_CLOSED] t=40.70s n_samples=4 times=['34.27', '36.43', '38.57', '40.70']
2025-12-26 11:02:06,222 backend.server - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-26 11:02:06,223 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. The user provided a timeline of activity descriptions and wants me to identify continuous segments based on temporal patterns. Let me start by breaking
2025-12-26 11:02:06,223 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-26 11:02:06,223 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.57-40.70: work with 1 captions
2025-12-26 11:02:07,914 root - INFO [VLM_WINDOW_CLOSED] t=49.27s n_samples=4 times=['42.87', '45.00', '47.13', '49.27']
2025-12-26 11:02:10,541 backend.server - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-26 11:02:10,542 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze the given timeline of activity descriptions and identify continuous segments based on temporal patterns. The user wants me to output one segment per line
2025-12-26 11:02:10,542 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-26 11:02:10,542 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-26 11:02:10,543 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-26 11:02:10,543 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 4.92 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-26 11:02:12,261 root - INFO [VLM_WINDOW_CLOSED] t=57.87s n_samples=4 times=['51.43', '53.57', '55.70', '57.87']
2025-12-26 11:02:15,213 backend.server - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-26 11:02:15,213 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze the timeline and identify continuous activity segments. Let me start by looking at each part of the timeline.  First, there's an arafed man in a factory 
2025-12-26 11:02:15,214 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-26 11:02:15,214 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-26 11:02:15,214 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-26 11:02:15,215 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-26 11:02:15,215 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-26 11:02:20,771 backend.server - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-26 11:02:20,772 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to analyze a timeline of activity observations and identify continuous segments. The labels are work and idle. The example given has two entries: one wit
2025-12-26 11:02:20,772 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [60.0, 62.13])
2025-12-26 11:02:20,772 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [60.0, 62.13])
2025-12-26 11:02:20,772 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [60.0, 62.13])
2025-12-26 11:40:18,658 root - INFO [VLM_WINDOW_CLOSED] t=6.11s n_samples=22 times=['0.00', '0.27', '0.56', '0.86', '1.16', '1.43', '1.73', '2.03', '2.33', '2.59', '2.89', '3.19', '3.49', '3.76', '4.05', '4.35', '4.65', '4.95', '5.22', '5.52', '5.82', '6.11']
2025-12-26 11:41:02,362 backend.server - INFO [LLM_INPUT] captions: ['The main person is assembling a mechanic', 'The main person is assembling a mechanic', 'The main person in the image is engaged ', 'The main person is holding a wooden mech', 'The main person is assembling a wooden m', 'The main person is holding a wooden toy ', 'The main person is holding a mechanical ', 'The main person is holding a small elect', 'The main person is holding a small elect', 'The main person is holding a small piece', 'The main person is holding a small white', 'The main person is using a tool to work ', 'The main person is engaged in assembling', 'The main person in the image is engaged ', 'The main person is holding a small devic', 'The main person is holding a small mecha', 'The main person is holding a small devic', 'The main person in the image is holding ', 'The main person is holding a small white', 'The main person is holding a small white', 'The main person is assembling a wooden t', 'The main person is assembling a wooden t']
2025-12-26 11:41:02,363 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to identify continuous activity segments based on the timeline provided. The user wants me to group consecutive similar activities into segments. The labels are ass
2025-12-26 11:41:02,381 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid end time: 2.3 (not in [0.0, 0.27, 0.56, 0.86, 1.16, 1.43, 1.73, 2.03, 2.33, 2.59, 2.89, 3.19, 3.49, 3.76, 4.05, 4.35, 4.65, 4.95, 5.22, 5.52, 5.82, 6.11])
2025-12-26 11:41:02,382 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [0.0, 0.27, 0.56, 0.86, 1.16, 1.43, 1.73, 2.03, 2.33, 2.59, 2.89, 3.19, 3.49, 3.76, 4.05, 4.35, 4.65, 4.95, 5.22, 5.52, 5.82, 6.11])
2025-12-26 11:41:02,382 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [0.0, 0.27, 0.56, 0.86, 1.16, 1.43, 1.73, 2.03, 2.33, 2.59, 2.89, 3.19, 3.49, 3.76, 4.05, 4.35, 4.65, 4.95, 5.22, 5.52, 5.82, 6.11])
2025-12-26 11:41:02,383 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 5.2 (not in [0.0, 0.27, 0.56, 0.86, 1.16, 1.43, 1.73, 2.03, 2.33, 2.59, 2.89, 3.19, 3.49, 3.76, 4.05, 4.35, 4.65, 4.95, 5.22, 5.52, 5.82, 6.11])
2025-12-26 11:42:28,420 backend.server - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden d', 'The main person is assembling a small dr', 'The main person is assembling a wooden d', 'The main person is assembling a small dr', 'The main person is holding a small drone', 'The main person in the image is holding ', 'The main person is holding a small drone', 'The main person is holding a small drone']
2025-12-26 11:42:28,421 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to identify continuous activity segments based on the timeline of observations. The labels are assembling_drone, using_phone, idle, or unknown.   First, 
2025-12-26 11:42:28,421 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [6.38, 6.68, 6.98, 7.28, 7.54, 7.84, 8.14, 8.44])
2025-12-26 12:06:45,772 backend.server - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-26 12:06:45,775 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to identify continuous activity segments from the given timeline. The user provided timestamps and labels, and I have to group consecutive similar activities. Let m
2025-12-26 12:06:45,780 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-26 12:06:45,781 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-26 12:06:45,782 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: idle with 1 captions
2025-12-26 12:06:45,783 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.13: work with 1 captions
2025-12-26 12:06:45,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.13-4.27: work with 2 captions
2025-12-26 12:06:45,787 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.27-6.40: idle with 1 captions
2025-12-26 12:06:53,902 backend.server - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-26 12:06:53,903 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze these timeline observations and identify continuous activity segments. The user provided several timestamps and wants me to group them into work or idle 
2025-12-26 12:06:53,904 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [8.57, 10.7, 12.83, 15.0])
2025-12-26 12:06:53,905 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: idle with 1 captions
2025-12-26 12:06:53,912 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 2 captions
2025-12-26 12:06:53,912 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [8.57, 10.7, 12.83, 15.0])
2025-12-26 12:06:53,912 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: idle with 1 captions
2025-12-26 12:06:53,917 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 2 captions
2025-12-26 12:07:00,695 backend.server - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-26 12:07:00,696 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. The user wants me to identify continuous activity segments based on the timeline provided. Let me start by looking at the timestamps.  First, there's a
2025-12-26 12:07:00,696 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-26 12:07:00,696 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 0.50-17:13: work (computer monitor)
0.50-17:13: work
0.50-17:13: work
2025-12-26 12:07:06,858 backend.server - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-26 12:07:06,859 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to analyze a timeline of activity descriptions and identify continuous segments. The timeline has several entries. Let me start by breaking down each tim
2025-12-26 12:07:06,860 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-26 12:07:06,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 1 captions
2025-12-26 12:07:06,861 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-26 12:07:06,862 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 1 captions
2025-12-26 12:07:16,868 backend.server - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-26 12:07:16,868 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to analyze a timeline of activity observations and identify continuous segments. The labels are work and idle. First, I need to look at the timestamps pr
2025-12-26 12:07:16,869 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-26 12:07:16,869 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-26 12:07:22,641 backend.server - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-26 12:07:22,641 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze the timeline of activity descriptions and identify continuous segments. The user provided timestamps and labels, and I need to group them into work or id
2025-12-26 12:07:22,642 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-26 12:07:22,642 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-26 12:07:22,643 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-26 12:07:22,644 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-26 12:07:22,644 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-26 12:07:22,644 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-26 12:07:28,357 backend.server - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-26 12:07:28,358 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline of activity descriptions and wants me to identify continuous segments based on temporal patterns. The task is to group con
2025-12-26 12:07:28,358 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-26 12:07:28,359 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-26 12:07:28,360 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 5.2 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-26 12:07:39,571 backend.server - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-26 12:07:39,572 backend.server - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. The user provided a timeline of activity observations and wants me to identify continuous segments based on temporal patterns. The labels are work and 
2025-12-26 12:07:39,575 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [60.0, 62.13])
2025-12-26 12:07:39,575 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [60.0, 62.13])
2025-12-26 12:07:39,576 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [60.0, 62.13])
2025-12-29 09:08:27,330 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-29 09:08:27,331 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze this timeline of activity descriptions and identify continuous segments. The user provided several timestamps and labels. Let me start by breaking down e
2025-12-29 09:08:27,332 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [0.0, 2.13, 4.27, 6.4])
2025-12-29 09:08:27,333 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [0.0, 2.13, 4.27, 6.4])
2025-12-29 09:08:27,333 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [0.0, 2.13, 4.27, 6.4])
2025-12-29 09:08:27,333 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [0.0, 2.13, 4.27, 6.4])
2025-12-29 09:08:27,333 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [0.0, 2.13, 4.27, 6.4])
2025-12-29 09:08:27,334 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [0.0, 2.13, 4.27, 6.4])
2025-12-29 09:08:30,857 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-29 09:08:30,857 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user wants me to analyze a timeline of activity descriptions and identify continuous segments. The example given shows that when activities change,
2025-12-29 09:08:30,857 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [8.57, 10.7, 12.83, 15.0])
2025-12-29 09:08:30,857 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [8.57, 10.7, 12.83, 15.0])
2025-12-29 09:08:30,857 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [8.57, 10.7, 12.83, 15.0])
2025-12-29 09:08:30,858 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 5.2 (not in [8.57, 10.7, 12.83, 15.0])
2025-12-29 09:08:37,162 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-29 09:08:37,162 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze the timeline and identify continuous activity segments. The user provided timestamps and labels, so first, I should look at each time point and see when 
2025-12-29 09:08:37,162 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,162 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,163 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,163 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,163 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,163 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,164 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,164 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,164 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,164 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,164 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,165 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,165 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,165 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,165 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,165 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,166 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:37,166 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [17.13, 19.27, 21.43, 23.57])
2025-12-29 09:08:41,509 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-29 09:08:41,509 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user wants me to identify continuous activity segments based on the timeline provided. Let me start by looking at the timeline.  First, the timelin
2025-12-29 09:08:41,509 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [25.7, 27.83, 30.0, 32.13])
2025-12-29 09:08:41,510 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 1 captions
2025-12-29 09:08:46,993 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-29 09:08:46,994 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user provided a timeline of activity descriptions and wants me to identify continuous segments based on temporal patterns. Let me start by breaking down the timeline. 
2025-12-29 09:08:46,995 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:46,995 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:46,995 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:46,995 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 4.0 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:46,996 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:46,996 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:46,996 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:46,996 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 4.0 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:46,996 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:46,996 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:46,996 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:46,997 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 4.0 (not in [34.27, 36.43, 38.57, 40.7])
2025-12-29 09:08:49,949 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-29 09:08:49,950 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user provided a timeline of activity observations and wants me to identify continuous segments. So first, I need to look at the timestamps and see when activities chan
2025-12-29 09:08:49,950 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-29 09:08:49,950 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-29 09:08:49,950 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [42.87, 45.0, 47.13, 49.27])
2025-12-29 09:08:53,646 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-29 09:08:53,646 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to identify continuous activity segments from their timeline based on temporal patterns. Let me start by looking at the timestamps provided.  First, ther
2025-12-29 09:08:53,646 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-29 09:08:53,646 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 2.3 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-29 09:08:53,646 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-29 09:08:53,647 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-29 09:08:53,647 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-29 09:08:53,647 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-29 09:08:53,647 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [51.43, 53.57, 55.7, 57.87])
2025-12-29 09:08:58,065 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-29 09:08:58,065 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user provided a timeline of activity observations and wants me to identify continuous segments based on temporal patterns. The labels are work or idle.   First, I need
2025-12-29 09:08:58,065 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [60.0, 62.13])
2025-12-29 09:08:58,065 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [60.0, 62.13])
2025-12-29 09:08:58,065 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [60.0, 62.13])
2025-12-29 09:08:58,065 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 0.5 (not in [60.0, 62.13])
2025-12-29 09:08:58,065 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.1 (not in [60.0, 62.13])
2025-12-29 09:08:58,066 backend.stream_utils - WARNING [PARSE_LLM] Skipping segment with invalid start time: 3.8 (not in [60.0, 62.13])
2025-12-29 09:12:21,721 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a mechanic', 'The main person is assembling a mechanic', 'The main person in the image is engaged ', 'The main person is holding a wooden mech']
2025-12-29 09:12:21,721 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. The user wants me to identify continuous activity segments based on the timeline provided. The labels are assembling_drone, using_phone, idle, or unknown. 
2025-12-29 09:12:21,724 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: assembling_drone with 2 captions
2025-12-29 09:12:21,724 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: assembling_drone with 2 captions
2025-12-29 09:12:21,724 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: assembling_drone with 2 captions
2025-12-29 09:13:40,997 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden m', 'The main person is holding a wooden toy ', 'The main person is holding a mechanical ', 'The main person is holding a small elect']
2025-12-29 09:13:40,997 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to identify continuous activity segments based on the timeline provided. The user wants me to group consecutive similar activities into segments labeled as specifie
2025-12-29 09:13:40,997 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: assembling_drone with 4 captions
2025-12-29 09:13:40,998 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: assembling_drone with 4 captions
2025-12-29 09:14:48,585 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-29 09:14:48,585 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to identify continuous activity segments based on the given timeline. Let me start by looking at the timestamps.  First, there's an arafed image of a man
2025-12-29 09:14:48,586 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:14:48,587 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.80: idle with 4 captions
2025-12-29 09:14:48,587 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:14:48,587 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.80: idle with 4 captions
2025-12-29 09:14:59,778 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-29 09:14:59,778 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user provided a timeline of activity descriptions and wants me to identify continuous segments based on temporal patterns. Let me start by reading 
2025-12-29 09:14:59,779 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 4 captions
2025-12-29 09:14:59,779 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: idle with 4 captions
2025-12-29 09:14:59,779 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 4 captions
2025-12-29 09:14:59,780 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 4 captions
2025-12-29 09:14:59,780 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 4 captions
2025-12-29 09:14:59,780 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 4 captions
2025-12-29 09:14:59,780 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 4 captions
2025-12-29 09:14:59,780 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 4 captions
2025-12-29 09:14:59,781 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 4 captions
2025-12-29 09:14:59,781 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 4 captions
2025-12-29 09:14:59,782 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 4 captions
2025-12-29 09:14:59,783 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 4 captions
2025-12-29 09:14:59,783 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 4 captions
2025-12-29 09:14:59,783 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 4 captions
2025-12-29 09:14:59,783 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 4 captions
2025-12-29 09:14:59,783 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 4 captions
2025-12-29 09:14:59,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 4 captions
2025-12-29 09:14:59,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 4 captions
2025-12-29 09:14:59,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:14:59,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: work with 4 captions
2025-12-29 09:14:59,786 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 4 captions
2025-12-29 09:15:05,193 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-29 09:15:05,193 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze the timeline of activities to identify continuous segments. The user provided several timestamps with different activities. Let me start by looking at ea
2025-12-29 09:15:05,194 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:15:05,195 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:15:10,787 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-29 09:15:10,787 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user provided a timeline of observations and wants me to identify continuous activity segments. First, I need to parse each timestamp and check when activities change.
2025-12-29 09:15:10,788 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:15:10,788 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 4 captions
2025-12-29 09:15:10,789 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:15:10,789 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.13: work with 4 captions
2025-12-29 09:15:16,859 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-29 09:15:16,859 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze this timeline of activity descriptions and identify continuous segments. The user provided a timeline with several observations and wants me to group the
2025-12-29 09:15:16,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:15:16,861 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: work with 4 captions
2025-12-29 09:15:16,861 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:15:16,862 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:15:16,863 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: work with 4 captions
2025-12-29 09:15:16,863 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:15:22,039 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-29 09:15:22,039 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to analyze a timeline of activity descriptions and identify continuous segments. The labels are work and idle.   First, I need to look at each time point
2025-12-29 09:15:22,040 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:15:22,040 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:15:22,040 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:15:22,040 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:15:22,040 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:15:22,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-49.27: work with 4 captions
2025-12-29 09:15:22,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:15:22,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:15:22,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-49.27: work with 4 captions
2025-12-29 09:15:26,108 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-29 09:15:26,110 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze the timeline of activity descriptions and identify continuous segments. The user provided timestamps and labels, so first, I should look at each time poi
2025-12-29 09:15:26,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:15:26,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:15:26,112 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: idle with 4 captions
2025-12-29 09:15:29,654 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-29 09:15:29,655 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to analyze a timeline of activity descriptions and identify continuous segments. The timeline has two events: a worker in a factory with a mask on and gl
2025-12-29 09:15:29,655 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 2 captions
2025-12-29 09:23:52,112 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-29 09:23:52,113 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to identify continuous activity segments based on the timeline provided. The user has given me a timeline with observations and wants me to merge them into specific
2025-12-29 09:23:52,114 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-4.27: work with 4 captions
2025-12-29 09:23:52,114 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-4.27: work with 4 captions
2025-12-29 09:23:52,114 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-4.27: work with 4 captions
2025-12-29 09:23:52,114 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-4.27: work with 4 captions
2025-12-29 09:23:57,990 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-29 09:23:57,990 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to identify continuous activity segments based on the given timeline. The user provided the timeline with timestamps for various observations and wants me to merge 
2025-12-29 09:23:57,991 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:23:57,991 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:23:57,991 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:23:57,991 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 4 captions
2025-12-29 09:23:57,992 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 4 captions
2025-12-29 09:23:57,992 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:23:57,992 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:23:57,992 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 4 captions
2025-12-29 09:23:57,992 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 4 captions
2025-12-29 09:23:57,992 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-10.70: work with 4 captions
2025-12-29 09:23:57,993 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: work with 4 captions
2025-12-29 09:24:05,447 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-29 09:24:05,448 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the user wants me to identify continuous activity segments based on a timeline of activity observations. The labels are work and idle. The example give
2025-12-29 09:24:05,448 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:24:05,448 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:24:05,448 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:24:05,449 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.13-19.27: work with 4 captions
2025-12-29 09:24:05,449 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.13-19.27: work with 4 captions
2025-12-29 09:24:05,449 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.13-19.27: work with 4 captions
2025-12-29 09:24:05,449 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:24:05,449 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:24:05,449 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.13-19.27: work with 4 captions
2025-12-29 09:24:05,450 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.13-19.27: work with 4 captions
2025-12-29 09:24:05,450 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.13-19.27: work with 4 captions
2025-12-29 09:24:10,598 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-29 09:24:10,598 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to identify continuous activity segments based on the given timeline. The user provided a timeline of observations and wants me to merge similar activities into seg
2025-12-29 09:24:10,598 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:24:10,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:24:10,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:24:10,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:24:10,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:24:10,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-32.13: work with 4 captions
2025-12-29 09:24:10,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:24:10,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:24:10,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-32.13: work with 4 captions
2025-12-29 09:24:10,600 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:24:10,600 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:24:10,600 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-32.13: work with 4 captions
2025-12-29 09:26:11,596 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-29 09:26:11,596 backend.stream_processor - INFO [LLM_OUTPUT] 
2025-12-29 09:26:11,596 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-29 09:26:11,597 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 09:28:12,787 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-29 09:28:12,787 backend.stream_processor - INFO [LLM_OUTPUT] 
2025-12-29 09:28:12,787 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-29 09:28:12,788 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 09:30:14,053 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-29 09:30:14,054 backend.stream_processor - INFO [LLM_OUTPUT] 
2025-12-29 09:30:14,054 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-29 09:30:14,054 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 09:31:03,468 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-29 09:31:03,468 backend.stream_processor - INFO [LLM_OUTPUT] 
2025-12-29 09:31:03,468 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2025-12-29 09:31:03,469 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 09:48:37,604 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-29 09:48:37,604 backend.stream_processor - INFO [LLM_OUTPUT] 
2025-12-29 09:48:37,604 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-29 09:48:37,604 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 09:50:16,029 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-29 09:50:16,030 backend.stream_processor - INFO [LLM_OUTPUT] 
2025-12-29 09:50:16,030 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-29 09:50:16,030 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 09:50:21,462 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-29 09:50:21,462 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the timestamps and the labels provided. Let me start by looking at each timestamp and the cor
2025-12-29 09:50:21,463 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-23.60: work with 4 captions
2025-12-29 09:50:21,463 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: idle with 4 captions
2025-12-29 09:50:39,073 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-29 09:50:39,073 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given timestamps and labels. The labels are work or idle, and I have to follow the rules 
2025-12-29 09:50:39,074 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:39,074 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:39,075 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:50:39,075 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:39,075 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:39,076 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:39,076 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:50:39,076 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:39,076 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:39,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:50:39,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:39,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:39,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:50:39,078 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:39,078 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:39,078 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:50:49,045 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-29 09:50:49,046 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure out how to process this timeline. The task is to group consecutive observations into continuous activity segments based on the given labels. Let me start by looki
2025-12-29 09:50:49,046 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:49,046 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:49,047 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:50:49,048 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:49,049 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:49,049 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:49,049 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:49,050 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-40.70: work with 4 captions
2025-12-29 09:50:49,050 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:49,051 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:49,051 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:50:49,051 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:49,052 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:49,052 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 4 captions
2025-12-29 09:50:49,052 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:49,053 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:49,053 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-40.70: work with 4 captions
2025-12-29 09:50:49,053 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:49,053 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:50:49,054 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-40.70: work with 4 captions
2025-12-29 09:50:53,641 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-29 09:50:53,641 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the timestamps and the labels given. Let me start by looking at each observation one by one. 
2025-12-29 09:50:53,641 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:53,642 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: work with 4 captions
2025-12-29 09:50:53,642 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:50:53,642 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: work with 4 captions
2025-12-29 09:51:00,639 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-29 09:51:00,641 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. So, the task is to group consecutive observations into continuous activity segments based on the timestamps and labels provided. Let me start by lookin
2025-12-29 09:51:00,643 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 09:51:00,645 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 4 captions
2025-12-29 09:51:00,646 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 09:51:00,648 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 09:51:00,650 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 4 captions
2025-12-29 09:51:00,652 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 09:51:00,653 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 09:51:00,655 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 4 captions
2025-12-29 09:51:00,657 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 09:51:03,466 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-29 09:51:03,466 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the timestamps and labels provided. Let me start by looking at the timeline given.  The
2025-12-29 09:51:03,466 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 2 captions
2025-12-29 09:51:03,466 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 2 captions
2025-12-29 09:51:03,467 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.80-5.20: work with 2 captions
2025-12-29 09:56:01,702 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-29 09:56:01,703 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on their timestamps and labels. The labels are either work or idl
2025-12-29 09:56:01,704 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 4 captions
2025-12-29 09:56:01,704 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: work with 4 captions
2025-12-29 09:56:01,704 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 4 captions
2025-12-29 09:56:01,704 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:56:01,705 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:56:01,705 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 09:56:01,705 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:56:01,705 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:56:01,705 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 09:56:05,536 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-29 09:56:05,536 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps. The labels are work or idle. So first, I should look at each time
2025-12-29 09:56:05,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-29 09:56:05,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-12.80: idle with 4 captions
2025-12-29 09:56:05,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 4 captions
2025-12-29 09:56:05,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-29 09:56:05,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-12.80: idle with 4 captions
2025-12-29 09:56:05,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 4 captions
2025-12-29 09:56:14,745 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-29 09:56:14,746 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle. Let me start 
2025-12-29 09:56:14,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:56:14,747 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:56:14,747 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 09:56:14,747 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 4 captions
2025-12-29 09:56:14,748 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 09:56:14,748 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 4 captions
2025-12-29 09:56:14,749 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:56:14,750 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:56:14,750 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 09:56:14,750 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 4 captions
2025-12-29 09:56:14,751 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 09:56:14,751 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 4 captions
2025-12-29 09:56:14,752 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:56:14,752 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:56:14,752 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 09:56:14,753 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 4 captions
2025-12-29 09:56:14,753 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 09:56:14,753 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 4 captions
2025-12-29 09:56:14,754 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 4 captions
2025-12-29 09:56:14,755 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 09:56:14,755 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 4 captions
2025-12-29 09:56:14,755 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 4 captions
2025-12-29 09:56:14,756 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 09:56:14,757 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 4 captions
2025-12-29 09:56:14,757 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 4 captions
2025-12-29 09:56:14,759 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 09:56:14,759 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 4 captions
2025-12-29 09:56:20,390 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-29 09:56:20,390 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. So, the task is to group consecutive observations into continuous activity segments based on their timestamps. The labels are work or idle. The key here
2025-12-29 09:56:20,390 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:56:20,391 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:56:20,391 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 09:56:20,391 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:56:20,392 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:56:20,392 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 09:56:20,392 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 09:56:20,393 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 09:56:20,393 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 09:58:22,411 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-29 09:58:22,411 backend.stream_processor - INFO [LLM_OUTPUT] 
2025-12-29 09:58:22,411 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-29 09:58:22,411 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 10:00:23,685 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-29 10:00:23,686 backend.stream_processor - INFO [LLM_OUTPUT] 
2025-12-29 10:00:23,686 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-29 10:00:23,686 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 10:42:22,559 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-29 10:42:22,559 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. The task is to group consecutive observations into continuous activity segments based on the timestamps provided. Each observation is a VLM caption, and
2025-12-29 10:42:22,560 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 10:42:22,560 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 10:42:22,560 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 10:42:22,560 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 4 captions
2025-12-29 10:42:22,560 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 4 captions
2025-12-29 10:42:22,560 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: idle with 4 captions
2025-12-29 10:42:28,869 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-29 10:42:28,869 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem step by step. So, the task is to group consecutive observations into continuous activity segments based on their timestamps and labels. The labels are eithe
2025-12-29 10:42:28,869 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-29 10:42:28,869 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: idle with 4 captions
2025-12-29 10:42:28,870 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-29 10:42:28,870 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: idle with 4 captions
2025-12-29 10:42:28,870 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-29 10:42:28,870 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: idle with 4 captions
2025-12-29 10:42:28,870 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-29 10:42:28,870 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: idle with 4 captions
2025-12-29 10:42:34,070 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-29 10:42:34,070 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle. So first, I should process each o
2025-12-29 10:42:34,070 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-21.40: work with 4 captions
2025-12-29 10:42:34,070 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: idle with 4 captions
2025-12-29 10:42:39,937 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-29 10:42:39,937 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on the timestamps provided. Each observation is a single frame, a
2025-12-29 10:42:39,937 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 10:42:39,937 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 10:42:39,938 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 10:42:47,041 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-29 10:42:47,041 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are either work or idle. The ke
2025-12-29 10:42:47,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 10:42:47,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 10:42:47,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 10:42:47,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-29 10:42:47,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: idle with 4 captions
2025-12-29 10:42:47,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 4 captions
2025-12-29 10:42:47,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-29 10:42:47,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: idle with 4 captions
2025-12-29 10:42:47,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 4 captions
2025-12-29 10:42:47,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-29 10:42:47,045 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: idle with 4 captions
2025-12-29 10:42:47,045 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 4 captions
2025-12-29 10:42:56,531 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-29 10:42:56,532 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze these VLM captions and group consecutive observations into continuous activity segments. The user provided a timeline with timestamps for each observatio
2025-12-29 10:42:56,532 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-49.30: work with 4 captions
2025-12-29 10:42:56,532 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-49.30: work with 4 captions
2025-12-29 10:42:56,532 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 10:42:56,533 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 10:42:56,533 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 10:42:56,533 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-49.30: work with 4 captions
2025-12-29 10:42:56,533 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 10:42:56,533 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 10:42:56,534 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 10:42:56,534 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-49.30: work with 4 captions
2025-12-29 10:42:56,534 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-49.30: work with 4 captions
2025-12-29 10:42:56,534 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-49.30: work with 4 captions
2025-12-29 10:43:08,086 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-29 10:43:08,087 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. So, the task is to group consecutive observations into continuous activity segments based on the timestamps provided. Each observation is a single frame
2025-12-29 10:43:08,087 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 10:43:08,087 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 10:43:08,087 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 10:43:08,088 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 10:43:08,088 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: idle with 4 captions
2025-12-29 10:43:08,088 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: idle with 4 captions
2025-12-29 10:43:08,088 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 10:43:08,088 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: idle with 4 captions
2025-12-29 10:43:08,089 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: idle with 4 captions
2025-12-29 10:43:12,820 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-29 10:43:12,820 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. Let me start by understanding the problem step by step
2025-12-29 10:43:12,821 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 2 captions
2025-12-29 10:43:12,821 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 2 captions
2025-12-29 10:43:12,821 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 2 captions
2025-12-29 11:15:20,309 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-29 11:15:20,310 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on the given labels. The key here is to check for consecutive same lab
2025-12-29 11:15:20,312 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:20,312 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:20,312 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:26,067 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-29 11:15:26,067 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle. So first, I should process each o
2025-12-29 11:15:26,068 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:26,068 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:26,068 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:32,482 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-29 11:15:32,483 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on timestamps and labels. The labels are either work or idle. The key 
2025-12-29 11:15:32,483 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:32,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:32,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:32,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:32,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:32,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:32,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:32,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:32,485 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:32,485 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:32,485 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:32,485 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:32,485 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:32,485 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:32,485 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:40,992 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-29 11:15:40,993 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle. So first, I need to look at each 
2025-12-29 11:15:40,993 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:40,993 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:40,993 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:40,993 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 4 captions
2025-12-29 11:15:40,994 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 4 captions
2025-12-29 11:15:45,455 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-29 11:15:45,455 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are either work or idle. The ke
2025-12-29 11:15:45,455 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:45,456 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:45,456 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:45,456 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:45,456 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:45,456 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:45,456 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:45,456 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:45,456 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:49,031 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-29 11:15:49,031 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are either work or idle. The key here is to look at
2025-12-29 11:15:49,031 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:49,032 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:49,032 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:49,032 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:49,032 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:49,032 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:57,194 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-29 11:15:57,194 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze these VLM captions and group them into continuous activity segments. The timestamps are given, and I have to merge consecutive entries with the same labe
2025-12-29 11:15:57,195 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:57,195 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:57,195 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:57,195 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:57,195 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:57,195 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:57,195 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 11:15:57,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 4 captions
2025-12-29 11:15:57,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 11:15:57,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:57,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:57,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:57,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 11:15:57,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 4 captions
2025-12-29 11:15:57,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 11:15:57,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:57,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.30-3.10: idle with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-5.20: work with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 11:15:57,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 11:15:57,198 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 11:15:57,198 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 11:15:57,198 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 4 captions
2025-12-29 11:15:57,198 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 11:17:57,849 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-29 11:17:57,850 backend.stream_processor - INFO [LLM_OUTPUT] 
2025-12-29 11:17:57,850 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2025-12-29 11:17:57,850 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 12:32:33,567 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-29 12:32:33,567 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. The labels are work and idle. Let me start by looking 
2025-12-29 12:32:33,567 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 4 captions
2025-12-29 12:32:33,567 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: idle with 4 captions
2025-12-29 12:32:42,114 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-29 12:32:42,115 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps. The labels are work or idle. So first, I need to process each obs
2025-12-29 12:32:42,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:32:42,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:32:42,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:32:42,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:32:42,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:32:42,117 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:32:42,117 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:32:42,117 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:32:42,117 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:32:42,117 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:32:42,117 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:32:42,117 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:32:49,744 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-29 12:32:49,746 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are either work or idle. The key is to check for co
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 12:32:49,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 4 captions
2025-12-29 12:32:57,547 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-29 12:32:57,547 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze these VLM captions and group them into continuous activity segments based on timestamps. The user provided a timeline with multiple timestamps, and I nee
2025-12-29 12:32:57,547 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 4 captions
2025-12-29 12:32:57,547 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 4 captions
2025-12-29 12:32:57,547 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:32:57,547 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:32:57,547 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:33:04,150 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-29 12:33:04,150 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on timestamps. The labels are work or idle. So first, I have to look at each timestamp ent
2025-12-29 12:33:04,150 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:33:04,150 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:33:04,150 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:33:04,150 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:33:04,150 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:33:04,150 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:33:10,564 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-29 12:33:10,564 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on timestamps and labels. Let me start by understanding the task step 
2025-12-29 12:33:10,564 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:33:10,565 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:33:10,565 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:33:10,565 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:33:10,566 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:33:10,566 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:33:15,121 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-29 12:33:15,121 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle, and I have to merge them if they 
2025-12-29 12:33:15,121 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:33:15,121 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:33:15,121 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:33:19,662 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-29 12:33:19,662 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. Let me start by looking at the example input provided.
2025-12-29 12:33:19,662 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 2 captions
2025-12-29 12:33:19,662 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-5.20: idle with 2 captions
2025-12-29 12:45:48,287 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-29 12:45:48,289 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on the labels provided. Let me read through the instructions agai
2025-12-29 12:45:48,291 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:45:48,291 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:45:48,291 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:45:48,291 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 4 captions
2025-12-29 12:45:48,292 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: idle with 4 captions
2025-12-29 12:45:48,292 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 4 captions
2025-12-29 12:45:48,292 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: idle with 4 captions
2025-12-29 12:45:48,292 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 4 captions
2025-12-29 12:45:48,293 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: idle with 4 captions
2025-12-29 12:45:48,293 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 4 captions
2025-12-29 12:45:48,293 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: idle with 4 captions
2025-12-29 12:45:52,566 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-29 12:45:52,566 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given timestamps. The labels are work or idle, and I have to merge consecutive same-label
2025-12-29 12:45:52,566 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-29 12:45:52,567 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 4 captions
2025-12-29 12:45:52,567 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-29 12:45:52,568 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 4 captions
2025-12-29 12:45:57,009 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-29 12:45:57,010 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze the given sequence of VLM captions and group consecutive observations into continuous activity segments. The user provided an example, so I should follow
2025-12-29 12:45:57,011 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-29 12:45:57,012 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 4 captions
2025-12-29 12:45:57,013 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-29 12:45:57,013 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 4 captions
2025-12-29 12:46:03,475 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-29 12:46:03,475 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on the given timestamps and labels. Let me start by understanding
2025-12-29 12:46:03,476 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 4 captions
2025-12-29 12:46:03,476 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: idle with 4 captions
2025-12-29 12:46:03,476 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 4 captions
2025-12-29 12:46:07,513 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-29 12:46:07,514 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given timestamps and labels. Let me start by looking at the example input and output to u
2025-12-29 12:46:07,514 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-29 12:46:07,515 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: idle with 4 captions
2025-12-29 12:46:07,515 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 4 captions
2025-12-29 12:46:07,515 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-29 12:46:07,516 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: idle with 4 captions
2025-12-29 12:46:07,516 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 4 captions
2025-12-29 12:46:12,373 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-29 12:46:12,373 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on the labels provided. The example given uses timestamps and lab
2025-12-29 12:46:12,374 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 4 captions
2025-12-29 12:46:12,374 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-47.10: idle with 4 captions
2025-12-29 12:46:12,374 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: work with 4 captions
2025-12-29 12:46:12,374 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 4 captions
2025-12-29 12:46:12,375 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-47.10: idle with 4 captions
2025-12-29 12:46:12,375 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: work with 4 captions
2025-12-29 12:46:20,717 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-29 12:46:20,718 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on their timestamps and labels. The labels are either work or idl
2025-12-29 12:46:20,718 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:46:20,719 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:46:20,719 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:46:20,719 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:46:20,719 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:46:20,719 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:46:20,720 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 12:46:20,720 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 4 captions
2025-12-29 12:46:20,720 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 12:46:20,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:46:20,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:46:20,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:46:20,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:46:20,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:46:20,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:46:20,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 12:46:20,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 4 captions
2025-12-29 12:46:20,723 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 12:46:20,723 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-29 12:46:20,723 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 4 captions
2025-12-29 12:46:20,723 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 12:46:24,804 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-29 12:46:24,804 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps. The example input has two observations, and the output shows them
2025-12-29 12:46:24,805 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2025-12-29 12:46:24,805 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 12:50:38,704 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-29 12:50:38,705 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given labels and timestamps. Let me start by understanding the example provided.  T
2025-12-29 12:50:38,708 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 4 captions
2025-12-29 12:50:38,708 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 4 captions
2025-12-29 12:50:38,709 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 4 captions
2025-12-29 12:50:38,709 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: work with 4 captions
2025-12-29 12:51:19,110 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-29 12:51:19,110 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the timestamps given. The labels are work or idle. So first, I need to process each observati
2025-12-29 12:51:19,112 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:51:19,112 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:51:19,112 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:51:19,113 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:51:19,113 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:51:19,113 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:51:19,113 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-29 12:51:19,114 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.80: idle with 4 captions
2025-12-29 12:51:19,114 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 4 captions
2025-12-29 12:51:19,114 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 4 captions
2025-12-29 12:51:19,114 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-29 12:51:19,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.80: idle with 4 captions
2025-12-29 12:51:19,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 4 captions
2025-12-29 12:51:19,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 4 captions
2025-12-29 12:51:19,116 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-29 12:51:19,116 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.80: idle with 4 captions
2025-12-29 12:51:19,116 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 4 captions
2025-12-29 12:51:19,116 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 4 captions
2025-12-29 12:52:10,327 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-29 12:52:10,328 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on timestamps and labels provided. Let me read through the instru
2025-12-29 12:52:10,329 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-29 12:52:10,329 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 12:52:10,329 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 4 captions
2025-12-29 12:52:10,329 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: idle with 4 captions
2025-12-29 12:52:10,329 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-29 12:52:10,330 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 12:52:10,330 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 4 captions
2025-12-29 12:52:10,330 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: idle with 4 captions
2025-12-29 12:52:10,330 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-29 12:52:10,330 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 12:52:10,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 4 captions
2025-12-29 12:52:10,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: idle with 4 captions
2025-12-29 12:52:10,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-29 12:52:10,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-29 12:52:10,332 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 4 captions
2025-12-29 12:52:10,332 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: idle with 4 captions
2025-12-29 12:52:56,044 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-29 12:52:56,044 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given labels. The user provided an example, so I should follow that structure.  Fir
2025-12-29 12:52:56,045 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:52:56,045 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:52:56,046 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-29 12:52:56,046 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:52:56,046 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:52:56,046 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 12:52:56,047 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 12:53:37,742 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-29 12:53:37,743 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. The task is to group consecutive observations into continuous activity segments based on the labels provided. So first, I need to look at each timestam
2025-12-29 12:53:37,744 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-29 12:53:37,744 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: idle with 4 captions
2025-12-29 12:53:37,745 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 4 captions
2025-12-29 12:54:07,856 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-29 12:54:07,856 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. Let me start by looking at the example provided. The e
2025-12-29 12:54:07,856 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-42.90: work with 4 captions
2025-12-29 12:54:07,856 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: work with 4 captions
2025-12-29 12:54:07,857 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-42.90: work with 4 captions
2025-12-29 12:54:07,857 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: work with 4 captions
2025-12-29 12:54:07,857 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-47.10: idle with 4 captions
2025-12-29 12:54:07,857 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.30-49.30: work with 4 captions
2025-12-29 12:54:07,857 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-42.90: work with 4 captions
2025-12-29 12:54:07,857 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: work with 4 captions
2025-12-29 12:54:07,858 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-47.10: idle with 4 captions
2025-12-29 12:54:07,858 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.30-49.30: work with 4 captions
2025-12-29 12:54:07,858 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-42.90: work with 4 captions
2025-12-29 12:54:07,859 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: work with 4 captions
2025-12-29 12:54:07,859 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-47.10: idle with 4 captions
2025-12-29 12:54:07,859 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.30-49.30: work with 4 captions
2025-12-29 12:54:07,859 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-42.90: work with 4 captions
2025-12-29 12:54:07,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: work with 4 captions
2025-12-29 12:54:07,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-47.10: idle with 4 captions
2025-12-29 12:54:07,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.30-49.30: work with 4 captions
2025-12-29 12:54:57,346 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-29 12:54:57,347 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze these timestamps and group consecutive observations into continuous activity segments. The labels are work or idle, and I have to merge them when they ha
2025-12-29 12:54:57,347 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: idle with 4 captions
2025-12-29 12:54:57,347 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 4 captions
2025-12-29 12:55:13,201 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-29 12:55:13,201 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. So, the task is to group consecutive observations into continuous activity segments based on their timestamps. The labels are either work or idle. And 
2025-12-29 12:55:13,202 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.10: work with 2 captions
2025-12-29 12:55:22,150 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a mechanic', 'The main person is assembling a mechanic', 'The main person in the image is engaged ', 'The main person is holding a wooden mech']
2025-12-29 12:55:22,151 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem step by step. So, the user provided a sequence of timestamped VLM captions and wants to group consecutive observations into continuous activity segments bas
2025-12-29 12:55:22,152 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-29 12:59:34,891 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden m', 'The main person is holding a wooden toy ', 'The main person is holding a mechanical ', 'The main person is holding a small elect']
2025-12-29 12:59:34,891 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on activity consistency. The user provided a sample input with timestamps and labels, and 
2025-12-29 12:59:34,891 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-29 13:03:44,306 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small elect', 'The main person is holding a small piece', 'The main person is holding a small white', 'The main person is using a tool to work ']
2025-12-29 13:03:44,306 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on activity consistency. The example input has timestamps, and I have to process them in c
2025-12-29 13:03:44,307 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-29 13:03:44,307 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 13:07:52,909 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is engaged in assembling', 'The main person in the image is engaged ', 'The main person is holding a small devic', 'The main person is holding a small mecha']
2025-12-29 13:07:52,909 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user provided a sequence of timestamps and wants me to group consecutive observations into continuous activity segments based on activity consistency. The labels are i
2025-12-29 13:07:52,910 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.50-4.10: assembling_drone with 4 captions
2025-12-29 13:07:52,910 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.10-4.40: unknown with 4 captions
2025-12-29 13:07:52,910 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.50-4.10: assembling_drone with 4 captions
2025-12-29 13:07:52,911 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.10-4.40: unknown with 4 captions
2025-12-29 13:12:07,650 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small devic', 'The main person in the image is holding ', 'The main person is holding a small white', 'The main person is holding a small white']
2025-12-29 13:12:07,651 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. So, the task is to group consecutive observations into continuous activity segments based on activity consistency. The input has timestamps for each obs
2025-12-29 13:12:07,652 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.50: idle with 4 captions
2025-12-29 13:16:23,094 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden t', 'The main person is assembling a wooden t', 'The main person is assembling a wooden d', 'The main person is assembling a small dr']
2025-12-29 13:16:23,095 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user provided a sequence of VLM captions with timestamps, and I need to group consecutive observations into continuous activity segments based on activity consistency.
2025-12-29 13:16:23,096 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-29 13:16:23,096 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-29 13:16:23,097 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-29 13:20:41,076 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden d', 'The main person is assembling a small dr', 'The main person is holding a small drone', 'The main person in the image is holding ']
2025-12-29 13:20:41,082 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on labels. The example input shows that each observation is a single timestamp. So first, I shou
2025-12-29 13:20:41,085 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.80: idle with 4 captions
2025-12-29 13:22:49,988 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small drone', 'The main person is holding a small drone']
2025-12-29 13:22:49,989 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on activity consistency. The input has timestamps, and I have to process them in order. Th
2025-12-29 13:22:49,993 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 2 captions
2025-12-29 13:43:28,972 backend.stream_processor - INFO [LLM_INPUT] captions: ['someone is holding a black wire with a s', 'someone is holding a black wire with a s', 'someone is holding a black cord with a s', 'someone is holding a black wire with a s']
2025-12-29 13:43:28,983 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze this sequence of VLM captions with timestamps and group consecutive observations into continuous activity segments. The labels are work or idle.   First,
2025-12-29 13:43:28,995 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.20: work with 4 captions
2025-12-29 13:43:52,294 backend.stream_processor - INFO [LLM_INPUT] captions: ['someone is holding a black wire with a s', 'someone is holding a black wire with a s', 'someone is holding a pair of scissors in', 'someone is holding a pair of scissors in']
2025-12-29 13:43:52,295 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. Let me start by understanding the task step by step.  
2025-12-29 13:43:52,296 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.30-0.40: work with 4 captions
2025-12-29 13:43:52,298 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.40-0.50: idle with 4 captions
2025-12-29 13:43:52,298 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.30-0.40: work with 4 captions
2025-12-29 13:43:52,299 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.40-0.50: idle with 4 captions
2025-12-29 13:43:52,300 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.30-0.40: work with 4 captions
2025-12-29 13:43:52,301 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.40-0.50: idle with 4 captions
2025-12-29 13:43:52,302 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.30-0.40: work with 4 captions
2025-12-29 13:43:52,303 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.40-0.50: idle with 4 captions
2025-12-29 13:43:52,303 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.30-0.40: work with 4 captions
2025-12-29 13:43:52,304 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.40-0.50: idle with 4 captions
2025-12-29 13:44:18,161 backend.stream_processor - INFO [LLM_INPUT] captions: ['someone is holding a pair of scissors in', 'someone is holding a pair of scissors in', 'someone is holding a pair of scissors in', 'someone is holding a black wire with a s']
2025-12-29 13:44:18,161 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. The task is to group consecutive observations into continuous activity segments based on their timestamps and labels. The labels are either work or idl
2025-12-29 13:44:18,162 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 13:44:18,162 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 13:44:18,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.60-0.70: work with 4 captions
2025-12-29 13:44:18,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: idle with 4 captions
2025-12-29 13:44:18,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.60-0.60: work with 4 captions
2025-12-29 13:44:18,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.70-0.70: idle with 4 captions
2025-12-29 13:44:18,164 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: work with 4 captions
2025-12-29 13:44:18,165 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.60-0.70: work with 4 captions
2025-12-29 13:44:18,167 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: work with 4 captions
2025-12-29 13:44:18,167 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.60-0.60: work with 4 captions
2025-12-29 13:44:18,169 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.70-0.70: idle with 4 captions
2025-12-29 13:44:18,169 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: work with 4 captions
2025-12-29 13:44:18,170 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.60-0.60: work with 4 captions
2025-12-29 13:44:18,170 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.70-0.70: idle with 4 captions
2025-12-29 13:44:18,171 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: work with 4 captions
2025-12-29 13:44:18,171 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.60-0.60: work with 4 captions
2025-12-29 13:44:18,171 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.70-0.70: idle with 4 captions
2025-12-29 13:44:18,172 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: work with 4 captions
2025-12-29 13:44:37,319 backend.stream_processor - INFO [LLM_INPUT] captions: ['someone is holding a piece of black wire', 'someone is holding a pair of scissors in', 'someone is holding a black wire with a s', 'someone is holding a black wire with a s']
2025-12-29 13:44:37,319 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given labels. The timestamps are provided, so I have to process each observation on
2025-12-29 13:44:37,320 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.90-0.90: work with 4 captions
2025-12-29 13:44:37,320 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.00-1.00: idle with 4 captions
2025-12-29 13:44:37,320 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.10-1.10: work with 4 captions
2025-12-29 13:44:37,320 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.90-0.90: work with 4 captions
2025-12-29 13:44:37,320 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.00-1.00: idle with 4 captions
2025-12-29 13:44:37,320 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.10-1.10: work with 4 captions
2025-12-29 13:44:37,321 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.90-0.90: work with 4 captions
2025-12-29 13:44:37,321 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.00-1.00: idle with 4 captions
2025-12-29 13:44:37,321 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.10-1.10: work with 4 captions
2025-12-29 13:44:52,703 backend.stream_processor - INFO [LLM_INPUT] captions: ['someone is holding a black wire with a s', 'someone is holding a black wire with a s', 'someone is working on a small electronic', 'someone is working on a small electronic']
2025-12-29 13:44:52,703 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given labels and timestamps. Let me start by looking at the example provided.   In 
2025-12-29 13:44:52,704 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-29 13:44:52,705 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-29 13:45:08,701 backend.stream_processor - INFO [LLM_INPUT] captions: ['someone is working on a small electronic', 'someone is working on a small electronic', 'someone is working on a project with wir', 'someone is working on a circuit with wir']
2025-12-29 13:45:08,702 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given labels. The example given has timestamps and labels. Let me try to apply the 
2025-12-29 13:45:08,703 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.50-1.70: work with 4 captions
2025-12-29 13:45:48,956 backend.stream_processor - INFO [LLM_INPUT] captions: ['someone is working on a circuit with wir', 'someone is making a circuit with a small', 'someone is making a small circuit with a', 'someone is working on a small electronic']
2025-12-29 13:45:48,956 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on labels provided. The labels are either work or idle. The key h
2025-12-29 13:45:48,960 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.70-2.00: work with 4 captions
2025-12-29 13:45:48,961 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.70-2.00: work with 4 captions
2025-12-29 13:45:48,961 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.70-2.00: work with 4 captions
2025-12-29 13:45:48,962 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 13:45:48,962 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-29 13:45:48,962 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 13:45:48,963 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-5.20: idle with 4 captions
2025-12-29 13:45:48,963 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 13:45:48,964 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-5.20: idle with 4 captions
2025-12-29 13:45:48,964 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-29 13:45:48,965 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-5.20: idle with 4 captions
2025-12-29 13:45:59,194 backend.stream_processor - INFO [LLM_INPUT] captions: ['someone is working on a small electronic', 'someone is working on a small electronic']
2025-12-29 13:45:59,194 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on their timestamps and labels. The example given uses timestamps like 0.50, 2.30, etc., a
2025-12-29 13:45:59,195 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 2 captions
2025-12-29 13:45:59,195 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 2 captions
2025-12-29 13:45:59,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 2 captions
2025-12-30 09:18:15,199 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a mechanic', 'The main person is assembling a mechanic', 'The main person in the image is engaged ', 'The main person is holding a wooden mech']
2025-12-30 09:18:15,246 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on activity consistency. The input is a sequence of timestamps wi
2025-12-30 09:18:15,276 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:19:26,813 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden m', 'The main person is holding a wooden toy ', 'The main person is holding a mechanical ', 'The main person is holding a small elect']
2025-12-30 09:19:26,813 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. So, the task is to group consecutive observations into continuous activity segments based on labels. The user provided an example, and I need to apply t
2025-12-30 09:19:26,814 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:19:26,814 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:21:03,686 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small elect', 'The main person is holding a small piece', 'The main person is holding a small white', 'The main person is using a tool to work ']
2025-12-30 09:21:03,686 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on labels. The input is a sequence of timestamps, and each timestamp r
2025-12-30 09:21:03,686 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:21:03,686 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.30-3.20: assembling_drone with 4 captions
2025-12-30 09:21:03,687 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.60-2.90: using_phone with 4 captions
2025-12-30 09:21:03,687 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.90-3.20: unknown with 4 captions
2025-12-30 09:21:03,687 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.30-3.20: idle with 4 captions
2025-12-30 09:21:03,688 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:21:03,688 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:21:03,688 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:21:53,385 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is engaged in assembling', 'The main person in the image is engaged ', 'The main person is holding a small devic', 'The main person is holding a small mecha']
2025-12-30 09:21:53,386 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on their labels. The input has timestamps and captions. Each timestamp is a single observa
2025-12-30 09:21:53,387 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:22:45,226 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small devic', 'The main person in the image is holding ', 'The main person is holding a small white', 'The main person is holding a small white']
2025-12-30 09:22:45,226 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on activity consistency. The input is a sequence of timestamps with VL
2025-12-30 09:22:45,226 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.50: idle with 4 captions
2025-12-30 09:22:45,227 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.50: idle with 4 captions
2025-12-30 09:22:45,227 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.50: idle with 4 captions
2025-12-30 09:22:45,227 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.50: idle with 4 captions
2025-12-30 09:23:36,885 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden t', 'The main person is assembling a wooden t', 'The main person is assembling a wooden d', 'The main person is assembling a small dr']
2025-12-30 09:23:36,886 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on activity consistency. The user provided example input and output, so I should follow th
2025-12-30 09:23:36,886 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-6.70: idle with 4 captions
2025-12-30 09:24:31,453 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden d', 'The main person is assembling a small dr', 'The main person is holding a small drone', 'The main person in the image is holding ']
2025-12-30 09:24:31,455 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on activity consistency. The input is a sequence of timestamps wi
2025-12-30 09:24:31,456 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:25:08,152 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small drone', 'The main person is holding a small drone']
2025-12-30 09:25:08,152 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. So the task is to group consecutive observations into continuous activity segments based on activity consistency. The labels are idle, using_phone, ass
2025-12-30 09:25:08,152 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 2 captions
2025-12-30 09:39:52,277 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a mechanic', 'The main person is assembling a mechanic', 'The main person in the image is engaged ', 'The main person is holding a wooden mech']
2025-12-30 09:39:52,277 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on activity consistency. The labels are idle, using_phone, assemb
2025-12-30 09:39:52,278 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:41:30,145 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden m', 'The main person is holding a wooden toy ', 'The main person is holding a mechanical ', 'The main person is holding a small elect']
2025-12-30 09:41:30,146 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on activity consistency. The key here is to look at the timestamp
2025-12-30 09:41:30,147 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:42:30,812 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small elect', 'The main person is holding a small piece', 'The main person is holding a small white', 'The main person is using a tool to work ']
2025-12-30 09:42:30,813 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on activity consistency. The example input has timestamps and labels, so I should process 
2025-12-30 09:42:30,813 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:42:30,813 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.30-2.60: assembling_drone with 4 captions
2025-12-30 09:42:30,814 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.60-2.90: using_phone with 4 captions
2025-12-30 09:42:30,814 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.90-3.20: using_phone with 4 captions
2025-12-30 09:43:20,463 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is engaged in assembling', 'The main person in the image is engaged ', 'The main person is holding a small devic', 'The main person is holding a small mecha']
2025-12-30 09:43:20,464 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on their labels. The input has timestamps and captions. Each timestamp represents a single
2025-12-30 09:43:20,465 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:44:01,660 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small devic', 'The main person in the image is holding ', 'The main person is holding a small white', 'The main person is holding a small white']
2025-12-30 09:44:01,661 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the timestamps provided. The example shows that each observation is a single time point
2025-12-30 09:44:01,662 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.50: idle with 4 captions
2025-12-30 09:44:51,686 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden t', 'The main person is assembling a wooden t', 'The main person is assembling a wooden d', 'The main person is assembling a small dr']
2025-12-30 09:44:51,686 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the timestamps and labels provided. Let me start by looking at each observation and see how t
2025-12-30 09:44:51,687 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-6.40: idle with 4 captions
2025-12-30 09:44:51,688 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.70: assembling_drone with 4 captions
2025-12-30 09:44:51,688 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-15.00: idle with 4 captions
2025-12-30 09:44:51,688 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-6.10: idle with 4 captions
2025-12-30 09:44:51,690 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.10-6.40: idle with 4 captions
2025-12-30 09:44:51,690 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.70: assembling_drone with 4 captions
2025-12-30 09:44:51,690 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-6.10: idle with 4 captions
2025-12-30 09:44:51,690 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.10-6.40: idle with 4 captions
2025-12-30 09:44:51,691 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.70: assembling_drone with 4 captions
2025-12-30 09:44:51,691 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-15.00: idle with 4 captions
2025-12-30 09:44:51,691 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 09:44:51,693 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-6.10: idle with 4 captions
2025-12-30 09:44:51,693 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.10-6.40: idle with 4 captions
2025-12-30 09:44:51,693 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.70: assembling_drone with 4 captions
2025-12-30 09:44:51,693 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-6.10: idle with 4 captions
2025-12-30 09:44:51,694 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.10-6.40: idle with 4 captions
2025-12-30 09:44:51,694 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.70: assembling_drone with 4 captions
2025-12-30 09:44:51,694 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-6.10: idle with 4 captions
2025-12-30 09:44:51,695 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.10-6.40: idle with 4 captions
2025-12-30 09:44:51,695 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.70: assembling_drone with 4 captions
2025-12-30 09:47:23,396 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden d', 'The main person is assembling a small dr', 'The main person is holding a small drone', 'The main person in the image is holding ']
2025-12-30 09:47:23,397 backend.stream_processor - INFO [LLM_OUTPUT] 
2025-12-30 09:47:23,397 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 09:47:23,397 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 09:47:53,177 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small drone', 'The main person is holding a small drone']
2025-12-30 09:47:53,177 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on labels. The input has timestamps, and each entry is a single observation. So first, I s
2025-12-30 09:47:53,177 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.10-8.40: idle with 2 captions
2025-12-30 09:59:56,745 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-30 09:59:56,745 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to analyze a sequence of VLM captions with timestamps and group consecutive observations into continuous activity segments. Let me start by understanding
2025-12-30 09:59:56,747 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 4 captions
2025-12-30 09:59:56,747 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: work with 4 captions
2025-12-30 09:59:56,748 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 4 captions
2025-12-30 09:59:56,748 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: work with 4 captions
2025-12-30 10:00:09,829 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-30 10:00:09,830 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these timestamps into continuous activity segments based on the given labels. Let me start by looking at the example provided. The example input has multip
2025-12-30 10:00:09,830 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:00:09,832 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:00:09,833 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:00:09,834 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-30 10:00:09,834 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.80: work with 4 captions
2025-12-30 10:00:09,835 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 4 captions
2025-12-30 10:00:09,836 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 4 captions
2025-12-30 10:00:37,471 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-30 10:00:37,471 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to analyze a sequence of timestamped VLM captions and group them into continuous activity segments. Let me start by understanding the problem step by ste
2025-12-30 10:00:37,471 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:00:37,472 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:00:37,472 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: idle with 4 captions
2025-12-30 10:00:37,472 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 4 captions
2025-12-30 10:00:37,472 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: idle with 4 captions
2025-12-30 10:00:51,229 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-30 10:00:51,230 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on the given timestamps and labels. The labels are work or idle, 
2025-12-30 10:00:51,231 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 4 captions
2025-12-30 10:00:51,231 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: idle with 4 captions
2025-12-30 10:00:51,231 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 4 captions
2025-12-30 10:00:51,232 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: idle with 4 captions
2025-12-30 10:00:51,234 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 4 captions
2025-12-30 10:00:51,235 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: idle with 4 captions
2025-12-30 10:01:12,771 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-30 10:01:12,772 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. The task is to group consecutive observations into continuous activity segments based on their timestamps and labels. The labels are work or idle. So f
2025-12-30 10:01:12,772 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:01:12,773 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:01:12,773 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:01:12,773 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:01:12,774 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:01:12,774 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:01:12,774 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-30 10:01:12,775 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 4 captions
2025-12-30 10:01:12,775 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 4 captions
2025-12-30 10:01:12,775 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-30 10:01:12,776 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 4 captions
2025-12-30 10:01:12,776 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 4 captions
2025-12-30 10:01:12,776 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-30 10:01:12,776 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 4 captions
2025-12-30 10:01:12,777 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 4 captions
2025-12-30 10:01:12,777 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-30 10:01:12,777 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 4 captions
2025-12-30 10:01:12,777 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 4 captions
2025-12-30 10:02:00,333 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-30 10:02:00,334 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given timestamps and labels. Let me start by looking at the example input and output to u
2025-12-30 10:02:00,334 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:02:00,336 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:02:00,336 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:02:00,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:02:00,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:02:00,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:02:00,338 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 4 captions
2025-12-30 10:02:00,338 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:02:00,339 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:02:00,339 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:02:00,340 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 4 captions
2025-12-30 10:02:00,340 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 4 captions
2025-12-30 10:02:00,341 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:02:16,975 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-30 10:02:16,976 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given timestamps. The labels are work or idle, and I have to merge consecutive same-label
2025-12-30 10:02:16,976 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:02:16,977 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:02:16,977 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:02:16,977 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.79-5.79: idle with 4 captions
2025-12-30 10:02:16,977 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-51.40: work with 4 captions
2025-12-30 10:02:16,977 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-53.60: idle with 4 captions
2025-12-30 10:02:16,978 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: idle with 4 captions
2025-12-30 10:02:16,978 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: idle with 4 captions
2025-12-30 10:02:42,583 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-30 10:02:42,583 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. The task is to group consecutive observations into continuous activity segments based on the given labels. The example given has timestamps, and the ou
2025-12-30 10:02:42,583 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.10: work with 2 captions
2025-12-30 10:02:42,583 backend.stream_utils - INFO [PARSE_LLM] Created segment 64.20-64.20: work with 2 captions
2025-12-30 10:04:06,868 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a mechanic', 'The main person is assembling a mechanic', 'The main person in the image is engaged ', 'The main person is holding a wooden mech']
2025-12-30 10:04:06,868 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to group consecutive observations into continuous activity segments based on labels. They provided an example, and I need to apply the same rules to the 
2025-12-30 10:04:06,868 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 10:06:11,947 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden m', 'The main person is holding a wooden toy ', 'The main person is holding a mechanical ', 'The main person is holding a small elect']
2025-12-30 10:06:11,948 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on their labels. The example input has timestamps, and I have to process them in order. Le
2025-12-30 10:06:11,948 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 10:06:11,948 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: idle with 4 captions
2025-12-30 10:06:11,949 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: idle with 4 captions
2025-12-30 10:06:11,949 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 10:06:11,950 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.83: idle with 4 captions
2025-12-30 10:06:11,950 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.83-15.00: idle with 4 captions
2025-12-30 10:08:05,672 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small elect', 'The main person is holding a small piece', 'The main person is holding a small white', 'The main person is using a tool to work ']
2025-12-30 10:08:05,672 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on activity consistency. The input is a sequence of timestamps wi
2025-12-30 10:08:05,672 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 10:10:01,138 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is engaged in assembling', 'The main person in the image is engaged ', 'The main person is holding a small devic', 'The main person is holding a small mecha']
2025-12-30 10:10:01,138 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to analyze a sequence of VLM captions with timestamps and group them into continuous activity segments. The example given has timestamps from 8.57 to 15.
2025-12-30 10:10:01,138 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 10:12:20,007 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small devic', 'The main person in the image is holding ', 'The main person is holding a small white', 'The main person is holding a small white']
2025-12-30 10:12:20,008 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given labels and segmentation rules. The input has timestamps for each observation,
2025-12-30 10:12:20,008 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.00: idle with 4 captions
2025-12-30 10:12:20,008 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.50: unknown with 4 captions
2025-12-30 10:12:20,009 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.00: using_phone with 4 captions
2025-12-30 10:12:20,009 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.50: unknown with 4 captions
2025-12-30 10:12:20,009 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.00: using_phone with 4 captions
2025-12-30 10:12:20,009 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.50: unknown with 4 captions
2025-12-30 10:12:20,010 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.00: using_phone with 4 captions
2025-12-30 10:12:20,010 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.50: unknown with 4 captions
2025-12-30 10:12:20,010 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.00: using_phone with 4 captions
2025-12-30 10:12:20,010 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.50: unknown with 4 captions
2025-12-30 10:12:20,011 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 10:12:20,011 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.00: using_phone with 4 captions
2025-12-30 10:12:20,012 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.50: unknown with 4 captions
2025-12-30 10:12:20,012 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 10:13:31,973 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-30 10:13:31,973 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on binary labels. The example given shows that when there's a cha
2025-12-30 10:13:31,974 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:13:31,975 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:13:31,975 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:13:31,976 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-0.50: work with 4 captions
2025-12-30 10:13:31,977 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.30-2.30: work with 4 captions
2025-12-30 10:13:31,977 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:13:31,977 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:13:31,983 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-0.50: work with 4 captions
2025-12-30 10:13:31,984 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.30-2.30: work with 4 captions
2025-12-30 10:13:31,985 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:13:31,985 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:13:31,986 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-0.50: work with 4 captions
2025-12-30 10:13:31,986 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.30-2.30: work with 4 captions
2025-12-30 10:13:31,987 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:13:31,987 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:14:02,214 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-30 10:14:02,215 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given labels and timestamps. Let me start by looking at the example provided.   In the ex
2025-12-30 10:14:02,215 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:14:02,216 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:14:02,216 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:14:02,216 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 4 captions
2025-12-30 10:14:02,217 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-10.70: idle with 4 captions
2025-12-30 10:14:02,217 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-12.80: idle with 4 captions
2025-12-30 10:14:02,218 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 4 captions
2025-12-30 10:14:28,195 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-30 10:14:28,196 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamped captions. Let me start by understanding the problem step by step.
2025-12-30 10:14:28,196 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: idle with 4 captions
2025-12-30 10:14:28,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-21.40: idle with 4 captions
2025-12-30 10:14:28,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 4 captions
2025-12-30 10:14:28,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: idle with 4 captions
2025-12-30 10:14:28,198 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-21.40: idle with 4 captions
2025-12-30 10:14:28,198 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 4 captions
2025-12-30 10:14:28,199 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: idle with 4 captions
2025-12-30 10:14:28,199 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-21.40: idle with 4 captions
2025-12-30 10:14:28,199 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 4 captions
2025-12-30 10:14:38,587 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden t', 'The main person is assembling a wooden t', 'The main person is assembling a wooden d', 'The main person is assembling a small dr']
2025-12-30 10:14:38,588 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the rules given. Each observation is a timestamp, and I have to merge them if they have the s
2025-12-30 10:14:38,588 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 10:15:04,388 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-30 10:15:04,388 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle, and I have to
2025-12-30 10:15:04,389 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:15:04,389 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:15:04,389 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:15:04,390 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 4 captions
2025-12-30 10:15:04,390 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 4 captions
2025-12-30 10:15:04,390 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 4 captions
2025-12-30 10:15:04,391 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 4 captions
2025-12-30 10:15:41,311 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-30 10:15:41,311 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. So, the task is to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle, and I
2025-12-30 10:15:41,312 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-30 10:15:41,312 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 4 captions
2025-12-30 10:15:41,313 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-40.70: work with 4 captions
2025-12-30 10:15:41,313 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 10:15:41,313 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 10:15:41,313 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 10:15:41,314 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-30 10:15:41,314 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 4 captions
2025-12-30 10:15:41,315 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-40.70: work with 4 captions
2025-12-30 10:15:41,315 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 4 captions
2025-12-30 10:15:41,315 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 4 captions
2025-12-30 10:15:41,316 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-40.70: work with 4 captions
2025-12-30 10:15:51,113 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-30 10:15:51,113 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the timestamps provided. Each observation is a single frame, and I have to merge consecutive 
2025-12-30 10:15:51,114 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 4 captions
2025-12-30 10:15:51,114 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 4 captions
2025-12-30 10:16:17,655 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-30 10:16:17,656 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the timestamps provided. The labels are work or idle. The rules are straightforward: if conse
2025-12-30 10:16:17,656 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-30 10:16:17,656 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: work with 4 captions
2025-12-30 10:16:17,657 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: idle with 4 captions
2025-12-30 10:16:17,657 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-30 10:16:17,657 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: work with 4 captions
2025-12-30 10:16:17,658 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: idle with 4 captions
2025-12-30 10:16:17,658 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 4 captions
2025-12-30 10:16:17,658 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: work with 4 captions
2025-12-30 10:16:17,658 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: idle with 4 captions
2025-12-30 10:16:46,708 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-30 10:16:46,708 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. The example provided has two observations: one at 60.0
2025-12-30 10:16:46,709 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 2 captions
2025-12-30 10:16:46,710 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 2 captions
2025-12-30 10:16:57,208 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is assembling a wooden d', 'The main person is assembling a small dr', 'The main person is holding a small drone', 'The main person in the image is holding ']
2025-12-30 10:16:57,208 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on activity consistency. The input is a sequence of timestamped V
2025-12-30 10:16:57,209 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 4 captions
2025-12-30 10:18:18,792 backend.stream_processor - INFO [LLM_INPUT] captions: ['The main person is holding a small drone', 'The main person is holding a small drone']
2025-12-30 10:18:18,793 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on activity consistency. The input is a sequence of timestamps an
2025-12-30 10:18:18,793 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 2 captions
2025-12-30 10:18:18,794 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.57-15.00: idle with 2 captions
2025-12-30 11:52:36,002 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-30 11:52:36,002 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on the given labels and timeline. Let me start by understanding the ta
2025-12-30 11:52:36,003 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 4 captions
2025-12-30 11:52:36,004 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 4 captions
2025-12-30 11:52:36,004 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: idle with 4 captions
2025-12-30 11:52:36,004 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: work with 4 captions
2025-12-30 11:52:36,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 4 captions
2025-12-30 11:52:36,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 4 captions
2025-12-30 11:52:36,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: idle with 4 captions
2025-12-30 11:52:36,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: work with 4 captions
2025-12-30 11:52:36,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 4 captions
2025-12-30 11:52:36,006 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 4 captions
2025-12-30 11:52:36,006 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: idle with 4 captions
2025-12-30 11:52:36,006 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: work with 4 captions
2025-12-30 11:52:36,006 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 4 captions
2025-12-30 11:52:36,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 4 captions
2025-12-30 11:52:36,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: idle with 4 captions
2025-12-30 11:52:36,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: work with 4 captions
2025-12-30 11:53:18,196 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-30 11:53:18,196 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. Let me start by understanding the 
2025-12-30 11:53:18,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 11:53:18,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 11:53:18,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 11:53:18,198 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 11:53:18,198 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 11:53:18,198 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 11:53:18,199 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 11:53:18,199 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 11:53:18,199 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 11:53:18,200 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-30 11:53:18,200 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: idle with 4 captions
2025-12-30 11:53:18,200 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-30 11:53:18,200 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: idle with 4 captions
2025-12-30 11:53:34,415 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-30 11:53:34,415 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle. The key 
2025-12-30 11:53:34,416 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-30 11:53:34,416 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-30 11:53:34,416 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 4 captions
2025-12-30 11:53:34,416 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 4 captions
2025-12-30 11:53:34,417 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-30 11:53:34,417 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 4 captions
2025-12-30 11:53:56,880 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-30 11:53:56,881 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on their timestamps and labels. The labels are either work or idl
2025-12-30 11:53:56,886 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 11:53:56,887 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 11:53:56,887 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 11:53:56,888 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 11:53:56,888 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 11:53:56,888 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 11:53:56,889 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 11:53:56,889 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 11:53:56,889 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 11:53:56,890 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 11:53:56,890 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 11:53:56,890 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 11:54:12,067 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-30 11:54:12,067 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given labels and segmentation rules. Let me start by looking at the example input a
2025-12-30 11:54:12,068 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 11:54:12,068 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 11:54:12,068 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 11:54:12,069 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 11:54:12,069 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 11:54:12,069 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 11:54:12,069 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 11:54:12,069 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 11:54:12,070 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 11:54:26,449 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-30 11:54:26,450 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the timestamps provided. The labels are work or idle. The rules are straightforward: if conse
2025-12-30 11:54:26,450 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 11:54:26,450 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 11:54:26,451 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 11:54:40,039 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-30 11:54:40,040 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's try to figure this out. So, the task is to group consecutive observations into continuous activity segments based on the given labels. The example given has timestamps and labe
2025-12-30 11:54:40,040 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-51.40: work with 4 captions
2025-12-30 11:54:40,040 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-53.60: idle with 4 captions
2025-12-30 11:54:40,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: work with 4 captions
2025-12-30 11:54:40,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 4 captions
2025-12-30 11:55:02,094 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-30 11:55:02,096 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The task is to group consecutive observations into continuous activity segments based on labels. The example given has two timestamps, and I need to follow the rules.  Fir
2025-12-30 11:55:02,096 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 2 captions
2025-12-30 11:55:02,096 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 2 captions
2025-12-30 11:55:02,097 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 2 captions
2025-12-30 11:55:02,097 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 2 captions
2025-12-30 11:55:02,097 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 2 captions
2025-12-30 11:55:02,098 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 2 captions
2025-12-30 12:28:35,193 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-30 12:28:35,195 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. So, the task is to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle, and 
2025-12-30 12:28:35,199 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:28:35,200 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:28:35,200 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:28:35,200 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:28:35,201 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:28:35,201 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:28:35,202 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:28:35,202 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:28:35,202 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:28:35,203 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:28:35,203 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:28:35,204 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:28:35,204 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: idle with 4 captions
2025-12-30 12:28:35,204 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 4 captions
2025-12-30 12:28:55,535 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-30 12:28:55,535 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given timestamps. The labels are work or idle, and I have to merge consecutive ones with 
2025-12-30 12:28:55,535 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:28:55,536 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:28:55,536 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:28:55,536 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-30 12:28:55,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 4 captions
2025-12-30 12:28:55,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 4 captions
2025-12-30 12:28:55,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 4 captions
2025-12-30 12:29:15,732 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-30 12:29:15,733 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given timestamps. Let me start by looking at the example provided. The example had three 
2025-12-30 12:29:15,733 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 4 captions
2025-12-30 12:29:15,733 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: idle with 4 captions
2025-12-30 12:29:50,864 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-30 12:29:50,865 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. The task is to group consecutive observations into continuous activity segments based on the timestamps provided. Each observation is a single frame, s
2025-12-30 12:29:50,867 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:29:50,868 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:29:50,869 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:29:50,870 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:29:50,872 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:29:50,873 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:28,941 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-30 12:30:28,941 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps. The labels are work or idle. The key here is to look at the times
2025-12-30 12:30:28,942 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:30:28,942 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:30:28,942 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:28,942 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:30:28,942 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:30:28,942 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:28,943 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:30:28,943 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:30:28,943 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:28,943 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:30:28,944 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:30:28,944 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:28,944 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:30:28,945 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:30:28,945 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:28,945 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:30:28,945 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:30:28,946 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:28,946 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:30:28,946 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:30:28,947 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:28,947 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:30:28,947 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:30:28,953 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:39,249 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-30 12:30:39,249 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on the given labels and rules. Let me start by understanding the 
2025-12-30 12:30:39,250 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 12:30:39,251 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 12:30:56,666 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-30 12:30:56,668 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. So, the task is to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle, and 
2025-12-30 12:30:56,675 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:30:56,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:30:56,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:56,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:30:56,678 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:30:56,679 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:56,680 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.79-5.79: work with 4 captions
2025-12-30 12:30:56,681 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-30 12:30:56,683 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 4 captions
2025-12-30 12:30:56,684 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 4 captions
2025-12-30 12:30:56,685 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.79-5.79: work with 4 captions
2025-12-30 12:31:10,041 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-30 12:31:10,042 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given labels. The example shows that if there's a same label in a row, they merge. 
2025-12-30 12:31:10,042 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2025-12-30 12:31:10,042 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 12:36:43,284 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 12:36:53,042 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-30 12:36:53,043 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given labels. Let me start by understanding the example provided.  In the example, 
2025-12-30 12:36:53,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 12:36:53,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: work with 2 captions
2025-12-30 12:36:53,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 12:36:53,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 12:36:53,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: work with 2 captions
2025-12-30 12:36:53,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 12:36:53,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 12:36:53,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: work with 2 captions
2025-12-30 12:36:53,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 12:36:53,045 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 12:36:53,953 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 12:36:58,942 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-30 12:36:58,942 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze these VLM captions and group them into continuous activity segments. The user provided a timeline with timestamps, and I have to apply the rules to merge
2025-12-30 12:36:58,942 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 12:36:58,942 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 12:36:58,942 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 12:36:58,942 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 12:36:58,943 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 12:36:58,943 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 12:36:58,943 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 12:36:58,943 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 12:36:58,943 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 12:36:59,801 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 12:37:05,147 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-30 12:37:05,147 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on their timestamps and labels. The labels are either work or idl
2025-12-30 12:37:05,148 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 12:37:05,148 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 12:37:05,148 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 12:37:05,148 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 12:37:05,149 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 12:37:05,149 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 12:37:05,149 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 12:37:05,149 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 12:37:05,149 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 12:37:06,020 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 12:37:09,118 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-30 12:37:09,118 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on their timestamps and labels. The example given has timestamps and labels, and I need to
2025-12-30 12:37:09,118 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-30.00: work with 3 captions
2025-12-30 12:37:09,120 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 2 captions
2025-12-30 12:37:11,076 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 12:37:25,269 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-30 12:37:25,269 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. Let me start by looking at the example provided. The i
2025-12-30 12:37:25,270 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-34.30: work with 1 captions
2025-12-30 12:37:25,270 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-36.40: work with 1 captions
2025-12-30 12:37:25,270 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: work with 1 captions
2025-12-30 12:37:25,270 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 1 captions
2025-12-30 12:37:26,139 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 12:37:26,279 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-30 12:37:26,279 backend.stream_processor - INFO [LLM_OUTPUT] 
2025-12-30 12:37:26,280 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 12:37:26,280 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 12:37:27,137 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 12:37:30,785 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-30 12:37:30,785 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these timestamps into continuous activity segments based on the given labels. Let me start by looking at each observation one by one.  First, the example i
2025-12-30 12:37:30,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 12:37:30,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: work with 2 captions
2025-12-30 12:37:30,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: idle with 2 captions
2025-12-30 12:37:30,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 12:37:30,786 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: work with 2 captions
2025-12-30 12:37:30,786 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: idle with 2 captions
2025-12-30 12:37:30,786 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 12:37:31,264 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 12:37:33,089 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-30 12:37:33,089 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps. Let me start by understanding the problem step by step.  First, t
2025-12-30 12:37:33,089 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2025-12-30 12:37:33,090 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 12:37:33,090 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 12:37:33,090 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 12:37:33,090 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 12:37:33,091 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 12:37:33,091 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 12:37:33,091 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 12:37:33,091 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 12:37:33,091 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 12:37:33,091 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 12:37:33,091 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 12:37:33,092 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 12:38:15,830 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 12:38:20,110 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-30 12:38:20,110 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on their timestamps and labels. The labels are either work or idle. Th
2025-12-30 12:38:20,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 1 captions
2025-12-30 12:38:20,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 12:38:20,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 12:38:20,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 12:38:20,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 12:38:20,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 12:38:20,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 12:38:20,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 12:38:20,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 12:38:20,111 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 12:38:20,111 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 12:38:21,015 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 12:38:24,104 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-30 12:38:24,105 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. Let me start by looking at the example provided.   In 
2025-12-30 12:38:24,105 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 12:38:24,105 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 12:38:24,952 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 12:38:28,505 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-30 12:38:28,506 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on the given labels. The key here is to process each observation 
2025-12-30 12:38:28,506 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 12:38:28,506 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 2 captions
2025-12-30 12:38:28,506 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 12:38:28,506 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 12:38:28,507 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 2 captions
2025-12-30 12:38:28,507 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 12:38:28,507 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 12:38:28,507 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: work with 2 captions
2025-12-30 12:38:28,507 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 12:38:28,507 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 12:38:29,376 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 12:38:32,391 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-30 12:38:32,392 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on the given labels. The input is a sequence of timestamps, and e
2025-12-30 12:38:32,392 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 12:38:32,392 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 2 captions
2025-12-30 12:38:32,392 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 12:38:32,392 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 2 captions
2025-12-30 12:38:32,392 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 12:38:32,392 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 2 captions
2025-12-30 12:38:32,393 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 12:38:33,313 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 12:38:37,101 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-30 12:38:37,101 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the timestamps provided. Each observation is a single frame, and I have to assign work or idl
2025-12-30 12:38:37,965 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 12:38:40,859 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-30 12:38:40,859 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on their timestamps and labels. Let me start by looking at the example they provided.   In the e
2025-12-30 12:38:40,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 12:38:40,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 12:38:40,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 12:38:40,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 12:38:40,860 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-30 12:38:41,752 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 12:38:45,459 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-30 12:38:45,460 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given labels and timestamps. Let me start by looking at the example they provided.   In t
2025-12-30 12:38:45,460 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 12:38:45,461 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 2 captions
2025-12-30 12:38:45,461 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 12:38:45,461 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 12:38:45,461 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 2 captions
2025-12-30 12:38:45,461 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 12:38:45,461 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 12:38:45,462 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 2 captions
2025-12-30 12:38:45,462 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 12:38:45,462 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 12:38:45,463 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 2 captions
2025-12-30 12:38:45,464 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 12:38:45,464 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-30 12:38:46,446 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 12:38:48,502 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-30 12:38:48,503 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps. The example shows that when there's a change in activity, like a 
2025-12-30 12:38:48,503 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.10: work with 2 captions
2025-12-30 12:38:48,505 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 12:38:48,505 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 12:38:48,505 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 12:38:48,505 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 12:38:48,506 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 12:38:48,506 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 12:38:48,507 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 12:38:48,508 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 12:38:48,508 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 12:38:48,509 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 12:38:48,510 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 13:04:30,109 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 13:04:35,081 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-30 13:04:35,083 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze this sequence of VLM captions and group consecutive observations into continuous activity segments. The user provided example input and output, so I shou
2025-12-30 13:04:35,085 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-6.40: work with 4 captions
2025-12-30 13:04:35,087 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 13:04:35,089 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:04:37,225 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 13:04:41,219 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-30 13:04:41,219 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given labels and timestamps. Let me start by looking at the example provided. The e
2025-12-30 13:04:41,219 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 13:04:41,219 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.80: work with 2 captions
2025-12-30 13:04:41,220 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: idle with 2 captions
2025-12-30 13:04:42,977 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 13:04:53,314 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-30 13:04:53,315 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. The example input shows that each observation is a sin
2025-12-30 13:04:53,315 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 13:04:53,315 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 2 captions
2025-12-30 13:04:53,316 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 13:04:53,316 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 2 captions
2025-12-30 13:04:53,316 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 13:04:53,316 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 2 captions
2025-12-30 13:04:53,316 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 13:04:55,169 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 13:04:59,999 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-30 13:05:00,000 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let me try to figure this out. The task is to group consecutive observations into continuous activity segments based on the labels provided. The example given shows that each observa
2025-12-30 13:05:00,000 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 13:05:00,000 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: idle with 2 captions
2025-12-30 13:05:00,001 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:05:00,001 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 13:05:00,001 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: idle with 2 captions
2025-12-30 13:05:00,001 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:05:00,001 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 13:05:00,002 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: idle with 2 captions
2025-12-30 13:05:00,002 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:05:00,002 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 13:05:00,002 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: idle with 2 captions
2025-12-30 13:05:00,002 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:05:00,003 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-30 13:05:01,808 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 13:05:06,316 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-30 13:05:06,317 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given rules. Let me start by looking at the example input and output to understand the pr
2025-12-30 13:05:08,149 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 13:05:11,567 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-30 13:05:11,568 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze these timestamped VLM captions and group consecutive observations into continuous activity segments. The labels are work or idle. So first, I should proc
2025-12-30 13:05:11,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:05:11,572 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:05:11,573 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:05:11,573 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:05:11,574 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-30 13:05:13,547 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 13:05:18,632 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-30 13:05:18,632 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on the given labels and timestamps. Let me start by understanding the 
2025-12-30 13:05:19,737 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 13:05:25,069 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-30 13:05:25,069 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. The example given has two observations, and they are m
2025-12-30 13:05:25,070 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 13:05:25,071 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 13:05:25,071 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 13:05:25,072 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 13:05:25,072 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 13:05:25,073 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 13:05:25,073 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 13:05:25,074 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 13:05:25,074 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 13:05:25,075 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 13:05:25,075 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 13:30:12,660 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 13:30:20,064 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-30 13:30:20,065 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on the given labels and timestamps. Let me start by understanding
2025-12-30 13:30:20,065 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:30:20,066 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 13:30:20,066 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:30:20,066 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:30:20,066 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 13:30:20,067 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:30:20,067 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:30:20,067 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 13:30:20,067 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:30:20,068 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:30:20,068 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 13:30:20,068 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:30:20,068 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:30:20,069 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 13:30:20,069 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:30:20,069 backend.stream_utils - INFO [PARSE_LLM] Removed 12 duplicate segment(s) in window
2025-12-30 13:30:22,573 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 13:30:34,294 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-30 13:30:34,294 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. The example shows that when there's a change in activi
2025-12-30 13:30:34,295 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 13:30:34,295 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 13:30:34,296 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 13:30:34,297 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 13:30:34,298 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 13:30:34,299 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 13:30:36,619 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 13:30:39,626 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-30 13:30:39,626 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps. The labels are work or idle. So first, I need to process each obs
2025-12-30 13:30:39,626 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-23.60: work with 4 captions
2025-12-30 13:30:39,626 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-21.40: idle with 1 captions
2025-12-30 13:30:39,626 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 1 captions
2025-12-30 13:30:42,137 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 13:30:48,698 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-30 13:30:48,698 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on their timestamps and labels. The labels are either work or idle. Th
2025-12-30 13:30:48,699 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 13:30:48,700 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.00: idle with 1 captions
2025-12-30 13:30:48,700 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:30:48,701 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 13:30:48,701 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.00: idle with 1 captions
2025-12-30 13:30:48,701 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:30:48,701 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 13:30:48,701 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.00: idle with 1 captions
2025-12-30 13:30:48,702 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:30:48,702 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 13:30:50,655 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 13:30:54,281 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-30 13:30:54,281 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze these VLM captions with timestamps and group them into continuous activity segments. Let me start by looking at the example given. The example input has 
2025-12-30 13:30:54,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 13:30:54,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: idle with 1 captions
2025-12-30 13:30:54,282 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 1 captions
2025-12-30 13:30:56,219 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 13:30:58,957 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-30 13:30:58,958 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given rules. Let me start by looking at each timestamp and the corresponding caption.  Fi
2025-12-30 13:30:58,958 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:30:58,959 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:30:58,959 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:30:58,959 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:30:58,960 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:30:58,960 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:30:58,960 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:30:58,960 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:30:58,960 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 13:31:01,104 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 13:31:04,492 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-30 13:31:04,493 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to group consecutive observations into continuous activity segments based on the given timestamps and labels. Let me start by understanding the problem s
2025-12-30 13:31:04,494 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 13:31:04,495 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 2 captions
2025-12-30 13:31:04,495 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 13:31:05,836 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 13:31:07,551 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-30 13:31:07,551 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. The example shows that if there's a same label in a ro
2025-12-30 13:31:07,551 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2025-12-30 13:31:07,551 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 13:31:07,554 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 13:31:07,554 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 13:31:07,555 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 13:31:07,555 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 13:31:07,555 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 13:31:07,556 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 13:31:07,556 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 13:31:07,556 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 13:31:07,556 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 13:31:07,557 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 13:31:07,557 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 13:37:03,793 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 13:37:08,620 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-30 13:37:08,621 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on their timestamps. The labels are work or idle. So first, I should process each observat
2025-12-30 13:37:08,621 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-30 13:37:08,622 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 1 captions
2025-12-30 13:37:08,622 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 1 captions
2025-12-30 13:37:08,622 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: work with 1 captions
2025-12-30 13:37:08,623 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-30 13:37:08,623 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 1 captions
2025-12-30 13:37:08,623 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 1 captions
2025-12-30 13:37:08,623 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: work with 1 captions
2025-12-30 13:37:08,624 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 13:37:10,765 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 13:37:13,330 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-30 13:37:13,330 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given timestamps and labels. The example shows that if there's a change in activity, they
2025-12-30 13:37:13,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 13:37:13,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 13:37:13,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 13:37:13,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 13:37:13,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 13:37:13,332 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 13:37:13,332 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 13:37:15,224 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 13:37:18,953 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-30 13:37:18,953 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given labels. The example provided has timestamps, and I need to follow the rules. 
2025-12-30 13:37:18,953 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-21.40: work with 3 captions
2025-12-30 13:37:18,954 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-21.40: work with 3 captions
2025-12-30 13:37:18,954 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-21.40: work with 3 captions
2025-12-30 13:37:18,954 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-30 13:37:20,732 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 13:37:24,713 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-30 13:37:24,713 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on the given labels. The key here is to look at the timestamps and ass
2025-12-30 13:37:24,714 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 13:37:24,714 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 2 captions
2025-12-30 13:37:27,295 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 13:37:29,627 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-30 13:37:29,627 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem step by step. So, the task is to group consecutive observations into continuous activity segments based on binary labels. The example given shows how to pro
2025-12-30 13:37:29,628 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 13:37:29,628 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 2 captions
2025-12-30 13:37:29,628 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-40.70: work with 2 captions
2025-12-30 13:37:32,118 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 13:37:34,503 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-30 13:37:34,504 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The task is to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are either work or idle. So first, I need to p
2025-12-30 13:37:34,504 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:37:34,505 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:37:34,505 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:37:34,505 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:37:34,506 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-30 13:37:36,775 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 13:37:40,884 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-30 13:37:40,884 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on the given labels and timestamps. Let me start by looking at the example provided. The input t
2025-12-30 13:37:41,916 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 13:37:44,007 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-30 13:37:44,007 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user wants me to analyze a sequence of VLM captions with timestamps and group consecutive observations into continuous activity segments. The labels are either work or
2025-12-30 13:37:44,008 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.10: work with 2 captions
2025-12-30 13:37:44,009 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 13:37:44,009 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 13:37:44,009 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 13:37:44,010 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 13:37:44,011 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 13:37:44,011 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 13:37:44,012 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 13:37:44,013 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 13:37:44,013 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 13:37:44,013 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 13:37:44,013 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 13:42:53,290 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 13:43:01,438 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed image of a man working in a facto', 'there is a man that is standing in front', 'arafed man working on a car in a factory', 'there are many people standing around a ']
2025-12-30 13:43:01,439 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle. The key here 
2025-12-30 13:43:01,439 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 1 captions
2025-12-30 13:43:01,439 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:43:01,440 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: work with 2 captions
2025-12-30 13:43:01,440 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:43:01,440 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:43:01,440 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: work with 2 captions
2025-12-30 13:43:01,440 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:43:01,440 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:43:01,440 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: work with 2 captions
2025-12-30 13:43:01,441 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:43:01,441 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 13:43:02,450 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 13:43:06,835 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a man standing in front of a co', 'there is a man that is standing in front', 'arafed man standing in a factory with a ', 'there is a man that is standing in a roo']
2025-12-30 13:43:06,835 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the given timestamps and labels. Let me start by understanding the problem step by step
2025-12-30 13:43:06,835 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 13:43:06,835 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.80: idle with 2 captions
2025-12-30 13:43:06,836 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 13:43:06,836 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 13:43:06,836 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.80: idle with 2 captions
2025-12-30 13:43:06,836 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 13:43:06,836 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 13:43:07,687 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 13:43:12,598 backend.stream_processor - INFO [LLM_INPUT] captions: ['there is a computer monitor sitting on a', 'arafed worker in a factory working on a ', 'arafed worker in a factory working on a ', 'arafed man in blue shirt standing in fro']
2025-12-30 13:43:12,599 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these timestamps into continuous activity segments. The user provided a timeline with real timestamps and wants me to apply the rules. Let me start by unde
2025-12-30 13:43:12,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: idle with 2 captions
2025-12-30 13:43:12,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 13:43:12,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: idle with 2 captions
2025-12-30 13:43:12,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 13:43:12,600 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: idle with 2 captions
2025-12-30 13:43:12,600 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 13:43:12,600 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 13:43:13,475 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 13:43:17,481 backend.stream_processor - INFO [LLM_INPUT] captions: ['there are two men standing in a room wit', 'there is a man in a blue shirt standing ', 'arafed man standing in a factory with a ', 'arafed man in a factory with a laptop an']
2025-12-30 13:43:17,481 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group consecutive observations into continuous activity segments based on the timestamps provided. The labels are work or idle. The rules are to merge consecutiv
2025-12-30 13:43:17,482 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-25.70: work with 1 captions
2025-12-30 13:43:17,482 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.80-27.80: idle with 1 captions
2025-12-30 13:43:17,482 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.00: work with 1 captions
2025-12-30 13:43:17,482 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:43:17,482 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-25.70: work with 1 captions
2025-12-30 13:43:17,482 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.80-27.80: idle with 1 captions
2025-12-30 13:43:17,482 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.00: work with 1 captions
2025-12-30 13:43:17,482 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:43:17,482 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 13:43:18,393 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 13:43:21,544 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man holding a large piece of plas', 'there is a man that is standing in a fac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask work']
2025-12-30 13:43:21,544 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's tackle this problem. So, the task is to group consecutive observations into continuous activity segments based on their labels. The labels are either work or idle. The key here
2025-12-30 13:43:21,545 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 13:43:21,545 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: idle with 1 captions
2025-12-30 13:43:21,545 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 1 captions
2025-12-30 13:43:22,432 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 13:43:27,349 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man in a factory working on a mac', 'arafed man in a factory looking at a mac', 'arafed man standing in a factory with a ', 'arafed man in a blue shirt and mask stan']
2025-12-30 13:43:27,349 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to group these observations into continuous activity segments based on their timestamps and labels. The labels are either work or idle. The key here is to merge con
2025-12-30 13:43:27,349 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-42.90: work with 1 captions
2025-12-30 13:43:27,350 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: idle with 1 captions
2025-12-30 13:43:27,350 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-47.10: idle with 1 captions
2025-12-30 13:43:27,350 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.30-49.30: work with 1 captions
2025-12-30 13:43:27,350 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-42.90: work with 1 captions
2025-12-30 13:43:27,350 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: idle with 1 captions
2025-12-30 13:43:27,351 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-47.10: idle with 1 captions
2025-12-30 13:43:27,351 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.30-49.30: work with 1 captions
2025-12-30 13:43:27,351 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-42.90: work with 1 captions
2025-12-30 13:43:27,351 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: idle with 1 captions
2025-12-30 13:43:27,351 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-47.10: idle with 1 captions
2025-12-30 13:43:27,351 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.30-49.30: work with 1 captions
2025-12-30 13:43:27,351 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-30 13:43:28,243 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 13:43:37,084 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed man standing in a factory with a ', 'arafed man in a blue shirt is walking th', 'arafed worker in a factory with a mask o', 'there is a man that is standing in a sto']
2025-12-30 13:43:37,084 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. I need to analyze these VLM captions with timestamps and group them into continuous activity segments. Let me start by looking at the example given. The example input has 
2025-12-30 13:43:37,560 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 13:43:39,841 backend.stream_processor - INFO [LLM_INPUT] captions: ['arafed worker in a factory with boxes an', 'arafed worker in a factory with a mask o']
2025-12-30 13:43:39,841 backend.stream_processor - INFO [LLM_OUTPUT] Thinking... Okay, let's see. The user provided a timeline of two observations and wants me to group them into continuous activity segments. The labels are work or idle. So first, I need to process the
2025-12-30 13:43:39,842 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 13:43:39,842 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 13:43:39,842 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 13:43:39,842 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 13:43:39,842 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 13:43:39,842 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 13:43:39,843 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 13:43:39,843 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 13:43:39,843 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 13:43:39,843 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 13:43:39,843 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 13:45:54,966 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 13:45:58,773 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:45:58,773 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 1 captions
2025-12-30 13:45:58,774 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: idle with 1 captions
2025-12-30 13:45:58,774 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:45:58,774 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 1 captions
2025-12-30 13:45:58,775 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: idle with 1 captions
2025-12-30 13:45:58,775 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 13:46:00,842 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 13:46:04,723 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 13:46:04,723 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-12.80: idle with 2 captions
2025-12-30 13:46:04,723 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 13:46:06,848 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 13:46:12,101 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 13:46:12,103 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 13:46:12,104 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 13:46:12,105 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 13:46:12,107 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 13:46:12,108 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 13:46:12,110 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 13:46:14,426 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 13:46:19,627 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-25.70: work with 1 captions
2025-12-30 13:46:19,627 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.80-27.80: work with 1 captions
2025-12-30 13:46:19,628 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.00: idle with 1 captions
2025-12-30 13:46:19,628 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:46:19,629 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-25.70: work with 1 captions
2025-12-30 13:46:19,629 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.80-27.80: work with 1 captions
2025-12-30 13:46:19,630 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.00: idle with 1 captions
2025-12-30 13:46:19,630 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:46:19,630 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-25.70: work with 1 captions
2025-12-30 13:46:19,630 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.80-27.80: work with 1 captions
2025-12-30 13:46:19,631 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.00: idle with 1 captions
2025-12-30 13:46:19,631 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-30 13:46:19,631 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-30 13:46:21,506 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 13:46:27,300 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 13:46:27,302 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 13:46:29,392 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 13:46:33,636 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:46:33,636 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:46:33,636 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.30-49.30: work with 1 captions
2025-12-30 13:46:33,637 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:46:33,637 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:46:33,637 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.30-49.30: work with 1 captions
2025-12-30 13:46:33,637 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 13:46:35,596 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 13:46:40,356 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 13:46:40,358 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 2 captions
2025-12-30 13:46:40,358 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 13:46:40,358 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 13:46:40,359 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 2 captions
2025-12-30 13:46:40,359 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 13:46:40,359 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 13:46:40,360 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 2 captions
2025-12-30 13:46:40,360 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 13:46:40,360 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 13:46:41,362 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 13:46:42,944 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.10: work with 2 captions
2025-12-30 13:46:42,945 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 13:46:42,946 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 13:46:42,946 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 13:46:42,947 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 13:46:42,947 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 13:46:42,947 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 13:46:42,948 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 13:46:42,948 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 13:46:42,948 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 13:46:42,948 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 13:46:42,948 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 13:46:42,965 backend.db - INFO [STATS] samples=23 duration=64.30 fps=30.00 work=30.00s idle=25.70s work%=46.7 idle%=40.0
2025-12-30 13:46:42,966 backend.db - INFO [STATS_SAVE] analysis=7495317e-3db5-415e-983b-8b2229d17179 duration=64.30 fps=30.00 work=30.00s idle=25.70s work%=46.7 idle%=40.0
2025-12-30 13:49:53,373 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 13:49:56,866 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:49:56,866 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:49:56,866 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:49:56,866 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:49:56,866 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:49:56,866 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:49:56,866 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 13:49:57,820 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 13:50:02,388 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-12.80: work with 1 captions
2025-12-30 13:50:02,388 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 1 captions
2025-12-30 13:50:02,388 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 1 captions
2025-12-30 13:50:02,389 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-10.70: work with 1 captions
2025-12-30 13:50:02,389 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-12.80: idle with 1 captions
2025-12-30 13:50:02,389 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 1 captions
2025-12-30 13:50:02,390 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 1 captions
2025-12-30 13:50:02,390 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-10.70: work with 1 captions
2025-12-30 13:50:02,390 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-12.80: idle with 1 captions
2025-12-30 13:50:02,390 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 1 captions
2025-12-30 13:50:02,391 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 1 captions
2025-12-30 13:50:02,391 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-10.70: work with 1 captions
2025-12-30 13:50:02,391 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-12.80: idle with 1 captions
2025-12-30 13:50:02,391 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 1 captions
2025-12-30 13:50:02,392 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-30 13:50:04,344 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 13:50:07,222 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 13:50:07,223 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: idle with 2 captions
2025-12-30 13:50:07,223 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 13:50:07,224 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 13:50:07,224 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-21.40: idle with 2 captions
2025-12-30 13:50:07,224 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 13:50:07,224 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 13:50:09,594 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 13:50:13,002 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 13:50:13,003 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: idle with 2 captions
2025-12-30 13:50:13,003 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 13:50:13,003 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: idle with 2 captions
2025-12-30 13:50:13,004 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-30 13:50:15,010 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 13:50:20,743 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 13:50:24,021 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:50:24,021 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:50:24,021 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:50:24,022 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:50:24,022 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 13:50:24,022 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: idle with 2 captions
2025-12-30 13:50:24,022 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 13:50:26,266 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 13:50:29,093 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 13:50:29,094 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 2 captions
2025-12-30 13:50:29,095 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 13:50:30,170 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 13:50:33,108 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.10: work with 2 captions
2025-12-30 13:50:33,109 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.10-62.10: idle with 1 captions
2025-12-30 13:50:33,111 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 13:50:33,111 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 13:50:33,112 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 13:50:33,112 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 13:50:33,113 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 13:50:33,113 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 13:50:33,114 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 13:50:33,114 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 13:50:33,114 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 13:50:33,115 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 13:50:33,115 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 13:50:33,117 backend.db - INFO [STATS] samples=18 duration=64.30 fps=30.00 work=40.70s idle=8.57s work%=63.3 idle%=13.3
2025-12-30 13:50:33,118 backend.db - INFO [STATS_SAVE] analysis=66c781ce-96ac-47c8-85a2-d709b1263581 duration=64.30 fps=30.00 work=40.70s idle=8.57s work%=63.3 idle%=13.3
2025-12-30 13:58:12,951 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 13:58:27,687 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:58:27,688 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:58:27,689 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 1 captions
2025-12-30 13:58:27,689 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:58:27,689 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 13:58:27,690 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:58:27,690 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:58:27,692 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 13:58:27,693 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:58:27,695 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 13:58:27,695 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: idle with 2 captions
2025-12-30 13:58:27,695 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 13:58:27,695 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-30 13:58:30,053 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 13:58:34,804 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-15.00: work with 4 captions
2025-12-30 13:58:36,559 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 13:58:39,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 13:58:39,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 13:58:39,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 13:58:39,331 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 13:58:39,332 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 13:58:39,332 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 13:58:39,332 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 13:58:41,855 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 13:58:50,800 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 13:58:54,526 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 13:58:54,527 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 2 captions
2025-12-30 13:58:54,527 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-40.70: work with 2 captions
2025-12-30 13:58:54,527 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 13:58:54,529 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 2 captions
2025-12-30 13:58:54,530 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-40.70: work with 2 captions
2025-12-30 13:58:54,531 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 13:58:56,585 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 13:59:03,117 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 13:59:03,121 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 13:59:05,459 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 13:59:08,142 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 13:59:08,142 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 2 captions
2025-12-30 13:59:08,142 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 13:59:09,448 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 13:59:13,481 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2025-12-30 13:59:13,483 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 13:59:13,490 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 13:59:13,491 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 13:59:13,493 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 13:59:13,494 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 13:59:13,494 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 13:59:13,495 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 13:59:13,495 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 13:59:13,496 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 13:59:13,497 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 13:59:13,498 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 13:59:13,498 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 13:59:13,525 backend.db - INFO [STATS] samples=24 duration=64.30 fps=30.00 work=17.13s idle=10.67s work%=26.6 idle%=16.6
2025-12-30 13:59:13,526 backend.db - INFO [STATS_SAVE] analysis=cff7ff93-1665-43f8-bc15-e04b9de26ef2 duration=64.30 fps=30.00 work=17.13s idle=10.67s work%=26.6 idle%=16.6
2025-12-30 14:07:56,334 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 14:08:00,228 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 1 captions
2025-12-30 14:08:01,161 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 14:08:04,963 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 14:08:04,964 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-12.80: idle with 1 captions
2025-12-30 14:08:04,964 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 1 captions
2025-12-30 14:08:07,094 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 14:08:16,278 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 1 captions
2025-12-30 14:08:16,278 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-19.30: idle with 1 captions
2025-12-30 14:08:16,278 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-21.40: work with 1 captions
2025-12-30 14:08:16,278 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 1 captions
2025-12-30 14:08:16,279 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 1 captions
2025-12-30 14:08:16,279 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-19.30: idle with 1 captions
2025-12-30 14:08:16,279 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-21.40: work with 1 captions
2025-12-30 14:08:16,279 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 1 captions
2025-12-30 14:08:16,279 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 1 captions
2025-12-30 14:08:16,280 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-19.30: idle with 1 captions
2025-12-30 14:08:16,280 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-21.40: work with 1 captions
2025-12-30 14:08:16,280 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 1 captions
2025-12-30 14:08:16,280 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 1 captions
2025-12-30 14:08:16,280 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-19.30: idle with 1 captions
2025-12-30 14:08:16,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-21.40: work with 1 captions
2025-12-30 14:08:16,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 1 captions
2025-12-30 14:08:16,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 1 captions
2025-12-30 14:08:16,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-19.30: idle with 1 captions
2025-12-30 14:08:16,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-21.40: work with 1 captions
2025-12-30 14:08:16,282 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 1 captions
2025-12-30 14:08:16,282 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 1 captions
2025-12-30 14:08:16,282 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-19.30: idle with 1 captions
2025-12-30 14:08:16,282 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-21.40: work with 1 captions
2025-12-30 14:08:16,282 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 1 captions
2025-12-30 14:08:16,283 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 1 captions
2025-12-30 14:08:16,283 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-19.30: idle with 1 captions
2025-12-30 14:08:16,283 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-21.40: work with 1 captions
2025-12-30 14:08:16,283 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 1 captions
2025-12-30 14:08:16,283 backend.stream_utils - INFO [PARSE_LLM] Removed 24 duplicate segment(s) in window
2025-12-30 14:08:17,991 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 14:08:22,687 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 14:08:22,690 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.80-30.00: idle with 2 captions
2025-12-30 14:08:22,691 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 2 captions
2025-12-30 14:08:22,691 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 14:08:22,691 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.80-30.00: idle with 2 captions
2025-12-30 14:08:22,691 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 2 captions
2025-12-30 14:08:22,691 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-27.80: work with 2 captions
2025-12-30 14:08:22,692 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.80-30.00: idle with 2 captions
2025-12-30 14:08:22,692 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-32.10: work with 2 captions
2025-12-30 14:08:22,692 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 14:08:25,153 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 14:08:33,137 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 14:08:35,392 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 14:08:35,393 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 14:08:37,298 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 14:08:39,391 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 14:08:39,391 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: idle with 2 captions
2025-12-30 14:08:40,602 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 14:08:42,508 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2025-12-30 14:08:42,508 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 14:08:42,509 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 14:08:42,511 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 14:08:42,511 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 14:08:42,511 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 14:08:42,511 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 14:08:42,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 14:08:42,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 14:08:42,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 14:08:42,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 14:08:42,513 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 14:08:42,513 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 14:08:42,514 backend.db - INFO [STATS] samples=16 duration=64.30 fps=30.00 work=10.70s idle=34.27s work%=16.6 idle%=53.3
2025-12-30 14:08:42,515 backend.db - INFO [STATS_SAVE] analysis=b4cbecb6-bf05-4c7c-bb6a-b748e459bbeb duration=64.30 fps=30.00 work=10.70s idle=34.27s work%=16.6 idle%=53.3
2025-12-30 15:07:44,953 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 15:07:54,459 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 15:07:54,459 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: idle with 2 captions
2025-12-30 15:07:54,459 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 15:07:54,460 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: idle with 2 captions
2025-12-30 15:07:54,460 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 15:07:54,460 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: idle with 2 captions
2025-12-30 15:07:54,460 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 15:07:56,631 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 15:08:06,597 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 1 captions
2025-12-30 15:08:06,597 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-10.70: work with 1 captions
2025-12-30 15:08:06,598 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 1 captions
2025-12-30 15:08:06,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-10.70: work with 1 captions
2025-12-30 15:08:06,600 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 1 captions
2025-12-30 15:08:06,601 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-10.70: work with 1 captions
2025-12-30 15:08:06,601 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 1 captions
2025-12-30 15:08:06,602 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-10.70: work with 1 captions
2025-12-30 15:08:06,603 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 1 captions
2025-12-30 15:08:06,604 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-10.70: work with 1 captions
2025-12-30 15:08:06,605 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-12.80: idle with 1 captions
2025-12-30 15:08:06,605 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 1 captions
2025-12-30 15:08:06,607 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-30 15:08:08,784 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 15:08:12,699 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-21.40: work with 3 captions
2025-12-30 15:08:12,699 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 1 captions
2025-12-30 15:08:15,320 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 15:08:24,182 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 15:08:34,641 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 15:08:34,643 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-40.70: work with 2 captions
2025-12-30 15:08:34,644 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 15:08:34,644 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-40.70: work with 2 captions
2025-12-30 15:08:34,645 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 15:08:34,645 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-40.70: work with 2 captions
2025-12-30 15:08:34,645 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 15:08:36,772 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 15:08:44,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 15:08:44,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-47.10: work with 3 captions
2025-12-30 15:08:44,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-49.30: work with 4 captions
2025-12-30 15:08:44,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 15:08:44,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-47.10: work with 3 captions
2025-12-30 15:08:44,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-49.30: work with 4 captions
2025-12-30 15:08:44,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 15:08:44,723 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-47.10: work with 3 captions
2025-12-30 15:08:44,723 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-49.30: work with 4 captions
2025-12-30 15:08:44,724 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 15:08:44,724 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-47.10: work with 3 captions
2025-12-30 15:08:44,724 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-49.30: work with 4 captions
2025-12-30 15:08:44,724 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-30 15:08:46,798 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 15:08:53,900 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 15:08:53,900 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 15:08:53,900 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 15:08:53,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 15:08:53,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 15:08:53,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 15:08:53,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 15:08:53,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 15:08:53,901 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 15:08:54,972 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 15:09:00,930 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2025-12-30 15:09:00,930 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 15:09:00,931 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 15:09:00,932 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 15:09:00,932 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 15:09:00,932 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 15:09:00,932 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 15:09:00,932 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 15:09:00,932 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 15:09:00,932 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 15:09:00,933 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 15:09:00,933 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 15:09:00,933 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 15:09:00,957 backend.db - INFO [STATS] samples=16 duration=64.30 fps=30.00 work=25.73s idle=10.73s work%=40.0 idle%=16.7
2025-12-30 15:09:00,957 backend.db - INFO [STATS_SAVE] analysis=86b78acf-4433-4329-a5a3-0e6b833933c2 duration=64.30 fps=30.00 work=25.73s idle=10.73s work%=40.0 idle%=16.7
2025-12-30 15:09:00,961 backend.db - INFO [DB_SAVE] analysis 86b78acf-4433-4329-a5a3-0e6b833933c2 saved to database
2025-12-30 15:09:00,961 backend.db - INFO [DB_SAVE] analysis 86b78acf-4433-4329-a5a3-0e6b833933c2 saving 30 samples to database
2025-12-30 15:09:00,963 backend.db - INFO [DB_SAVE] analysis 86b78acf-4433-4329-a5a3-0e6b833933c2 samples saved to database
2025-12-30 15:09:00,963 backend.db - INFO [DB_SAVE] analysis 86b78acf-4433-4329-a5a3-0e6b833933c2 saving 16 segments to database
2025-12-30 15:09:00,965 backend.db - INFO [DB_SAVE_COMPLETE] analysis 86b78acf-4433-4329-a5a3-0e6b833933c2 saved to database
2025-12-30 16:01:42,405 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 16:01:51,123 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 16:01:51,124 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: idle with 1 captions
2025-12-30 16:01:51,124 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: work with 1 captions
2025-12-30 16:01:51,125 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-30 16:01:51,125 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 1 captions
2025-12-30 16:01:51,125 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 1 captions
2025-12-30 16:01:51,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-30 16:01:51,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 1 captions
2025-12-30 16:01:51,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 1 captions
2025-12-30 16:01:51,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-30 16:01:51,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 1 captions
2025-12-30 16:01:51,127 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 1 captions
2025-12-30 16:01:51,127 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: idle with 1 captions
2025-12-30 16:01:51,127 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-30 16:01:51,127 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 1 captions
2025-12-30 16:01:51,128 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 1 captions
2025-12-30 16:01:51,128 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: idle with 1 captions
2025-12-30 16:01:51,128 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-30 16:01:51,128 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 1 captions
2025-12-30 16:01:51,129 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-4.30: work with 1 captions
2025-12-30 16:01:51,129 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: idle with 1 captions
2025-12-30 16:01:51,129 backend.stream_utils - INFO [PARSE_LLM] Removed 14 duplicate segment(s) in window
2025-12-30 16:01:53,199 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 16:01:58,393 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 16:01:58,394 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 16:01:58,394 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 16:01:58,394 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 16:01:58,395 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 16:01:58,395 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 16:01:58,395 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 16:01:58,395 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 16:01:58,395 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 16:01:58,396 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 16:01:58,396 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 16:01:58,396 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 16:01:58,397 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 16:01:58,397 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: work with 2 captions
2025-12-30 16:01:58,397 backend.stream_utils - INFO [PARSE_LLM] Removed 12 duplicate segment(s) in window
2025-12-30 16:02:00,409 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 16:02:03,256 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 16:02:03,256 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 16:02:03,256 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 16:02:03,257 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: work with 2 captions
2025-12-30 16:02:03,257 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-30 16:02:05,210 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 16:02:07,965 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 16:02:07,965 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 25.7-27.8: two men...
30.0-30.0: man in blue shirt...
32.1-32.1: arafed man in factory...
25.7-27.8: two men...
30.0-30.0: man in blue shirt...
32.1-32.1: arafed man in factory...
25.7-27.8: two men i
2025-12-30 16:02:09,727 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 16:02:13,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 16:02:13,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 2 captions
2025-12-30 16:02:13,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-40.70: work with 2 captions
2025-12-30 16:02:13,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 16:02:13,282 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.40-38.60: idle with 2 captions
2025-12-30 16:02:13,282 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-40.70: work with 2 captions
2025-12-30 16:02:13,282 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 16:02:15,180 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 16:02:18,591 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.90-45.00: work with 2 captions
2025-12-30 16:02:18,592 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-49.30: work with 2 captions
2025-12-30 16:02:20,503 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 16:02:24,884 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 16:02:24,885 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: idle with 1 captions
2025-12-30 16:02:24,885 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 1 captions
2025-12-30 16:02:24,886 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 16:02:24,886 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: idle with 1 captions
2025-12-30 16:02:24,886 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 1 captions
2025-12-30 16:02:24,887 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 16:02:25,863 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 16:02:28,288 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2025-12-30 16:02:28,289 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 16:02:28,296 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 16:02:28,297 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 16:02:28,299 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 16:02:28,302 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 16:02:28,303 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 16:02:28,304 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 16:02:28,305 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 16:02:28,306 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 16:02:28,307 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 16:02:28,308 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 16:02:28,308 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 16:02:28,332 backend.db - INFO [STATS] samples=24 duration=64.30 fps=30.00 work=36.43s idle=19.30s work%=56.7 idle%=30.0
2025-12-30 16:02:28,333 backend.db - INFO [STATS_SAVE] analysis=68c7f8f5-410d-46c9-8ca7-927d9d5c3f39 duration=64.30 fps=30.00 work=36.43s idle=19.30s work%=56.7 idle%=30.0
2025-12-30 16:02:28,342 backend.db - INFO [DB_SAVE] analysis 68c7f8f5-410d-46c9-8ca7-927d9d5c3f39 saved to database
2025-12-30 16:02:28,343 backend.db - INFO [DB_SAVE] analysis 68c7f8f5-410d-46c9-8ca7-927d9d5c3f39 saving 30 samples to database
2025-12-30 16:02:28,344 backend.db - INFO [DB_SAVE] analysis 68c7f8f5-410d-46c9-8ca7-927d9d5c3f39 samples saved to database
2025-12-30 16:02:28,344 backend.db - INFO [DB_SAVE] analysis 68c7f8f5-410d-46c9-8ca7-927d9d5c3f39 saving 21 segments to database
2025-12-30 16:02:28,346 backend.db - INFO [DB_SAVE_COMPLETE] analysis 68c7f8f5-410d-46c9-8ca7-927d9d5c3f39 saved to database
2025-12-30 16:21:35,652 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.40s with 4 samples
2025-12-30 16:21:51,619 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 1 captions
2025-12-30 16:21:51,619 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 1 captions
2025-12-30 16:21:51,619 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.10: work with 2 captions
2025-12-30 16:21:51,619 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-4.30: work with 2 captions
2025-12-30 16:21:51,619 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.30-6.40: work with 2 captions
2025-12-30 16:21:51,620 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-30 16:21:53,544 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2025-12-30 16:21:57,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 16:21:57,679 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: idle with 2 captions
2025-12-30 16:21:57,679 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 16:21:57,679 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: idle with 2 captions
2025-12-30 16:21:57,680 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 16:21:57,680 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: idle with 2 captions
2025-12-30 16:21:57,680 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-10.70: work with 2 captions
2025-12-30 16:21:57,680 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-15.00: idle with 2 captions
2025-12-30 16:21:57,681 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 16:21:59,438 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-30 16:22:04,502 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 16:22:04,502 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 2 captions
2025-12-30 16:22:04,502 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-21.40: work with 3 captions
2025-12-30 16:22:04,502 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: idle with 1 captions
2025-12-30 16:22:04,503 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 16:22:04,503 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 2 captions
2025-12-30 16:22:04,503 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 16:22:04,503 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 2 captions
2025-12-30 16:22:04,506 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-19.30: work with 2 captions
2025-12-30 16:22:04,506 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.40-23.60: idle with 2 captions
2025-12-30 16:22:04,506 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 16:22:06,284 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.13s with 4 samples
2025-12-30 16:22:17,987 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.70s with 4 samples
2025-12-30 16:22:21,615 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 16:22:21,615 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: idle with 1 captions
2025-12-30 16:22:21,616 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 1 captions
2025-12-30 16:22:21,616 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.30-36.40: work with 2 captions
2025-12-30 16:22:21,616 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: idle with 1 captions
2025-12-30 16:22:21,616 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.70: work with 1 captions
2025-12-30 16:22:21,616 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 16:22:23,457 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.27s with 4 samples
2025-12-30 16:22:26,746 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 16:22:26,746 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 16:22:28,681 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.87s with 4 samples
2025-12-30 16:22:33,069 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.40-53.60: work with 2 captions
2025-12-30 16:22:33,069 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-55.70: idle with 2 captions
2025-12-30 16:22:33,069 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-57.90: work with 2 captions
2025-12-30 16:22:34,093 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-30 16:22:35,741 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2025-12-30 16:22:35,742 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 16:22:35,748 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-30 16:22:35,748 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-30 16:22:35,749 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.1333333333333333, 'there is a man that is standing in front'), (4.266666666666667, 'arafed man working on a car in a factory'), (6.4, 'there are many people standing around a '), (8.566666666666666, 'there is a man standing in front of a co'), (10.7, 'there is a man that is standing in front'), (12.833333333333334, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.133333333333333, 'there is a computer monitor sitting on a'), (19.266666666666666, 'arafed worker in a factory working on a ')]...
2025-12-30 16:22:35,749 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.1s: there is a man that is sta...
2025-12-30 16:22:35,749 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=15.0: 4 samples, timeline=t=8.6s: there is a man standing in front of a counter with bottles of wine
t=10.7s: there is a man t...
2025-12-30 16:22:35,749 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=23.566666666666666: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=19.3s: arafed worker in a factory...
2025-12-30 16:22:35,750 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=32.13333333333333: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=27.8s: there is a man in a blue shirt ...
2025-12-30 16:22:35,750 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=40.7: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=36.4s: there is a man that is stand...
2025-12-30 16:22:35,750 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=49.266666666666666: 4 samples, timeline=t=42.9s: arafed man in a factory working on a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-30 16:22:35,751 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=57.86666666666667: 4 samples, timeline=t=51.4s: arafed man standing in a factory with a lot of machines
t=53.6s: arafed man in a blue shirt...
2025-12-30 16:22:35,753 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.1s: arafed worker in a factory wit...
2025-12-30 16:22:35,812 backend.db - INFO [STATS] samples=22 duration=64.30 fps=30.00 work=10.67s idle=12.83s unclass=40.80s work%=16.6 idle%=20.0 unclass%=63.5
2025-12-30 16:22:35,815 backend.db - INFO [STATS_SAVE] analysis=522f88d6-1991-41fa-9ec3-7ed822764b71 duration=64.30 fps=30.00 work=10.67s idle=12.83s unclass=40.80s work%=16.6 idle%=20.0 unclass%=63.5
2025-12-30 16:22:35,827 backend.db - INFO [DB_SAVE] analysis 522f88d6-1991-41fa-9ec3-7ed822764b71 saved to database
2025-12-30 16:22:35,830 backend.db - INFO [DB_SAVE] analysis 522f88d6-1991-41fa-9ec3-7ed822764b71 saving 30 samples to database
2025-12-30 16:22:35,832 backend.db - INFO [DB_SAVE] analysis 522f88d6-1991-41fa-9ec3-7ed822764b71 samples saved to database
2025-12-30 16:22:35,832 backend.db - INFO [DB_SAVE] analysis 522f88d6-1991-41fa-9ec3-7ed822764b71 saving 18 segments to database
2025-12-30 16:22:35,835 backend.db - INFO [DB_SAVE_COMPLETE] analysis 522f88d6-1991-41fa-9ec3-7ed822764b71 saved to database
2025-12-30 16:31:53,409 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.00s with 4 samples
2025-12-30 16:31:59,226 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.00: work with 2 captions
2025-12-30 16:31:59,227 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-6.00: work with 2 captions
2025-12-30 16:32:01,802 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.00s with 4 samples
2025-12-30 16:32:06,799 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-10.00: idle with 2 captions
2025-12-30 16:32:06,799 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-12.00: work with 2 captions
2025-12-30 16:32:06,799 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-14.00: work with 2 captions
2025-12-30 16:32:06,799 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-10.00: idle with 2 captions
2025-12-30 16:32:06,800 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-12.00: work with 2 captions
2025-12-30 16:32:06,800 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-14.00: work with 2 captions
2025-12-30 16:32:06,800 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-10.00: idle with 2 captions
2025-12-30 16:32:06,800 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-12.00: work with 2 captions
2025-12-30 16:32:06,800 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-14.00: work with 2 captions
2025-12-30 16:32:06,800 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 16:32:08,392 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.00s with 4 samples
2025-12-30 16:32:22,668 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.00s with 4 samples
2025-12-30 16:32:28,872 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-30 16:32:28,872 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.00-28.00: idle with 2 captions
2025-12-30 16:32:28,872 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-30 16:32:28,872 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-30 16:32:28,873 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.00-28.00: idle with 2 captions
2025-12-30 16:32:28,873 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-30 16:32:28,873 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 16:32:30,716 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.00s with 4 samples
2025-12-30 16:32:38,225 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.00s with 4 samples
2025-12-30 16:32:41,801 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-42.00: work with 2 captions
2025-12-30 16:32:41,803 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.00-46.00: work with 2 captions
2025-12-30 16:32:41,805 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-42.00: work with 2 captions
2025-12-30 16:32:41,806 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.00-46.00: work with 2 captions
2025-12-30 16:32:41,807 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-30 16:32:43,903 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.00s with 4 samples
2025-12-30 16:32:50,151 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.00s with 4 samples
2025-12-30 16:32:52,921 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 16:32:52,922 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 16:32:53,495 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2025-12-30 16:32:56,278 backend.stream_utils - INFO [PARSE_LLM] Created segment 64.00-64.00: work with 1 captions
2025-12-30 16:32:56,279 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 33
2025-12-30 16:32:56,280 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 9
2025-12-30 16:32:56,280 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.0, 'someone is working on a laptop with a lo'), (4.0, 'arafed worker working on a machine in a '), (6.0, 'arafed man standing in a factory with a '), (8.0, 'there is a man standing in front of a co'), (10.0, 'someone is holding a cat in a glove whil'), (12.0, 'arafed man standing in a factory with a '), (14.0, 'arafed worker working on a machine in a '), (16.0, 'there is a truck that is parked in a gar'), (18.0, 'there is a computer monitor sitting on a')]...
2025-12-30 16:32:56,280 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.0s: someone is working on a la...
2025-12-30 16:32:56,280 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=14.0: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=10.0s: someone is ho...
2025-12-30 16:32:56,281 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=22.0: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=18.0s: there is a computer monitor sitting on...
2025-12-30 16:32:56,281 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=30.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=26.0s: there are people standing in a bus with ...
2025-12-30 16:32:56,281 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=38.0: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=34.0s: arafed man in a factory holding a ...
2025-12-30 16:32:56,281 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=46.0: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.0s: arafed man in a blue shirt...
2025-12-30 16:32:56,282 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=54.0: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=50.0s: arafed man in a factory wi...
2025-12-30 16:32:56,282 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=62.0: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=58.0s: there is a man that is standing in a sto...
2025-12-30 16:32:56,282 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2025-12-30 16:32:56,283 backend.db - INFO [STATS] samples=21 duration=64.30 fps=30.00 work=16.00s idle=8.00s unclass=40.30s work%=24.9 idle%=12.4 unclass%=62.7
2025-12-30 16:32:56,283 backend.db - INFO [STATS_SAVE] analysis=be965296-b183-446f-b853-f66046875009 duration=64.30 fps=30.00 work=16.00s idle=8.00s unclass=40.30s work%=24.9 idle%=12.4 unclass%=62.7
2025-12-30 16:32:56,285 backend.db - INFO [DB_SAVE] analysis be965296-b183-446f-b853-f66046875009 saved to database
2025-12-30 16:32:56,286 backend.db - INFO [DB_SAVE] analysis be965296-b183-446f-b853-f66046875009 saving 33 samples to database
2025-12-30 16:32:56,286 backend.db - INFO [DB_SAVE] analysis be965296-b183-446f-b853-f66046875009 samples saved to database
2025-12-30 16:32:56,286 backend.db - INFO [DB_SAVE] analysis be965296-b183-446f-b853-f66046875009 saving 12 segments to database
2025-12-30 16:32:56,287 backend.db - INFO [DB_SAVE_COMPLETE] analysis be965296-b183-446f-b853-f66046875009 saved to database
2025-12-30 16:33:48,408 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.00s with 4 samples
2025-12-30 16:33:54,442 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 1 captions
2025-12-30 16:33:54,442 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.00: work with 2 captions
2025-12-30 16:33:54,442 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-4.00: work with 2 captions
2025-12-30 16:33:54,442 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-6.00: idle with 2 captions
2025-12-30 16:33:54,442 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.00: work with 2 captions
2025-12-30 16:33:54,443 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-4.00: work with 2 captions
2025-12-30 16:33:54,443 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-6.00: idle with 2 captions
2025-12-30 16:33:54,443 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.00: work with 2 captions
2025-12-30 16:33:54,443 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-4.00: work with 2 captions
2025-12-30 16:33:54,443 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-6.00: idle with 2 captions
2025-12-30 16:33:54,444 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 16:33:56,257 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.00s with 4 samples
2025-12-30 16:34:01,414 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-10.00: work with 2 captions
2025-12-30 16:34:01,419 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-14.00: work with 2 captions
2025-12-30 16:34:01,421 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-10.00: work with 2 captions
2025-12-30 16:34:01,422 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-14.00: work with 2 captions
2025-12-30 16:34:01,423 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-10.00: work with 2 captions
2025-12-30 16:34:01,423 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-14.00: work with 2 captions
2025-12-30 16:34:01,424 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-30 16:34:03,208 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.00s with 4 samples
2025-12-30 16:34:08,876 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-18.00: work with 2 captions
2025-12-30 16:34:08,876 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-22.00: work with 2 captions
2025-12-30 16:34:08,877 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-18.00: work with 2 captions
2025-12-30 16:34:08,877 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-22.00: work with 2 captions
2025-12-30 16:34:08,877 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-18.00: work with 2 captions
2025-12-30 16:34:08,877 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-22.00: work with 2 captions
2025-12-30 16:34:08,877 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-18.00: work with 2 captions
2025-12-30 16:34:08,877 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-22.00: work with 2 captions
2025-12-30 16:34:08,878 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 16:34:10,775 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.00s with 4 samples
2025-12-30 16:34:14,792 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-30 16:34:14,793 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-30 16:34:14,794 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-30 16:34:14,794 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-30 16:34:14,794 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-30 16:34:16,644 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.00s with 4 samples
2025-12-30 16:34:22,126 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.00s with 4 samples
2025-12-30 16:34:26,335 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-42.00: work with 2 captions
2025-12-30 16:34:26,336 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.00-46.00: work with 2 captions
2025-12-30 16:34:28,368 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.00s with 4 samples
2025-12-30 16:34:37,851 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.00s with 4 samples
2025-12-30 16:34:43,951 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-58.00: work with 2 captions
2025-12-30 16:34:43,951 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.00-60.00: idle with 2 captions
2025-12-30 16:34:43,952 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.00: work with 2 captions
2025-12-30 16:34:44,603 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2025-12-30 16:34:50,614 backend.stream_utils - INFO [PARSE_LLM] Created segment 64.00-64.00: work with 1 captions
2025-12-30 16:34:50,614 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 33
2025-12-30 16:34:50,614 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 9
2025-12-30 16:34:50,614 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.0, 'someone is working on a laptop with a lo'), (4.0, 'arafed worker working on a machine in a '), (6.0, 'arafed man standing in a factory with a '), (8.0, 'there is a man standing in front of a co'), (10.0, 'someone is holding a cat in a glove whil'), (12.0, 'arafed man standing in a factory with a '), (14.0, 'arafed worker working on a machine in a '), (16.0, 'there is a truck that is parked in a gar'), (18.0, 'there is a computer monitor sitting on a')]...
2025-12-30 16:34:50,614 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.0s: someone is working on a la...
2025-12-30 16:34:50,614 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=14.0: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=10.0s: someone is ho...
2025-12-30 16:34:50,615 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=22.0: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=18.0s: there is a computer monitor sitting on...
2025-12-30 16:34:50,615 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=30.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=26.0s: there are people standing in a bus with ...
2025-12-30 16:34:50,615 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=38.0: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=34.0s: arafed man in a factory holding a ...
2025-12-30 16:34:50,615 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=46.0: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.0s: arafed man in a blue shirt...
2025-12-30 16:34:50,615 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=54.0: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=50.0s: arafed man in a factory wi...
2025-12-30 16:34:50,615 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=62.0: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=58.0s: there is a man that is standing in a sto...
2025-12-30 16:34:50,615 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2025-12-30 16:34:50,616 backend.db - INFO [STATS] samples=25 duration=64.30 fps=30.00 work=36.00s idle=0.00s unclass=28.30s work%=56.0 idle%=0.0 unclass%=44.0
2025-12-30 16:34:50,616 backend.db - INFO [STATS_SAVE] analysis=7c479ff6-9bd1-4d8f-b0fb-a3c2cce4fc1c duration=64.30 fps=30.00 work=36.00s idle=0.00s unclass=28.30s work%=56.0 idle%=0.0 unclass%=44.0
2025-12-30 16:34:50,617 backend.db - INFO [DB_SAVE] analysis 7c479ff6-9bd1-4d8f-b0fb-a3c2cce4fc1c saved to database
2025-12-30 16:34:50,617 backend.db - INFO [DB_SAVE] analysis 7c479ff6-9bd1-4d8f-b0fb-a3c2cce4fc1c saving 33 samples to database
2025-12-30 16:34:50,617 backend.db - INFO [DB_SAVE] analysis 7c479ff6-9bd1-4d8f-b0fb-a3c2cce4fc1c samples saved to database
2025-12-30 16:34:50,617 backend.db - INFO [DB_SAVE] analysis 7c479ff6-9bd1-4d8f-b0fb-a3c2cce4fc1c saving 16 segments to database
2025-12-30 16:34:50,618 backend.db - INFO [DB_SAVE_COMPLETE] analysis 7c479ff6-9bd1-4d8f-b0fb-a3c2cce4fc1c saved to database
2025-12-30 16:40:42,020 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.00s with 4 samples
2025-12-30 16:40:47,626 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.00: work with 2 captions
2025-12-30 16:40:47,627 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-4.00: idle with 2 captions
2025-12-30 16:40:47,628 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-6.00: work with 2 captions
2025-12-30 16:40:47,628 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-2.00: work with 2 captions
2025-12-30 16:40:47,629 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-4.00: idle with 2 captions
2025-12-30 16:40:47,630 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-6.00: work with 2 captions
2025-12-30 16:40:47,630 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-30 16:40:49,630 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.00s with 4 samples
2025-12-30 16:40:56,323 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.00s with 4 samples
2025-12-30 16:40:58,690 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-18.00: work with 2 captions
2025-12-30 16:40:58,690 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-22.00: work with 2 captions
2025-12-30 16:41:00,527 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.00s with 4 samples
2025-12-30 16:41:05,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-30 16:41:05,192 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-30 16:41:05,192 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-30 16:41:05,193 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-30 16:41:05,193 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-30 16:41:05,193 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-30 16:41:05,194 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-30 16:41:05,194 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-30 16:41:05,194 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-26.00: work with 2 captions
2025-12-30 16:41:05,195 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-30.00: work with 2 captions
2025-12-30 16:41:05,195 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-30 16:41:07,348 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.00s with 4 samples
2025-12-30 16:41:13,620 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.00s with 4 samples
2025-12-30 16:41:24,427 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-42.00: work with 2 captions
2025-12-30 16:41:24,427 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.00-44.00: work with 1 captions
2025-12-30 16:41:24,427 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-46.00: work with 4 captions
2025-12-30 16:41:24,428 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-46.00: work with 4 captions
2025-12-30 16:41:24,428 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-46.00: work with 4 captions
2025-12-30 16:41:24,428 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-46.00: work with 4 captions
2025-12-30 16:41:24,428 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-42.00: work with 2 captions
2025-12-30 16:41:24,429 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.00-44.00: work with 1 captions
2025-12-30 16:41:24,430 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.00-46.00: work with 1 captions
2025-12-30 16:41:24,430 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-46.00: work with 4 captions
2025-12-30 16:41:24,430 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-46.00: work with 4 captions
2025-12-30 16:41:24,430 backend.stream_utils - INFO [PARSE_LLM] Removed 7 duplicate segment(s) in window
2025-12-30 16:41:26,688 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.00s with 4 samples
2025-12-30 16:41:38,792 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.00s with 4 samples
2025-12-30 16:41:44,993 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-60.00: work with 3 captions
2025-12-30 16:41:44,994 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.00-62.00: work with 1 captions
2025-12-30 16:41:44,995 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-60.00: work with 3 captions
2025-12-30 16:41:44,995 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.00-62.00: work with 1 captions
2025-12-30 16:41:44,995 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.00-58.00: idle with 1 captions
2025-12-30 16:41:44,996 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-60.00: idle with 1 captions
2025-12-30 16:41:44,996 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.00-62.00: work with 1 captions
2025-12-30 16:41:44,997 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-58.00: work with 2 captions
2025-12-30 16:41:44,997 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.00: work with 2 captions
2025-12-30 16:41:44,997 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-58.00: work with 2 captions
2025-12-30 16:41:44,997 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.00: work with 2 captions
2025-12-30 16:41:44,997 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-58.00: work with 2 captions
2025-12-30 16:41:44,998 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.00: work with 2 captions
2025-12-30 16:41:44,998 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-58.00: work with 2 captions
2025-12-30 16:41:44,998 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.00: work with 2 captions
2025-12-30 16:41:44,998 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-58.00: work with 2 captions
2025-12-30 16:41:44,998 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-62.00: work with 2 captions
2025-12-30 16:41:44,999 backend.stream_utils - INFO [PARSE_LLM] Removed 11 duplicate segment(s) in window
2025-12-30 16:41:45,484 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2025-12-30 16:41:47,477 backend.stream_utils - INFO [PARSE_LLM] Created segment 64.00-64.00: work with 1 captions
2025-12-30 16:41:47,479 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 33
2025-12-30 16:41:47,479 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 9
2025-12-30 16:41:47,479 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.0, 'someone is working on a laptop with a lo'), (4.0, 'arafed worker working on a machine in a '), (6.0, 'arafed man standing in a factory with a '), (8.0, 'there is a man standing in front of a co'), (10.0, 'someone is holding a cat in a glove whil'), (12.0, 'arafed man standing in a factory with a '), (14.0, 'arafed worker working on a machine in a '), (16.0, 'there is a truck that is parked in a gar'), (18.0, 'there is a computer monitor sitting on a')]...
2025-12-30 16:41:47,479 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.0s: someone is working on a la...
2025-12-30 16:41:47,479 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=14.0: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=10.0s: someone is ho...
2025-12-30 16:41:47,480 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=22.0: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=18.0s: there is a computer monitor sitting on...
2025-12-30 16:41:47,480 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=30.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=26.0s: there are people standing in a bus with ...
2025-12-30 16:41:47,480 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=38.0: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=34.0s: arafed man in a factory holding a ...
2025-12-30 16:41:47,480 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=46.0: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.0s: arafed man in a blue shirt...
2025-12-30 16:41:47,480 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=54.0: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=50.0s: arafed man in a factory wi...
2025-12-30 16:41:47,480 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=62.0: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=58.0s: there is a man that is standing in a sto...
2025-12-30 16:41:47,481 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2025-12-30 16:41:47,481 backend.db - INFO [STATS] samples=21 duration=64.30 fps=30.00 work=30.00s idle=0.00s unclass=34.30s work%=46.7 idle%=0.0 unclass%=53.3
2025-12-30 16:41:47,482 backend.db - INFO [STATS_SAVE] analysis=f27a7dda-39ac-4e19-b721-56e5dffe475e duration=64.30 fps=30.00 work=30.00s idle=0.00s unclass=34.30s work%=46.7 idle%=0.0 unclass%=53.3
2025-12-30 16:41:47,486 backend.db - INFO [DB_SAVE] analysis f27a7dda-39ac-4e19-b721-56e5dffe475e saved to database
2025-12-30 16:41:47,487 backend.db - INFO [DB_SAVE] analysis f27a7dda-39ac-4e19-b721-56e5dffe475e saving 33 samples to database
2025-12-30 16:41:47,489 backend.db - INFO [DB_SAVE] analysis f27a7dda-39ac-4e19-b721-56e5dffe475e samples saved to database
2025-12-30 16:41:47,489 backend.db - INFO [DB_SAVE] analysis f27a7dda-39ac-4e19-b721-56e5dffe475e saving 18 segments to database
2025-12-30 16:41:47,490 backend.db - INFO [DB_SAVE_COMPLETE] analysis f27a7dda-39ac-4e19-b721-56e5dffe475e saved to database
2025-12-30 16:44:10,924 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.40s with 4 samples
2025-12-30 16:44:13,401 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-30 16:44:13,402 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.60-1.60: idle with 1 captions
2025-12-30 16:44:13,402 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.40-2.40: work with 1 captions
2025-12-30 16:44:15,447 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.60s with 4 samples
2025-12-30 16:44:23,807 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=8.80s with 4 samples
2025-12-30 16:44:26,020 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-8.00: work with 3 captions
2025-12-30 16:44:26,021 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.80-8.80: idle with 1 captions
2025-12-30 16:44:26,021 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-8.00: work with 3 captions
2025-12-30 16:44:26,022 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.80-8.80: idle with 1 captions
2025-12-30 16:44:26,022 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-30 16:44:28,452 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=12.00s with 4 samples
2025-12-30 16:44:33,008 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-10.40: work with 2 captions
2025-12-30 16:44:33,009 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.20-11.20: work with 1 captions
2025-12-30 16:44:33,009 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-12.00: idle with 1 captions
2025-12-30 16:44:33,010 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.60-10.40: work with 2 captions
2025-12-30 16:44:33,010 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.20-11.20: work with 1 captions
2025-12-30 16:44:33,011 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-12.00: idle with 1 captions
2025-12-30 16:44:33,012 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-10.40: work with 2 captions
2025-12-30 16:44:33,012 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.20-11.20: work with 1 captions
2025-12-30 16:44:33,013 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-12.00: idle with 1 captions
2025-12-30 16:44:33,013 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-10.40: work with 2 captions
2025-12-30 16:44:33,014 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.20-11.20: work with 1 captions
2025-12-30 16:44:33,016 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-12.00: idle with 1 captions
2025-12-30 16:44:33,017 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-30 16:44:35,417 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.20s with 4 samples
2025-12-30 16:44:38,311 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.80-13.60: work with 2 captions
2025-12-30 16:44:38,312 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.40-15.20: idle with 2 captions
2025-12-30 16:44:40,202 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=18.40s with 4 samples
2025-12-30 16:44:51,788 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=21.60s with 4 samples
2025-12-30 16:44:59,525 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.20-20.00: work with 2 captions
2025-12-30 16:44:59,525 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-20.80: work with 2 captions
2025-12-30 16:44:59,526 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.80-21.60: work with 2 captions
2025-12-30 16:44:59,526 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.60-22.50: work with 1 captions
2025-12-30 16:44:59,527 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.20-20.00: work with 2 captions
2025-12-30 16:44:59,527 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-20.80: work with 2 captions
2025-12-30 16:44:59,528 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.80-21.60: work with 2 captions
2025-12-30 16:44:59,528 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.60-22.50: work with 1 captions
2025-12-30 16:44:59,529 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.20-20.00: work with 2 captions
2025-12-30 16:44:59,529 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-20.80: work with 2 captions
2025-12-30 16:44:59,530 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.80-21.60: work with 2 captions
2025-12-30 16:44:59,530 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.60-22.50: work with 1 captions
2025-12-30 16:44:59,532 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.20-20.00: work with 2 captions
2025-12-30 16:44:59,536 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-20.80: work with 2 captions
2025-12-30 16:44:59,539 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.80-21.60: work with 2 captions
2025-12-30 16:44:59,539 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.60-22.50: work with 1 captions
2025-12-30 16:44:59,540 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.20-20.00: work with 2 captions
2025-12-30 16:44:59,540 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-20.80: work with 2 captions
2025-12-30 16:44:59,540 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.80-21.60: work with 2 captions
2025-12-30 16:44:59,541 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.60-22.50: work with 1 captions
2025-12-30 16:44:59,542 backend.stream_utils - INFO [PARSE_LLM] Removed 16 duplicate segment(s) in window
2025-12-30 16:45:01,656 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=24.80s with 4 samples
2025-12-30 16:45:06,049 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.40-23.20: work with 2 captions
2025-12-30 16:45:06,049 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.00: idle with 1 captions
2025-12-30 16:45:06,049 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.80-24.80: work with 1 captions
2025-12-30 16:45:06,049 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.40-23.20: work with 2 captions
2025-12-30 16:45:06,049 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.00: idle with 1 captions
2025-12-30 16:45:06,050 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.80-24.80: work with 1 captions
2025-12-30 16:45:06,050 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.40-23.20: work with 2 captions
2025-12-30 16:45:06,050 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.00: idle with 1 captions
2025-12-30 16:45:06,050 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.80-24.80: work with 1 captions
2025-12-30 16:45:06,050 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-30 16:45:08,020 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=28.00s with 4 samples
2025-12-30 16:45:17,301 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.60-26.40: work with 2 captions
2025-12-30 16:45:17,303 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.20-28.00: work with 2 captions
2025-12-30 16:45:19,358 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=31.20s with 4 samples
2025-12-30 16:45:22,742 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 16:45:22,742 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 16:45:25,066 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=34.40s with 4 samples
2025-12-30 16:45:30,802 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.60s with 4 samples
2025-12-30 16:45:36,951 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.20-36.00: work with 2 captions
2025-12-30 16:45:36,952 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.00-36.80: idle with 2 captions
2025-12-30 16:45:36,952 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.80-37.60: idle with 2 captions
2025-12-30 16:45:36,952 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.20-36.00: work with 2 captions
2025-12-30 16:45:36,952 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.00-36.80: idle with 2 captions
2025-12-30 16:45:36,953 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.80-37.60: idle with 2 captions
2025-12-30 16:45:36,953 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.20-36.00: work with 2 captions
2025-12-30 16:45:36,953 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.00-36.80: idle with 2 captions
2025-12-30 16:45:36,954 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.80-37.60: idle with 2 captions
2025-12-30 16:45:36,954 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.20-36.00: work with 2 captions
2025-12-30 16:45:36,954 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.00-36.80: idle with 2 captions
2025-12-30 16:45:36,954 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.80-37.60: idle with 2 captions
2025-12-30 16:45:36,955 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-30 16:45:38,952 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.80s with 4 samples
2025-12-30 16:45:42,424 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 16:45:42,424 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 16:45:44,559 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=44.00s with 4 samples
2025-12-30 16:45:53,008 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.20s with 4 samples
2025-12-30 16:45:57,028 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.20-47.20: work with 1 captions
2025-12-30 16:45:57,029 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.20-47.20: work with 1 captions
2025-12-30 16:45:57,029 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-30 16:45:59,193 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=50.40s with 4 samples
2025-12-30 16:46:03,593 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.80: work with 2 captions
2025-12-30 16:46:03,593 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.80-49.60: work with 2 captions
2025-12-30 16:46:03,593 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.60-50.40: work with 2 captions
2025-12-30 16:46:03,594 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.80: work with 2 captions
2025-12-30 16:46:03,594 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.80-49.60: work with 2 captions
2025-12-30 16:46:03,594 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.60-50.40: work with 2 captions
2025-12-30 16:46:03,594 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.80: work with 2 captions
2025-12-30 16:46:03,594 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.80-49.60: work with 2 captions
2025-12-30 16:46:03,594 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.60-50.40: work with 2 captions
2025-12-30 16:46:03,594 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.80: work with 2 captions
2025-12-30 16:46:03,594 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.80-49.60: work with 2 captions
2025-12-30 16:46:03,595 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.60-50.40: work with 2 captions
2025-12-30 16:46:03,595 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-30 16:46:05,743 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=53.60s with 4 samples
2025-12-30 16:46:20,207 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.20-52.00: work with 2 captions
2025-12-30 16:46:20,207 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.00-52.00: work with 1 captions
2025-12-30 16:46:20,208 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.80-52.80: work with 1 captions
2025-12-30 16:46:20,208 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-53.60: idle with 1 captions
2025-12-30 16:46:20,208 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.20-52.00: work with 2 captions
2025-12-30 16:46:20,208 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.00-52.00: work with 1 captions
2025-12-30 16:46:20,209 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.80-52.80: work with 1 captions
2025-12-30 16:46:20,209 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-53.60: idle with 1 captions
2025-12-30 16:46:20,209 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.20-52.00: work with 2 captions
2025-12-30 16:46:20,210 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.00-52.00: work with 1 captions
2025-12-30 16:46:20,210 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.80-52.80: work with 1 captions
2025-12-30 16:46:20,210 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-53.60: idle with 1 captions
2025-12-30 16:46:20,210 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.20-52.00: work with 2 captions
2025-12-30 16:46:20,210 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.00-52.00: work with 1 captions
2025-12-30 16:46:20,211 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.80-52.80: work with 1 captions
2025-12-30 16:46:20,211 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-53.60: idle with 1 captions
2025-12-30 16:46:20,211 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.20-52.00: work with 2 captions
2025-12-30 16:46:20,211 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.00-52.00: work with 1 captions
2025-12-30 16:46:20,212 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.80-52.80: work with 1 captions
2025-12-30 16:46:20,212 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.60-53.60: idle with 1 captions
2025-12-30 16:46:20,212 backend.stream_utils - INFO [PARSE_LLM] Removed 16 duplicate segment(s) in window
2025-12-30 16:46:22,123 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=56.80s with 4 samples
2025-12-30 16:46:24,758 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.40-55.20: work with 2 captions
2025-12-30 16:46:24,759 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-56.80: work with 2 captions
2025-12-30 16:46:24,759 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.40-55.20: work with 2 captions
2025-12-30 16:46:24,759 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-56.80: work with 2 captions
2025-12-30 16:46:24,760 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-30 16:46:27,141 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=60.00s with 4 samples
2025-12-30 16:46:31,491 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-30 16:46:31,491 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 16:46:33,830 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=63.20s with 4 samples
2025-12-30 16:46:38,896 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.80-61.60: work with 2 captions
2025-12-30 16:46:38,896 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.40-63.20: idle with 2 captions
2025-12-30 16:46:38,896 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.80-61.60: work with 2 captions
2025-12-30 16:46:38,896 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.40-63.20: idle with 2 captions
2025-12-30 16:46:38,897 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.80-61.60: work with 2 captions
2025-12-30 16:46:38,897 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.40-63.20: idle with 2 captions
2025-12-30 16:46:38,897 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.80-61.60: work with 2 captions
2025-12-30 16:46:38,897 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.40-63.20: idle with 2 captions
2025-12-30 16:46:38,897 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.80-61.60: work with 2 captions
2025-12-30 16:46:38,897 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.40-63.20: idle with 2 captions
2025-12-30 16:46:38,898 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-30 16:46:39,361 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2025-12-30 16:46:42,609 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 1 captions.
2025-12-30 16:46:42,610 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-30 16:46:42,613 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 81
2025-12-30 16:46:42,613 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 21
2025-12-30 16:46:42,614 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (0.8, 'arafed man standing in a factory with a '), (1.6, 'arafed man in a factory with a machine i'), (2.4, 'someone is working on a computer in a ro'), (3.2, 'arafed man in a blue shirt is looking at'), (4.0, 'arafed worker working on a machine in a '), (4.8, 'araffe worker in a factory working on a '), (5.6, 'arafed man standing in a factory with a '), (6.4, 'there are many people standing around a '), (7.2, 'there is a man standing at a counter wit')]...
2025-12-30 16:46:42,615 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=2.4: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=0.8s: arafed man standing in a f...
2025-12-30 16:46:42,616 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=5.6: 4 samples, timeline=t=3.2s: arafed man in a blue shirt is looking at a shelf of wine bottles
t=4.0s: arafed worker worki...
2025-12-30 16:46:42,617 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=8.8: 4 samples, timeline=t=6.4s: there are many people standing around a table with a bunch of tools
t=7.2s: there is a man s...
2025-12-30 16:46:42,618 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=12.0: 4 samples, timeline=t=9.6s: there is a man that is petting a cat in a kitchen
t=10.4s: someone is working on a machine i...
2025-12-30 16:46:42,619 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=15.2: 4 samples, timeline=t=12.8s: arafed man standing in a factory with a camera in his hand
t=13.6s: arafed worker working o...
2025-12-30 16:46:42,619 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=18.4: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=16.8s: there is a computer monitor sitting on...
2025-12-30 16:46:42,620 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=21.6: 4 samples, timeline=t=19.2s: arafed worker in a factory working on a machine
t=20.0s: arafed worker in a factory working...
2025-12-30 16:46:42,621 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=24.8: 4 samples, timeline=t=22.4s: arafed worker in a factory working on a machine
t=23.2s: arafed man in blue shirt working i...
2025-12-30 16:46:42,622 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=28.0: 4 samples, timeline=t=25.6s: there are two men standing in a room with a laptop
t=26.4s: there is a man that is standing...
2025-12-30 16:46:42,622 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #10 at t=31.2: 4 samples, timeline=t=28.8s: arafed man in a factory with a baseball bat in his hand
t=29.6s: arafed man in a factory wi...
2025-12-30 16:46:42,623 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #11 at t=34.4: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=32.8s: arafed man in a blue shirt and blu...
2025-12-30 16:46:42,624 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #12 at t=37.6: 4 samples, timeline=t=35.2s: arafed man in blue shirt working on machine in factory
t=36.0s: there is a man that is stan...
2025-12-30 16:46:42,624 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #13 at t=40.8: 4 samples, timeline=t=38.4s: arafed man standing in a factory with a lot of machines
t=39.2s: arafed man standing in a f...
2025-12-30 16:46:42,625 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #14 at t=44.0: 4 samples, timeline=t=41.6s: arafed worker in a factory wearing a mask and gloves
t=42.4s: arafed man in a factory worki...
2025-12-30 16:46:42,625 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #15 at t=47.2: 4 samples, timeline=t=44.8s: arafed man in a blue shirt standing in a factory
t=45.6s: arafed man in blue shirt standing...
2025-12-30 16:46:42,625 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #16 at t=50.4: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=48.8s: arafed man in a blue shirt...
2025-12-30 16:46:42,626 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #17 at t=53.6: 4 samples, timeline=t=51.2s: arafed man standing in a factory with a lot of machines
t=52.0s: arafed man standing in a f...
2025-12-30 16:46:42,626 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #18 at t=56.8: 4 samples, timeline=t=54.4s: araffe worker in a factory with a lot of machines
t=55.2s: arafed worker in a factory with ...
2025-12-30 16:46:42,626 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #19 at t=60.0: 4 samples, timeline=t=57.6s: arafed man in a factory working on a machine
t=58.4s: there is a man standing in a store wi...
2025-12-30 16:46:42,626 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #20 at t=63.2: 4 samples, timeline=t=60.8s: arafed worker in a factory with a box of food
t=61.6s: arafed worker in a factory with a ma...
2025-12-30 16:46:42,627 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #21 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2025-12-30 16:46:42,657 backend.db - INFO [STATS] samples=66 duration=64.30 fps=30.00 work=25.60s idle=11.20s unclass=27.50s work%=39.8 idle%=17.4 unclass%=42.8
2025-12-30 16:46:42,658 backend.db - INFO [STATS_SAVE] analysis=ce3121ae-d563-4be3-a2ab-1bdbf51c742c duration=64.30 fps=30.00 work=25.60s idle=11.20s unclass=27.50s work%=39.8 idle%=17.4 unclass%=42.8
2025-12-30 16:46:42,662 backend.db - INFO [DB_SAVE] analysis ce3121ae-d563-4be3-a2ab-1bdbf51c742c saved to database
2025-12-30 16:46:42,662 backend.db - INFO [DB_SAVE] analysis ce3121ae-d563-4be3-a2ab-1bdbf51c742c saving 81 samples to database
2025-12-30 16:46:42,664 backend.db - INFO [DB_SAVE] analysis ce3121ae-d563-4be3-a2ab-1bdbf51c742c samples saved to database
2025-12-30 16:46:42,666 backend.db - INFO [DB_SAVE] analysis ce3121ae-d563-4be3-a2ab-1bdbf51c742c saving 39 segments to database
2025-12-30 16:46:42,672 backend.db - INFO [DB_SAVE_COMPLETE] analysis ce3121ae-d563-4be3-a2ab-1bdbf51c742c saved to database
2025-12-31 11:34:08,136 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.00s with 4 samples
2025-12-31 11:34:15,135 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 1 captions
2025-12-31 11:34:15,136 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-2.00: work with 1 captions
2025-12-31 11:34:15,136 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-4.00: idle with 1 captions
2025-12-31 11:34:15,136 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.00-6.00: work with 1 captions
2025-12-31 11:34:17,068 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.00s with 4 samples
2025-12-31 11:34:21,786 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 11:34:21,788 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 11:34:24,134 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.00s with 4 samples
2025-12-31 11:34:37,201 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.00s with 4 samples
2025-12-31 11:34:52,634 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.00s with 4 samples
2025-12-31 11:34:58,036 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.00s with 4 samples
2025-12-31 11:35:01,352 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.00-42.00: work with 2 captions
2025-12-31 11:35:01,353 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.00-46.00: idle with 2 captions
2025-12-31 11:35:03,440 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.00s with 4 samples
2025-12-31 11:35:06,355 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 11:35:06,356 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 11:35:08,440 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.00s with 4 samples
2025-12-31 11:35:17,316 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2025-12-31 11:35:23,289 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 1 captions.
2025-12-31 11:35:23,289 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 11:35:23,291 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 33
2025-12-31 11:35:23,292 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 9
2025-12-31 11:35:23,294 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.0, 'someone is working on a laptop with a lo'), (4.0, 'arafed worker working on a machine in a '), (6.0, 'arafed man standing in a factory with a '), (8.0, 'there is a man standing in front of a co'), (10.0, 'someone is holding a cat in a glove whil'), (12.0, 'arafed man standing in a factory with a '), (14.0, 'arafed worker working on a machine in a '), (16.0, 'there is a truck that is parked in a gar'), (18.0, 'there is a computer monitor sitting on a')]...
2025-12-31 11:35:23,294 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.0s: someone is working on a la...
2025-12-31 11:35:23,294 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=14.0: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=10.0s: someone is ho...
2025-12-31 11:35:23,294 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=22.0: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=18.0s: there is a computer monitor sitting on...
2025-12-31 11:35:23,295 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=30.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=26.0s: there are people standing in a bus with ...
2025-12-31 11:35:23,295 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=38.0: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=34.0s: arafed man in a factory holding a ...
2025-12-31 11:35:23,295 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=46.0: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.0s: arafed man in a blue shirt...
2025-12-31 11:35:23,295 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=54.0: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=50.0s: arafed man in a factory wi...
2025-12-31 11:35:23,296 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=62.0: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=58.0s: there is a man that is standing in a sto...
2025-12-31 11:35:23,296 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2025-12-31 11:35:23,327 backend.db - INFO [STATS] samples=17 duration=64.30 fps=30.00 work=4.00s idle=16.00s unclass=44.30s work%=6.2 idle%=24.9 unclass%=68.9
2025-12-31 11:35:23,328 backend.db - INFO [STATS_SAVE] analysis=c2ae27e2-2eb6-4817-a9cc-ed3902d3a01b duration=64.30 fps=30.00 work=4.00s idle=16.00s unclass=44.30s work%=6.2 idle%=24.9 unclass%=68.9
2025-12-31 11:35:23,334 backend.db - INFO [DB_SAVE] analysis c2ae27e2-2eb6-4817-a9cc-ed3902d3a01b saved to database
2025-12-31 11:35:23,335 backend.db - INFO [DB_SAVE] analysis c2ae27e2-2eb6-4817-a9cc-ed3902d3a01b saving 33 samples to database
2025-12-31 11:35:23,336 backend.db - INFO [DB_SAVE] analysis c2ae27e2-2eb6-4817-a9cc-ed3902d3a01b samples saved to database
2025-12-31 11:35:23,336 backend.db - INFO [DB_SAVE] analysis c2ae27e2-2eb6-4817-a9cc-ed3902d3a01b saving 9 segments to database
2025-12-31 11:35:23,336 backend.db - INFO [DB_SAVE_COMPLETE] analysis c2ae27e2-2eb6-4817-a9cc-ed3902d3a01b saved to database
2025-12-31 11:36:54,644 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=1.80s with 4 samples
2025-12-31 11:36:57,454 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.60: work with 2 captions
2025-12-31 11:36:57,455 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.20-1.80: idle with 2 captions
2025-12-31 11:36:57,456 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.60: work with 2 captions
2025-12-31 11:36:57,456 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.20-1.80: idle with 2 captions
2025-12-31 11:36:57,457 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 11:36:59,122 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.20s with 4 samples
2025-12-31 11:37:03,064 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.40-3.00: work with 2 captions
2025-12-31 11:37:03,064 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.00-3.60: work with 2 captions
2025-12-31 11:37:03,064 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.60-4.20: work with 2 captions
2025-12-31 11:37:04,706 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.60s with 4 samples
2025-12-31 11:37:11,841 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.80-6.00: work with 3 captions
2025-12-31 11:37:11,842 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.80-6.00: work with 3 captions
2025-12-31 11:37:11,842 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.80-6.00: work with 3 captions
2025-12-31 11:37:11,842 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.80-6.00: work with 3 captions
2025-12-31 11:37:11,842 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.80-6.00: work with 3 captions
2025-12-31 11:37:11,842 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.80-6.00: work with 3 captions
2025-12-31 11:37:11,843 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.80-6.00: work with 3 captions
2025-12-31 11:37:11,843 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 11:37:13,605 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=9.00s with 4 samples
2025-12-31 11:37:18,131 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.20-7.80: work with 2 captions
2025-12-31 11:37:18,131 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.80-8.40: idle with 2 captions
2025-12-31 11:37:18,131 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.40-9.00: work with 2 captions
2025-12-31 11:37:18,131 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.00-9.00: idle with 1 captions
2025-12-31 11:37:19,892 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=11.40s with 4 samples
2025-12-31 11:37:24,391 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.60-10.20: work with 2 captions
2025-12-31 11:37:24,395 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.80-11.40: idle with 2 captions
2025-12-31 11:37:24,396 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.60-10.20: work with 2 captions
2025-12-31 11:37:24,396 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.80-11.40: idle with 2 captions
2025-12-31 11:37:24,401 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.60-10.20: work with 2 captions
2025-12-31 11:37:24,401 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.80-11.40: idle with 2 captions
2025-12-31 11:37:24,401 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 11:37:26,106 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=13.80s with 4 samples
2025-12-31 11:37:30,270 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 11:37:30,270 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 11:37:32,054 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=16.20s with 4 samples
2025-12-31 11:37:36,692 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.40-15.00: work with 2 captions
2025-12-31 11:37:36,692 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.60: idle with 2 captions
2025-12-31 11:37:36,692 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-16.20: idle with 2 captions
2025-12-31 11:37:36,693 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.40-14.40: work with 1 captions
2025-12-31 11:37:36,693 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 1 captions
2025-12-31 11:37:36,694 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-15.60: idle with 1 captions
2025-12-31 11:37:36,694 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.20-16.20: idle with 1 captions
2025-12-31 11:37:36,694 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.40-14.40: work with 1 captions
2025-12-31 11:37:36,694 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 1 captions
2025-12-31 11:37:36,695 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-15.60: idle with 1 captions
2025-12-31 11:37:36,695 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.20-16.20: idle with 1 captions
2025-12-31 11:37:36,695 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.40-14.40: work with 1 captions
2025-12-31 11:37:36,695 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 1 captions
2025-12-31 11:37:36,695 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-15.60: idle with 1 captions
2025-12-31 11:37:36,696 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.20-16.20: idle with 1 captions
2025-12-31 11:37:36,696 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-31 11:37:38,343 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=18.60s with 4 samples
2025-12-31 11:37:44,961 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-18.60: work with 4 captions
2025-12-31 11:37:46,545 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=21.00s with 4 samples
2025-12-31 11:37:50,185 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.20-21.00: work with 4 captions
2025-12-31 11:37:51,872 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.40s with 4 samples
2025-12-31 11:37:55,696 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.60-22.80: work with 3 captions
2025-12-31 11:37:55,697 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.40-23.40: idle with 1 captions
2025-12-31 11:37:57,572 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=25.80s with 4 samples
2025-12-31 11:38:00,501 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.60: work with 2 captions
2025-12-31 11:38:00,502 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.20-25.80: work with 2 captions
2025-12-31 11:38:00,502 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.60: work with 2 captions
2025-12-31 11:38:00,502 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.20-25.80: work with 2 captions
2025-12-31 11:38:00,503 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.60: work with 2 captions
2025-12-31 11:38:00,503 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.20-25.80: work with 2 captions
2025-12-31 11:38:00,503 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 11:38:02,683 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=28.20s with 4 samples
2025-12-31 11:38:08,607 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.40-27.00: work with 2 captions
2025-12-31 11:38:08,607 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.00-27.60: idle with 2 captions
2025-12-31 11:38:08,607 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.60-28.20: work with 2 captions
2025-12-31 11:38:10,673 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.60s with 4 samples
2025-12-31 11:38:14,954 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.80-29.40: work with 2 captions
2025-12-31 11:38:14,954 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.60: work with 2 captions
2025-12-31 11:38:16,763 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=33.00s with 4 samples
2025-12-31 11:38:21,851 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.20-31.80: work with 2 captions
2025-12-31 11:38:21,852 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.40-33.00: idle with 2 captions
2025-12-31 11:38:21,852 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.20-31.80: work with 2 captions
2025-12-31 11:38:21,852 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.40-33.00: idle with 2 captions
2025-12-31 11:38:21,853 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.20-31.80: work with 2 captions
2025-12-31 11:38:21,853 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.40-33.00: idle with 2 captions
2025-12-31 11:38:21,853 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 11:38:23,936 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=35.40s with 4 samples
2025-12-31 11:38:28,294 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 11:38:28,295 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 11:38:30,418 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.80s with 4 samples
2025-12-31 11:38:34,216 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.00-36.60: work with 2 captions
2025-12-31 11:38:34,216 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.20-37.80: work with 2 captions
2025-12-31 11:38:34,216 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.00-36.60: work with 2 captions
2025-12-31 11:38:34,216 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.20-37.80: work with 2 captions
2025-12-31 11:38:34,216 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 11:38:36,308 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.20s with 4 samples
2025-12-31 11:38:39,920 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.40-39.00: work with 2 captions
2025-12-31 11:38:39,921 backend.stream_utils - INFO [PARSE_LLM] Created segment 39.00-39.60: work with 2 captions
2025-12-31 11:38:39,921 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.20-40.20: idle with 1 captions
2025-12-31 11:38:39,921 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.40-39.00: work with 2 captions
2025-12-31 11:38:39,922 backend.stream_utils - INFO [PARSE_LLM] Created segment 39.00-39.60: work with 2 captions
2025-12-31 11:38:39,922 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.20-40.20: idle with 1 captions
2025-12-31 11:38:39,922 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-31 11:38:42,204 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=42.60s with 4 samples
2025-12-31 11:38:50,028 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.80-41.40: work with 2 captions
2025-12-31 11:38:50,028 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-42.00: work with 2 captions
2025-12-31 11:38:50,029 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.00-42.60: work with 2 captions
2025-12-31 11:38:50,029 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.80-41.40: work with 2 captions
2025-12-31 11:38:50,029 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-42.00: work with 2 captions
2025-12-31 11:38:50,029 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.00-42.60: work with 2 captions
2025-12-31 11:38:50,030 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.80-41.40: work with 2 captions
2025-12-31 11:38:50,030 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-42.00: work with 2 captions
2025-12-31 11:38:50,030 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.00-42.60: work with 2 captions
2025-12-31 11:38:50,031 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.80-41.40: work with 2 captions
2025-12-31 11:38:50,031 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-42.00: work with 2 captions
2025-12-31 11:38:50,031 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.00-42.60: work with 2 captions
2025-12-31 11:38:50,031 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-31 11:38:52,078 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=45.00s with 4 samples
2025-12-31 11:38:56,366 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.20-43.20: work with 1 captions
2025-12-31 11:38:56,366 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.80-43.80: idle with 1 captions
2025-12-31 11:38:56,366 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.40-44.40: work with 1 captions
2025-12-31 11:38:56,367 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: idle with 1 captions
2025-12-31 11:38:56,367 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.20-43.20: work with 1 captions
2025-12-31 11:38:56,367 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.80-43.80: idle with 1 captions
2025-12-31 11:38:56,367 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.40-44.40: work with 1 captions
2025-12-31 11:38:56,367 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: idle with 1 captions
2025-12-31 11:38:56,367 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.20-43.20: work with 1 captions
2025-12-31 11:38:56,368 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.80-43.80: idle with 1 captions
2025-12-31 11:38:56,368 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.40-44.40: work with 1 captions
2025-12-31 11:38:56,368 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: idle with 1 captions
2025-12-31 11:38:56,368 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-31 11:38:58,616 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.40s with 4 samples
2025-12-31 11:39:05,470 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.80s with 4 samples
2025-12-31 11:39:13,727 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.60: work with 2 captions
2025-12-31 11:39:13,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.60-49.20: idle with 2 captions
2025-12-31 11:39:13,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.20-49.80: idle with 2 captions
2025-12-31 11:39:13,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.60: work with 2 captions
2025-12-31 11:39:13,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.60-49.20: idle with 2 captions
2025-12-31 11:39:13,729 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.20-49.80: idle with 2 captions
2025-12-31 11:39:13,729 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.60: work with 2 captions
2025-12-31 11:39:13,729 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.60-49.20: idle with 2 captions
2025-12-31 11:39:13,729 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.20-49.80: idle with 2 captions
2025-12-31 11:39:13,729 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 11:39:15,853 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=52.20s with 4 samples
2025-12-31 11:39:19,845 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.40-51.00: work with 2 captions
2025-12-31 11:39:19,846 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.60-52.20: work with 2 captions
2025-12-31 11:39:19,846 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.40-51.00: work with 2 captions
2025-12-31 11:39:19,847 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.60-52.20: work with 2 captions
2025-12-31 11:39:19,848 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 11:39:22,081 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.60s with 4 samples
2025-12-31 11:39:28,303 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.80-53.40: work with 2 captions
2025-12-31 11:39:28,303 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.00-54.60: work with 2 captions
2025-12-31 11:39:28,304 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.80-53.40: work with 2 captions
2025-12-31 11:39:28,304 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.00-54.60: work with 2 captions
2025-12-31 11:39:28,304 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.80-53.40: work with 2 captions
2025-12-31 11:39:28,304 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.00-54.60: work with 2 captions
2025-12-31 11:39:28,304 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.80-53.40: work with 2 captions
2025-12-31 11:39:28,305 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.00-54.60: work with 2 captions
2025-12-31 11:39:28,305 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.80-53.40: work with 2 captions
2025-12-31 11:39:28,305 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.00-54.60: work with 2 captions
2025-12-31 11:39:28,306 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-31 11:39:30,190 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.00s with 4 samples
2025-12-31 11:39:41,573 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=59.40s with 4 samples
2025-12-31 11:39:49,382 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.60-58.20: work with 2 captions
2025-12-31 11:39:49,383 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.80-59.40: idle with 2 captions
2025-12-31 11:39:49,383 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.60-58.20: work with 2 captions
2025-12-31 11:39:49,383 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.80-59.40: idle with 2 captions
2025-12-31 11:39:49,383 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.60-58.20: work with 2 captions
2025-12-31 11:39:49,384 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.80-59.40: idle with 2 captions
2025-12-31 11:39:49,384 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 11:39:51,395 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=61.80s with 4 samples
2025-12-31 11:39:57,796 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-60.60: work with 2 captions
2025-12-31 11:39:57,797 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.20-61.80: work with 2 captions
2025-12-31 11:39:57,797 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-60.60: work with 2 captions
2025-12-31 11:39:57,797 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.20-61.80: work with 2 captions
2025-12-31 11:39:57,797 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-60.60: work with 2 captions
2025-12-31 11:39:57,798 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.20-61.80: work with 2 captions
2025-12-31 11:39:57,798 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 11:40:00,126 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=64.20s with 4 samples
2025-12-31 11:40:06,208 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.40-62.40: work with 1 captions
2025-12-31 11:40:06,208 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.00-63.00: work with 1 captions
2025-12-31 11:40:06,209 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.60-63.60: idle with 1 captions
2025-12-31 11:40:06,209 backend.stream_utils - INFO [PARSE_LLM] Created segment 64.20-64.20: work with 1 captions
2025-12-31 11:40:06,212 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 108
2025-12-31 11:40:06,212 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 27
2025-12-31 11:40:06,212 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (0.6, 'arafed man in a factory with a blue shir'), (1.2, 'arafed man in blue shirt standing in fac'), (1.8, 'arafed man in a factory with a machine a'), (2.4, 'someone is working on a computer in a ro'), (3.0, 'arafed man working on a computer in a fa'), (3.6, 'arafed man working on a motorcycle in a '), (4.2, 'arafed man working on a motorcycle in a '), (4.8, 'araffe worker in a factory working on a '), (5.4, 'arafed man standing in a factory with a ')]...
2025-12-31 11:40:06,213 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=1.8: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=0.6s: arafed man in a factory wi...
2025-12-31 11:40:06,213 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=4.2: 4 samples, timeline=t=2.4s: someone is working on a computer in a room with many electronics
t=3.0s: arafed man working ...
2025-12-31 11:40:06,213 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=6.6: 4 samples, timeline=t=4.8s: araffe worker in a factory working on a computer
t=5.4s: arafed man standing in a factory wi...
2025-12-31 11:40:06,213 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=9.0: 4 samples, timeline=t=7.2s: there is a man standing at a counter with a bunch of bottles
t=7.8s: there are many bottles ...
2025-12-31 11:40:06,214 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=11.4: 4 samples, timeline=t=9.6s: there is a man that is petting a cat in a kitchen
t=10.2s: someone is holding a cat in their...
2025-12-31 11:40:06,214 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=13.8: 4 samples, timeline=t=12.0s: arafed man standing in a factory with a tablet computer
t=12.6s: arafed man standing in a f...
2025-12-31 11:40:06,214 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=16.2: 4 samples, timeline=t=14.4s: there is a man that is standing in front of a machine
t=15.0s: there is a man that is stand...
2025-12-31 11:40:06,214 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=18.6: 4 samples, timeline=t=16.8s: there is a computer monitor sitting on a desk in a room
t=17.4s: there is a computer monito...
2025-12-31 11:40:06,215 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=21.0: 4 samples, timeline=t=19.2s: arafed worker in a factory working on a machine
t=19.8s: arafed worker in a factory working...
2025-12-31 11:40:06,215 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #10 at t=23.4: 4 samples, timeline=t=21.6s: arafed worker in a factory working on a machine
t=22.2s: arafed worker in a factory working...
2025-12-31 11:40:06,215 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #11 at t=25.8: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=24.6s: there are two men working on a machine i...
2025-12-31 11:40:06,215 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #12 at t=28.2: 4 samples, timeline=t=26.4s: there is a man that is standing in a room with a dog
t=27.0s: arafed image of a man working...
2025-12-31 11:40:06,216 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #13 at t=30.6: 4 samples, timeline=t=28.8s: arafed man in a factory with a baseball bat in his hand
t=29.4s: arafed man standing in a f...
2025-12-31 11:40:06,216 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #14 at t=33.0: 4 samples, timeline=t=31.2s: arafed worker in a factory with a box of electronics
t=31.8s: arafed man in a factory with ...
2025-12-31 11:40:06,216 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #15 at t=35.4: 4 samples, timeline=t=33.6s: arafed man in a blue shirt and mask holding a bag of food
t=34.2s: there is a man holding a...
2025-12-31 11:40:06,216 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #16 at t=37.8: 4 samples, timeline=t=36.0s: there is a man that is standing in a factory with a machine
t=36.6s: arafed man standing in...
2025-12-31 11:40:06,217 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #17 at t=40.2: 4 samples, timeline=t=38.4s: arafed man standing in a factory with a lot of machines
t=39.0s: arafed man standing in a f...
2025-12-31 11:40:06,217 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #18 at t=42.6: 4 samples, timeline=t=40.8s: arafed man in a blue shirt and mask working on a machine
t=41.4s: arafed man in a blue shir...
2025-12-31 11:40:06,217 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #19 at t=45.0: 4 samples, timeline=t=43.2s: arafed man in a factory with a large amount of equipment
t=43.8s: arafed man in a factory w...
2025-12-31 11:40:06,217 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #20 at t=47.4: 4 samples, timeline=t=45.6s: arafed man in blue shirt standing in a factory with a machine
t=46.2s: arafed man standing ...
2025-12-31 11:40:06,218 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #21 at t=49.8: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=48.6s: arafed worker in a factory...
2025-12-31 11:40:06,218 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #22 at t=52.2: 4 samples, timeline=t=50.4s: arafed man in blue shirt talking on cell phone in factory
t=51.0s: arafed man standing in a...
2025-12-31 11:40:06,218 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #23 at t=54.6: 4 samples, timeline=t=52.8s: arafed man standing in a factory with a lot of machines
t=53.4s: arafed man standing in a f...
2025-12-31 11:40:06,218 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #24 at t=57.0: 4 samples, timeline=t=55.2s: arafed worker in a factory with a mask on
t=55.8s: arafed worker in a factory with a mask o...
2025-12-31 11:40:06,218 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #25 at t=59.4: 4 samples, timeline=t=57.6s: arafed man in a factory working on a machine
t=58.2s: there is a man standing in a store wi...
2025-12-31 11:40:06,219 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #26 at t=61.8: 4 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=60.6s: arafed worker in a factory wit...
2025-12-31 11:40:06,219 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #27 at t=64.2: 4 samples, timeline=t=62.4s: arafed worker in a factory with a mask on
t=63.0s: arafed man in a mask and gloves standing...
2025-12-31 11:40:06,221 backend.db - INFO [STATS] samples=99 duration=64.30 fps=30.00 work=33.60s idle=8.40s unclass=22.30s work%=52.3 idle%=13.1 unclass%=34.7
2025-12-31 11:40:06,221 backend.db - INFO [STATS_SAVE] analysis=c4ceb8ea-fa22-4ace-afe1-2057ac04b17f duration=64.30 fps=30.00 work=33.60s idle=8.40s unclass=22.30s work%=52.3 idle%=13.1 unclass%=34.7
2025-12-31 11:40:06,225 backend.db - INFO [DB_SAVE] analysis c4ceb8ea-fa22-4ace-afe1-2057ac04b17f saved to database
2025-12-31 11:40:06,225 backend.db - INFO [DB_SAVE] analysis c4ceb8ea-fa22-4ace-afe1-2057ac04b17f saving 108 samples to database
2025-12-31 11:40:06,226 backend.db - INFO [DB_SAVE] analysis c4ceb8ea-fa22-4ace-afe1-2057ac04b17f samples saved to database
2025-12-31 11:40:06,226 backend.db - INFO [DB_SAVE] analysis c4ceb8ea-fa22-4ace-afe1-2057ac04b17f saving 61 segments to database
2025-12-31 11:40:06,227 backend.db - INFO [DB_SAVE_COMPLETE] analysis c4ceb8ea-fa22-4ace-afe1-2057ac04b17f saved to database
2025-12-31 12:06:31,858 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=0.86s with 4 samples
2025-12-31 12:07:37,153 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.03s with 4 samples
2025-12-31 12:08:58,200 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.19s with 4 samples
2025-12-31 12:10:00,868 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.35s with 4 samples
2025-12-31 12:11:03,616 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.52s with 4 samples
2025-12-31 12:11:23,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.00: idle with 2 captions
2025-12-31 12:11:23,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.00-5.20: using_phone with 2 captions
2025-12-31 12:11:23,078 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.50: unknown with 2 captions
2025-12-31 12:11:23,079 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.00: idle with 2 captions
2025-12-31 12:11:23,079 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.00-5.20: using_phone with 2 captions
2025-12-31 12:11:23,079 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.50: unknown with 2 captions
2025-12-31 12:11:23,079 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-5.00: idle with 2 captions
2025-12-31 12:11:23,080 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.00-5.20: using_phone with 2 captions
2025-12-31 12:11:23,080 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.50: unknown with 2 captions
2025-12-31 12:11:23,080 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:12:01,923 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.68s with 4 samples
2025-12-31 12:12:10,591 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-6.10: idle with 2 captions
2025-12-31 12:12:10,591 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.70: assembling_drone with 2 captions
2025-12-31 12:12:49,878 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.84s with 4 samples
2025-12-31 12:12:55,348 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 12:12:55,349 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 12:13:05,390 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2025-12-31 12:13:15,022 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.10-15.00: idle with 2 captions
2025-12-31 12:13:15,024 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2025-12-31 12:13:15,025 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2025-12-31 12:13:15,026 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'The main person is assembling a mechanic'), (0.2658555133079848, 'The main person is assembling a mechanic'), (0.5649429657794677, 'The main person in the image is engaged '), (0.8640304182509505, 'The main person is holding a wooden mech'), (1.1631178707224334, 'The main person is assembling a wooden m'), (1.4289733840304182, 'The main person is holding a wooden toy '), (1.728060836501901, 'The main person is holding a mechanical '), (2.027148288973384, 'The main person is holding a small elect'), (2.326235741444867, 'The main person is holding a small elect'), (2.5920912547528516, 'The main person is holding a small piece')]...
2025-12-31 12:13:15,028 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=0.8640304182509505: 4 samples, timeline=t=0.0s: The main person is assembling a mechanical model. They are using their hands to connect wire...
2025-12-31 12:13:15,029 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=2.027148288973384: 4 samples, timeline=t=1.2s: The main person is assembling a wooden mechanical model. They are using their hands to conne...
2025-12-31 12:13:15,029 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=3.1902661596958173: 4 samples, timeline=t=2.3s: The main person is holding a small electronic circuit board with their fingers. They are usi...
2025-12-31 12:13:15,029 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=4.353384030418251: 4 samples, timeline=t=3.5s: The main person is engaged in assembling a mechanical device. They are using their hands to ...
2025-12-31 12:13:15,030 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=5.516501901140685: 4 samples, timeline=t=4.7s: The main person is holding a small device with their hands. They are using a pair of tweezer...
2025-12-31 12:13:15,030 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=6.679619771863118: 4 samples, timeline=t=5.8s: The main person is assembling a wooden toy. They are using a small piece of wood to attach a...
2025-12-31 12:13:15,031 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=7.8427376425855515: 4 samples, timeline=t=7.0s: The main person is assembling a wooden drone. They are using a screwdriver to attach the com...
2025-12-31 12:13:15,031 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=8.1s: The main person is holding a small drone. They are holding the drone with both hands, and it...
2025-12-31 12:13:15,049 backend.db - INFO [STATS] samples=4 duration=8.74 fps=30.09 work=0.00s idle=1.16s unclass=7.58s work%=0.0 idle%=13.3 unclass%=86.7
2025-12-31 12:13:15,049 backend.db - INFO [STATS_SAVE] analysis=6f7eff43-1730-4998-8cff-89fa128aec71 duration=8.74 fps=30.09 work=0.00s idle=1.16s unclass=7.58s work%=0.0 idle%=13.3 unclass%=86.7
2025-12-31 12:13:15,051 backend.db - INFO [DB_SAVE] analysis 6f7eff43-1730-4998-8cff-89fa128aec71 saved to database
2025-12-31 12:13:15,051 backend.db - INFO [DB_SAVE] analysis 6f7eff43-1730-4998-8cff-89fa128aec71 saving 30 samples to database
2025-12-31 12:13:15,051 backend.db - INFO [DB_SAVE] analysis 6f7eff43-1730-4998-8cff-89fa128aec71 samples saved to database
2025-12-31 12:13:15,051 backend.db - INFO [DB_SAVE] analysis 6f7eff43-1730-4998-8cff-89fa128aec71 saving 7 segments to database
2025-12-31 12:13:15,052 backend.db - INFO [DB_SAVE_COMPLETE] analysis 6f7eff43-1730-4998-8cff-89fa128aec71 saved to database
2025-12-31 12:29:46,679 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=0.10s with 4 samples
2025-12-31 12:29:53,541 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.00: work with 2 captions
2025-12-31 12:29:53,541 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.10-0.10: idle with 2 captions
2025-12-31 12:29:55,710 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=0.23s with 4 samples
2025-12-31 12:30:07,725 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.10-0.20: work with 4 captions
2025-12-31 12:30:07,726 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.20-0.20: work with 3 captions
2025-12-31 12:30:07,726 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.20-0.20: work with 3 captions
2025-12-31 12:30:07,726 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.20-0.20: work with 3 captions
2025-12-31 12:30:07,726 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.10-0.20: work with 4 captions
2025-12-31 12:30:07,726 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.20-0.20: work with 3 captions
2025-12-31 12:30:07,726 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.20-0.20: work with 3 captions
2025-12-31 12:30:07,726 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.20-0.20: work with 3 captions
2025-12-31 12:30:07,726 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:30:09,847 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=0.37s with 4 samples
2025-12-31 12:30:13,453 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.30-0.40: work with 4 captions
2025-12-31 12:30:15,371 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=0.50s with 4 samples
2025-12-31 12:30:22,517 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.40-0.40: work with 2 captions
2025-12-31 12:30:22,517 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-0.50: work with 2 captions
2025-12-31 12:30:22,517 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 2 captions
2025-12-31 12:30:22,518 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.40-0.40: work with 2 captions
2025-12-31 12:30:22,518 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-0.50: work with 2 captions
2025-12-31 12:30:22,518 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.40-0.40: work with 2 captions
2025-12-31 12:30:22,518 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-0.50: work with 2 captions
2025-12-31 12:30:22,518 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.40-0.40: work with 2 captions
2025-12-31 12:30:22,520 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-0.50: work with 2 captions
2025-12-31 12:30:22,520 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.40-0.40: work with 2 captions
2025-12-31 12:30:22,521 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-0.50: work with 2 captions
2025-12-31 12:30:22,521 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-31 12:30:24,515 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=0.63s with 4 samples
2025-12-31 12:30:27,417 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:30:29,635 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=0.77s with 4 samples
2025-12-31 12:30:33,058 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.70-0.70: work with 3 captions
2025-12-31 12:30:33,059 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.70-0.70: work with 3 captions
2025-12-31 12:30:33,059 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: idle with 1 captions
2025-12-31 12:30:33,059 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: work with 1 captions
2025-12-31 12:30:33,059 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:30:33,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.70-0.70: work with 3 captions
2025-12-31 12:30:33,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.70-0.70: work with 3 captions
2025-12-31 12:30:33,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: idle with 1 captions
2025-12-31 12:30:33,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: work with 1 captions
2025-12-31 12:30:33,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.70-0.70: work with 3 captions
2025-12-31 12:30:33,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: idle with 1 captions
2025-12-31 12:30:33,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.70-0.70: work with 3 captions
2025-12-31 12:30:33,061 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: work with 1 captions
2025-12-31 12:30:33,061 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-31 12:30:35,058 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=0.90s with 4 samples
2025-12-31 12:30:38,494 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: work with 2 captions
2025-12-31 12:30:38,494 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.90-0.90: idle with 2 captions
2025-12-31 12:30:38,496 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: work with 2 captions
2025-12-31 12:30:38,498 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.90-0.90: idle with 2 captions
2025-12-31 12:30:38,499 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.80-0.80: work with 2 captions
2025-12-31 12:30:38,500 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.90-0.90: idle with 2 captions
2025-12-31 12:30:38,501 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:30:40,527 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=1.03s with 4 samples
2025-12-31 12:30:44,843 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.90-1.00: work with 4 captions
2025-12-31 12:30:47,021 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=1.17s with 4 samples
2025-12-31 12:30:56,251 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:30:56,251 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:30:56,252 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:30:56,252 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:30:56,252 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-31 12:30:58,392 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=1.30s with 4 samples
2025-12-31 12:31:02,977 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:31:02,977 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:31:02,978 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:31:05,194 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=1.43s with 4 samples
2025-12-31 12:31:10,098 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.30-1.40: work with 4 captions
2025-12-31 12:31:10,099 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.40-1.40: idle with 3 captions
2025-12-31 12:31:10,099 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:31:10,100 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.30-1.40: work with 4 captions
2025-12-31 12:31:10,101 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.40-1.40: idle with 3 captions
2025-12-31 12:31:10,101 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.30-1.40: work with 4 captions
2025-12-31 12:31:10,101 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.40-1.40: idle with 3 captions
2025-12-31 12:31:10,102 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.30-1.40: work with 4 captions
2025-12-31 12:31:10,102 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.40-1.40: idle with 3 captions
2025-12-31 12:31:10,102 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:31:12,162 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=1.57s with 4 samples
2025-12-31 12:31:21,304 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 12:31:21,304 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 12:31:23,339 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=1.70s with 4 samples
2025-12-31 12:31:28,625 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:31:28,626 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.60-1.60: work with 2 captions
2025-12-31 12:31:28,626 backend.stream_utils - INFO [PARSE_LLM] Created segment 1.70-1.70: work with 2 captions
2025-12-31 12:31:30,809 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=1.83s with 4 samples
2025-12-31 12:31:34,952 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 12:31:34,952 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 12:31:36,944 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=1.97s with 4 samples
2025-12-31 12:31:41,706 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 12:31:41,707 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 12:31:43,593 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.10s with 4 samples
2025-12-31 12:31:47,791 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-2.00: work with 2 captions
2025-12-31 12:31:47,791 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 2 captions
2025-12-31 12:31:47,791 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-2.00: work with 2 captions
2025-12-31 12:31:47,791 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 2 captions
2025-12-31 12:31:47,792 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-2.00: work with 2 captions
2025-12-31 12:31:47,792 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.10: idle with 2 captions
2025-12-31 12:31:47,792 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:31:50,244 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.23s with 4 samples
2025-12-31 12:32:04,249 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:32:04,249 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.20: idle with 4 captions
2025-12-31 12:32:04,249 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,250 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,250 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,250 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 4 captions
2025-12-31 12:32:04,251 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.20: idle with 4 captions
2025-12-31 12:32:04,251 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,251 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,251 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,252 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.20: idle with 4 captions
2025-12-31 12:32:04,252 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,252 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,252 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,253 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.20: idle with 4 captions
2025-12-31 12:32:04,253 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,253 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,253 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,254 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.10-2.20: idle with 4 captions
2025-12-31 12:32:04,254 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,254 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,254 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.20-2.20: work with 3 captions
2025-12-31 12:32:04,254 backend.stream_utils - INFO [PARSE_LLM] Removed 19 duplicate segment(s) in window
2025-12-31 12:32:06,044 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.37s with 4 samples
2025-12-31 12:32:09,554 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 3 captions
2025-12-31 12:32:09,555 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.30-2.30: work with 3 captions
2025-12-31 12:32:09,555 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.40-2.40: work with 1 captions
2025-12-31 12:32:09,555 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 3 captions
2025-12-31 12:32:09,556 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.30-2.30: work with 3 captions
2025-12-31 12:32:09,556 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.40-2.40: work with 1 captions
2025-12-31 12:32:09,556 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 3 captions
2025-12-31 12:32:09,557 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.30-2.30: work with 3 captions
2025-12-31 12:32:09,557 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.40-2.40: work with 1 captions
2025-12-31 12:32:09,557 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:32:11,619 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.50s with 4 samples
2025-12-31 12:32:15,930 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.40-2.40: work with 2 captions
2025-12-31 12:32:15,931 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.50-2.50: idle with 2 captions
2025-12-31 12:32:15,931 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.50-2.50: work with 2 captions
2025-12-31 12:32:17,659 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.63s with 4 samples
2025-12-31 12:32:28,399 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.50-2.60: work with 4 captions
2025-12-31 12:32:28,400 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.60-2.60: idle with 3 captions
2025-12-31 12:32:28,400 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.50-2.60: work with 4 captions
2025-12-31 12:32:28,400 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.60-2.60: idle with 3 captions
2025-12-31 12:32:28,401 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.50-2.60: work with 4 captions
2025-12-31 12:32:28,401 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.60-2.60: idle with 3 captions
2025-12-31 12:32:28,401 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.50-2.60: work with 4 captions
2025-12-31 12:32:28,401 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.60-2.60: idle with 3 captions
2025-12-31 12:32:28,401 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.50-2.60: work with 4 captions
2025-12-31 12:32:28,401 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.60-2.60: idle with 3 captions
2025-12-31 12:32:28,401 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-31 12:32:30,566 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.77s with 4 samples
2025-12-31 12:32:43,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.70-2.70: work with 3 captions
2025-12-31 12:32:43,571 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.80-2.80: idle with 1 captions
2025-12-31 12:32:45,768 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.90s with 4 samples
2025-12-31 12:32:52,550 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.03s with 4 samples
2025-12-31 12:32:57,496 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.90-3.00: work with 4 captions
2025-12-31 12:32:57,496 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.00-3.00: idle with 3 captions
2025-12-31 12:32:57,496 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.90-3.00: work with 4 captions
2025-12-31 12:32:57,497 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.00-3.00: idle with 3 captions
2025-12-31 12:32:57,497 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:32:59,530 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.17s with 4 samples
2025-12-31 12:33:05,181 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: idle with 3 captions
2025-12-31 12:33:05,181 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: work with 3 captions
2025-12-31 12:33:05,181 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.20-3.20: idle with 1 captions
2025-12-31 12:33:05,182 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: work with 3 captions
2025-12-31 12:33:05,182 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.20-3.20: idle with 1 captions
2025-12-31 12:33:05,182 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-3.10: work with 3 captions
2025-12-31 12:33:05,183 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.20-3.20: idle with 1 captions
2025-12-31 12:33:05,183 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:33:07,568 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.30s with 4 samples
2025-12-31 12:33:13,304 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.20-3.20: idle with 2 captions
2025-12-31 12:33:13,304 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.30-3.30: work with 2 captions
2025-12-31 12:33:15,619 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.43s with 4 samples
2025-12-31 12:33:21,298 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.30-3.30: work with 1 captions
2025-12-31 12:33:21,298 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.40-3.40: idle with 3 captions
2025-12-31 12:33:21,299 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.40-3.40: idle with 3 captions
2025-12-31 12:33:21,299 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.40-3.40: work with 3 captions
2025-12-31 12:33:21,299 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:33:23,800 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.57s with 4 samples
2025-12-31 12:33:31,173 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.50-3.60: work with 4 captions
2025-12-31 12:33:31,174 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.50-3.60: work with 4 captions
2025-12-31 12:33:31,174 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.50-3.60: work with 4 captions
2025-12-31 12:33:31,174 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.50-3.60: work with 4 captions
2025-12-31 12:33:31,175 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.50-3.60: work with 4 captions
2025-12-31 12:33:31,175 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:33:32,932 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.70s with 4 samples
2025-12-31 12:33:41,856 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.60-3.60: work with 2 captions
2025-12-31 12:33:41,858 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.70-3.70: work with 2 captions
2025-12-31 12:33:41,858 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.70-3.70: work with 2 captions
2025-12-31 12:33:41,858 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:33:43,583 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.83s with 4 samples
2025-12-31 12:33:46,660 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.70-3.80: work with 4 captions
2025-12-31 12:33:48,343 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.97s with 4 samples
2025-12-31 12:33:51,899 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.90-3.90: work with 3 captions
2025-12-31 12:33:51,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-4.00: work with 1 captions
2025-12-31 12:33:51,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.90-3.90: work with 3 captions
2025-12-31 12:33:51,902 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-4.00: work with 1 captions
2025-12-31 12:33:51,902 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:33:53,604 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.10s with 4 samples
2025-12-31 12:33:56,766 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-4.00: work with 2 captions
2025-12-31 12:33:56,766 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.10-4.10: work with 2 captions
2025-12-31 12:33:58,782 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.23s with 4 samples
2025-12-31 12:34:05,296 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.20-4.20: work with 3 captions
2025-12-31 12:34:05,296 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.20-4.20: work with 3 captions
2025-12-31 12:34:05,296 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.10-4.20: work with 4 captions
2025-12-31 12:34:05,296 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.20-4.20: idle with 3 captions
2025-12-31 12:34:05,297 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.20-4.20: work with 3 captions
2025-12-31 12:34:05,299 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.20-4.20: work with 3 captions
2025-12-31 12:34:05,300 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.10-4.20: work with 4 captions
2025-12-31 12:34:05,300 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.20-4.20: idle with 3 captions
2025-12-31 12:34:05,300 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.20-4.20: work with 3 captions
2025-12-31 12:34:05,300 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.20-4.20: work with 3 captions
2025-12-31 12:34:05,300 backend.stream_utils - INFO [PARSE_LLM] Removed 7 duplicate segment(s) in window
2025-12-31 12:34:07,146 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.37s with 4 samples
2025-12-31 12:34:11,639 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.40-4.40: work with 1 captions
2025-12-31 12:34:11,641 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.40-4.40: work with 1 captions
2025-12-31 12:34:11,642 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.40-4.40: work with 1 captions
2025-12-31 12:34:11,643 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.40-4.40: work with 1 captions
2025-12-31 12:34:11,643 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-31 12:34:13,378 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.50s with 4 samples
2025-12-31 12:34:16,636 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 12:34:16,636 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 12:34:18,353 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.63s with 4 samples
2025-12-31 12:34:21,650 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.50-4.60: work with 4 captions
2025-12-31 12:34:21,650 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.60-4.60: idle with 3 captions
2025-12-31 12:34:21,651 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.60-4.60: work with 3 captions
2025-12-31 12:34:21,651 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.50-4.60: work with 4 captions
2025-12-31 12:34:21,651 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.60-4.60: idle with 3 captions
2025-12-31 12:34:21,651 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.60-4.60: work with 3 captions
2025-12-31 12:34:21,651 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-31 12:34:23,668 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.77s with 4 samples
2025-12-31 12:34:32,383 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-4.80: work with 4 captions
2025-12-31 12:34:32,384 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-4.80: work with 4 captions
2025-12-31 12:34:32,384 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-4.80: work with 4 captions
2025-12-31 12:34:32,385 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-4.80: work with 4 captions
2025-12-31 12:34:32,385 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-4.80: work with 4 captions
2025-12-31 12:34:32,385 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-4.80: work with 4 captions
2025-12-31 12:34:32,385 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-4.80: work with 4 captions
2025-12-31 12:34:32,385 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-4.80: work with 4 captions
2025-12-31 12:34:32,386 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-4.80: work with 4 captions
2025-12-31 12:34:32,386 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-4.80: work with 4 captions
2025-12-31 12:34:32,387 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.70-4.80: work with 4 captions
2025-12-31 12:34:32,389 backend.stream_utils - INFO [PARSE_LLM] Removed 10 duplicate segment(s) in window
2025-12-31 12:34:34,331 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.90s with 4 samples
2025-12-31 12:34:41,190 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.80-4.80: work with 2 captions
2025-12-31 12:34:41,190 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.90-4.90: idle with 2 captions
2025-12-31 12:34:41,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.90-4.90: idle with 2 captions
2025-12-31 12:34:41,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.80-4.80: work with 2 captions
2025-12-31 12:34:41,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.90-4.90: idle with 2 captions
2025-12-31 12:34:41,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.90-4.90: idle with 2 captions
2025-12-31 12:34:41,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.80-4.80: work with 2 captions
2025-12-31 12:34:41,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.90-4.90: idle with 2 captions
2025-12-31 12:34:41,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.90-4.90: idle with 2 captions
2025-12-31 12:34:41,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.80-4.80: work with 2 captions
2025-12-31 12:34:41,192 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.90-4.90: idle with 2 captions
2025-12-31 12:34:41,192 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.90-4.90: idle with 2 captions
2025-12-31 12:34:41,192 backend.stream_utils - INFO [PARSE_LLM] Removed 10 duplicate segment(s) in window
2025-12-31 12:34:43,288 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.03s with 4 samples
2025-12-31 12:34:48,933 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.90-5.00: work with 4 captions
2025-12-31 12:34:48,934 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.00-5.00: idle with 3 captions
2025-12-31 12:34:48,934 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.00-5.00: work with 3 captions
2025-12-31 12:34:51,448 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.17s with 4 samples
2025-12-31 12:34:59,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 1 captions
2025-12-31 12:34:59,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.10-5.10: work with 3 captions
2025-12-31 12:34:59,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 1 captions
2025-12-31 12:34:59,570 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:35:01,951 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.30s with 4 samples
2025-12-31 12:35:06,221 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 2 captions
2025-12-31 12:35:06,221 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 2 captions
2025-12-31 12:35:06,222 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.20-5.20: work with 2 captions
2025-12-31 12:35:06,222 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:35:08,491 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.43s with 4 samples
2025-12-31 12:35:12,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.30-5.30: work with 1 captions
2025-12-31 12:35:12,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.40-5.40: idle with 3 captions
2025-12-31 12:35:12,861 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.40-5.40: idle with 3 captions
2025-12-31 12:35:12,861 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.30-5.30: work with 1 captions
2025-12-31 12:35:12,861 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.40-5.40: idle with 3 captions
2025-12-31 12:35:12,861 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.40-5.40: idle with 3 captions
2025-12-31 12:35:12,862 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.30-5.30: work with 1 captions
2025-12-31 12:35:12,862 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.40-5.40: idle with 3 captions
2025-12-31 12:35:12,862 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.40-5.40: idle with 3 captions
2025-12-31 12:35:12,863 backend.stream_utils - INFO [PARSE_LLM] Removed 7 duplicate segment(s) in window
2025-12-31 12:35:14,982 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.57s with 4 samples
2025-12-31 12:35:18,015 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.50-5.60: work with 4 captions
2025-12-31 12:35:20,212 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.70s with 4 samples
2025-12-31 12:35:26,674 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.60-5.60: work with 2 captions
2025-12-31 12:35:26,674 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.70-5.70: idle with 2 captions
2025-12-31 12:35:26,674 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.60-5.60: work with 2 captions
2025-12-31 12:35:26,674 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.70-5.70: idle with 2 captions
2025-12-31 12:35:26,675 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.60-5.60: work with 2 captions
2025-12-31 12:35:26,675 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.70-5.70: idle with 2 captions
2025-12-31 12:35:26,675 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.60-5.60: work with 2 captions
2025-12-31 12:35:26,675 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.70-5.70: idle with 2 captions
2025-12-31 12:35:26,675 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.60-5.60: work with 2 captions
2025-12-31 12:35:26,675 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.70-5.70: idle with 2 captions
2025-12-31 12:35:26,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.60-5.60: work with 2 captions
2025-12-31 12:35:26,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.70-5.70: idle with 2 captions
2025-12-31 12:35:26,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.60-5.60: work with 2 captions
2025-12-31 12:35:26,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.70-5.70: idle with 2 captions
2025-12-31 12:35:26,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.60-5.60: work with 2 captions
2025-12-31 12:35:26,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.70-5.70: idle with 2 captions
2025-12-31 12:35:26,677 backend.stream_utils - INFO [PARSE_LLM] Removed 14 duplicate segment(s) in window
2025-12-31 12:35:28,757 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.83s with 4 samples
2025-12-31 12:35:34,236 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.70-5.80: work with 4 captions
2025-12-31 12:35:34,236 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-5.80: idle with 3 captions
2025-12-31 12:35:34,236 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-5.80: work with 3 captions
2025-12-31 12:35:34,236 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.70-5.80: work with 4 captions
2025-12-31 12:35:34,236 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-5.80: idle with 3 captions
2025-12-31 12:35:34,236 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-5.80: work with 3 captions
2025-12-31 12:35:34,236 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.70-5.80: work with 4 captions
2025-12-31 12:35:34,236 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-5.80: idle with 3 captions
2025-12-31 12:35:34,236 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-5.80: work with 3 captions
2025-12-31 12:35:34,236 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:35:36,270 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.97s with 4 samples
2025-12-31 12:35:40,954 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.90-5.90: work with 3 captions
2025-12-31 12:35:40,954 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.00-6.00: work with 1 captions
2025-12-31 12:35:43,135 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.10s with 4 samples
2025-12-31 12:35:53,088 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.23s with 4 samples
2025-12-31 12:35:56,480 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.10-6.20: work with 4 captions
2025-12-31 12:35:58,945 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.37s with 4 samples
2025-12-31 12:36:09,271 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-6.30: work with 3 captions
2025-12-31 12:36:09,271 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.30-6.30: work with 3 captions
2025-12-31 12:36:09,271 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: idle with 1 captions
2025-12-31 12:36:09,271 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-6.30: work with 3 captions
2025-12-31 12:36:09,272 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.30-6.30: work with 3 captions
2025-12-31 12:36:09,272 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: idle with 1 captions
2025-12-31 12:36:09,272 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-6.30: work with 3 captions
2025-12-31 12:36:09,272 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.30-6.30: work with 3 captions
2025-12-31 12:36:09,273 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: idle with 1 captions
2025-12-31 12:36:09,273 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:36:11,605 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.50s with 4 samples
2025-12-31 12:36:17,716 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.40-6.40: work with 2 captions
2025-12-31 12:36:17,716 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.50-6.50: idle with 2 captions
2025-12-31 12:36:17,716 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.50-6.50: idle with 2 captions
2025-12-31 12:36:17,717 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:36:19,728 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.63s with 4 samples
2025-12-31 12:36:30,572 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.50-6.60: work with 4 captions
2025-12-31 12:36:30,572 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: idle with 3 captions
2025-12-31 12:36:30,573 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: work with 3 captions
2025-12-31 12:36:30,573 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.50-6.60: work with 4 captions
2025-12-31 12:36:30,573 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: idle with 3 captions
2025-12-31 12:36:30,573 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: work with 3 captions
2025-12-31 12:36:30,573 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.50-6.50: work with 1 captions
2025-12-31 12:36:30,574 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: idle with 3 captions
2025-12-31 12:36:30,574 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: work with 3 captions
2025-12-31 12:36:30,574 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.50-6.60: work with 4 captions
2025-12-31 12:36:30,574 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: idle with 3 captions
2025-12-31 12:36:30,574 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: work with 3 captions
2025-12-31 12:36:30,575 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.50-6.60: work with 4 captions
2025-12-31 12:36:30,575 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: idle with 3 captions
2025-12-31 12:36:30,575 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: work with 3 captions
2025-12-31 12:36:30,575 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.50-6.60: work with 4 captions
2025-12-31 12:36:30,575 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: idle with 3 captions
2025-12-31 12:36:30,575 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.60-6.60: work with 3 captions
2025-12-31 12:36:30,576 backend.stream_utils - INFO [PARSE_LLM] Removed 14 duplicate segment(s) in window
2025-12-31 12:36:32,572 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.77s with 4 samples
2025-12-31 12:36:45,774 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.70-6.70: work with 3 captions
2025-12-31 12:36:45,774 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.70-6.80: work with 4 captions
2025-12-31 12:36:45,775 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.80-6.80: work with 1 captions
2025-12-31 12:36:47,843 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.90s with 4 samples
2025-12-31 12:36:50,555 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.80-6.80: work with 2 captions
2025-12-31 12:36:50,555 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.90-6.90: idle with 2 captions
2025-12-31 12:36:53,039 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.03s with 4 samples
2025-12-31 12:37:03,643 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.90-6.90: work with 1 captions
2025-12-31 12:37:03,644 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.90-7.00: work with 4 captions
2025-12-31 12:37:03,644 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,644 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,644 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.90-7.00: work with 4 captions
2025-12-31 12:37:03,644 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,644 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,645 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.90-7.00: work with 4 captions
2025-12-31 12:37:03,645 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,645 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,645 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.90-7.00: work with 4 captions
2025-12-31 12:37:03,645 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,645 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,645 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.90-7.00: work with 4 captions
2025-12-31 12:37:03,645 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,646 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,646 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.90-7.00: work with 4 captions
2025-12-31 12:37:03,646 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,646 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.00-7.00: work with 3 captions
2025-12-31 12:37:03,646 backend.stream_utils - INFO [PARSE_LLM] Removed 16 duplicate segment(s) in window
2025-12-31 12:37:06,094 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.17s with 4 samples
2025-12-31 12:37:14,343 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.30s with 4 samples
2025-12-31 12:37:23,039 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.43s with 4 samples
2025-12-31 12:37:27,431 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.30-7.30: work with 1 captions
2025-12-31 12:37:27,431 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.40-7.40: work with 3 captions
2025-12-31 12:37:30,011 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.57s with 4 samples
2025-12-31 12:37:35,229 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.50-7.60: work with 4 captions
2025-12-31 12:37:35,231 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.60-7.60: idle with 1 captions
2025-12-31 12:37:37,699 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.70s with 4 samples
2025-12-31 12:37:46,232 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.60-7.60: work with 2 captions
2025-12-31 12:37:46,233 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.70-7.70: idle with 2 captions
2025-12-31 12:37:46,233 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.60-7.60: work with 2 captions
2025-12-31 12:37:46,233 backend.stream_utils - INFO [PARSE_LLM] Created segment 7.70-7.70: idle with 2 captions
2025-12-31 12:37:46,233 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:37:48,569 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.83s with 4 samples
2025-12-31 12:37:59,285 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.97s with 4 samples
2025-12-31 12:38:09,622 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=8.10s with 4 samples
2025-12-31 12:38:16,996 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-8.10: work with 4 captions
2025-12-31 12:38:16,996 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.10-8.10: idle with 2 captions
2025-12-31 12:38:16,997 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-8.10: work with 4 captions
2025-12-31 12:38:16,997 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.10-8.10: idle with 2 captions
2025-12-31 12:38:16,998 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:38:19,454 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=8.23s with 4 samples
2025-12-31 12:38:24,792 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=8.37s with 4 samples
2025-12-31 12:38:51,989 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.30-8.30: work with 3 captions
2025-12-31 12:38:51,989 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.40-8.40: idle with 1 captions
2025-12-31 12:38:54,729 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=8.50s with 4 samples
2025-12-31 12:39:04,404 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=8.63s with 4 samples
2025-12-31 12:39:18,387 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.50-8.60: work with 4 captions
2025-12-31 12:39:18,389 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 3 captions
2025-12-31 12:39:18,389 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 3 captions
2025-12-31 12:39:18,390 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.50-8.60: work with 4 captions
2025-12-31 12:39:18,390 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 3 captions
2025-12-31 12:39:18,390 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.60-8.60: work with 3 captions
2025-12-31 12:39:18,390 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:39:20,912 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=8.77s with 4 samples
2025-12-31 12:39:29,742 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.70-8.70: work with 3 captions
2025-12-31 12:39:29,743 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.70-8.80: work with 4 captions
2025-12-31 12:39:29,743 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.80-8.80: work with 1 captions
2025-12-31 12:39:32,309 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=8.90s with 4 samples
2025-12-31 12:39:37,467 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.80-8.80: work with 2 captions
2025-12-31 12:39:37,468 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.90-8.90: idle with 2 captions
2025-12-31 12:39:37,468 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.90-8.90: work with 2 captions
2025-12-31 12:39:37,469 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.80-8.80: work with 2 captions
2025-12-31 12:39:37,469 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.90-8.90: idle with 2 captions
2025-12-31 12:39:37,469 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.90-8.90: work with 2 captions
2025-12-31 12:39:37,470 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.80-8.80: work with 2 captions
2025-12-31 12:39:37,470 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.90-8.90: idle with 2 captions
2025-12-31 12:39:37,470 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.90-8.90: work with 2 captions
2025-12-31 12:39:37,470 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:39:39,931 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=9.03s with 4 samples
2025-12-31 12:39:50,533 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=9.17s with 4 samples
2025-12-31 12:39:57,201 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.10-9.10: work with 3 captions
2025-12-31 12:39:57,202 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.20-9.20: idle with 1 captions
2025-12-31 12:39:57,202 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.10-9.10: work with 3 captions
2025-12-31 12:39:57,202 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.20-9.20: idle with 1 captions
2025-12-31 12:39:57,202 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.10-9.10: work with 3 captions
2025-12-31 12:39:57,202 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.20-9.20: idle with 1 captions
2025-12-31 12:39:57,203 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.10-9.10: work with 3 captions
2025-12-31 12:39:57,203 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.20-9.20: idle with 1 captions
2025-12-31 12:39:57,203 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:39:59,699 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=9.30s with 4 samples
2025-12-31 12:40:05,535 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.20-9.20: work with 2 captions
2025-12-31 12:40:05,535 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.30-9.30: work with 2 captions
2025-12-31 12:40:05,536 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.20-9.20: work with 2 captions
2025-12-31 12:40:05,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.30-9.30: work with 2 captions
2025-12-31 12:40:05,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.20-9.20: work with 2 captions
2025-12-31 12:40:05,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.30-9.30: work with 2 captions
2025-12-31 12:40:05,539 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.20-9.20: work with 2 captions
2025-12-31 12:40:05,540 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.30-9.30: work with 2 captions
2025-12-31 12:40:05,541 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:40:07,968 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=9.43s with 4 samples
2025-12-31 12:40:21,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.30-9.40: work with 4 captions
2025-12-31 12:40:21,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.40-9.40: work with 3 captions
2025-12-31 12:40:21,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.40-9.40: work with 3 captions
2025-12-31 12:40:21,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.40-9.40: work with 3 captions
2025-12-31 12:40:21,902 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.30-9.40: work with 4 captions
2025-12-31 12:40:21,902 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.40-9.40: work with 3 captions
2025-12-31 12:40:21,902 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.40-9.40: work with 3 captions
2025-12-31 12:40:21,903 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.40-9.40: work with 3 captions
2025-12-31 12:40:21,903 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:40:24,398 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=9.57s with 4 samples
2025-12-31 12:40:35,809 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=9.70s with 4 samples
2025-12-31 12:40:39,667 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.60-9.60: work with 2 captions
2025-12-31 12:40:39,667 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.70-9.70: idle with 2 captions
2025-12-31 12:40:41,968 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=9.83s with 4 samples
2025-12-31 12:40:54,850 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=9.97s with 4 samples
2025-12-31 12:40:58,616 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.90-9.90: work with 3 captions
2025-12-31 12:40:58,616 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-10.00: work with 1 captions
2025-12-31 12:40:58,616 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.90-9.90: work with 3 captions
2025-12-31 12:40:58,616 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-10.00: work with 1 captions
2025-12-31 12:40:58,616 backend.stream_utils - INFO [PARSE_LLM] Created segment 9.90-9.90: work with 3 captions
2025-12-31 12:40:58,617 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-10.00: work with 1 captions
2025-12-31 12:40:58,617 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:41:00,871 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=10.10s with 4 samples
2025-12-31 12:41:09,855 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-10.00: work with 2 captions
2025-12-31 12:41:09,859 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.10-10.10: idle with 2 captions
2025-12-31 12:41:09,863 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-10.00: work with 2 captions
2025-12-31 12:41:09,866 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.10-10.10: idle with 2 captions
2025-12-31 12:41:09,867 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-10.00: work with 2 captions
2025-12-31 12:41:09,870 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.10-10.10: idle with 2 captions
2025-12-31 12:41:09,873 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-10.00: work with 2 captions
2025-12-31 12:41:09,876 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.10-10.10: idle with 2 captions
2025-12-31 12:41:09,880 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-10.00: work with 2 captions
2025-12-31 12:41:09,880 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.10-10.10: idle with 2 captions
2025-12-31 12:41:09,885 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-10.00: work with 2 captions
2025-12-31 12:41:09,887 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.10-10.10: idle with 2 captions
2025-12-31 12:41:09,891 backend.stream_utils - INFO [PARSE_LLM] Removed 10 duplicate segment(s) in window
2025-12-31 12:41:12,197 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=10.23s with 4 samples
2025-12-31 12:41:25,747 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.10-10.20: work with 4 captions
2025-12-31 12:41:25,747 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.10-10.20: work with 4 captions
2025-12-31 12:41:25,748 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.10-10.20: work with 4 captions
2025-12-31 12:41:25,748 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:41:28,045 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=10.37s with 4 samples
2025-12-31 12:41:32,475 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.30-10.30: work with 3 captions
2025-12-31 12:41:32,476 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.40-10.40: work with 1 captions
2025-12-31 12:41:34,661 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=10.50s with 4 samples
2025-12-31 12:41:37,460 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.40-10.40: work with 2 captions
2025-12-31 12:41:37,460 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.50-10.50: idle with 2 captions
2025-12-31 12:41:39,788 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=10.63s with 4 samples
2025-12-31 12:41:46,680 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.50-10.60: work with 4 captions
2025-12-31 12:41:46,681 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.60-10.60: idle with 3 captions
2025-12-31 12:41:46,682 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.60-10.60: idle with 3 captions
2025-12-31 12:41:46,683 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.50-10.60: work with 4 captions
2025-12-31 12:41:46,683 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.60-10.60: idle with 3 captions
2025-12-31 12:41:46,684 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.60-10.60: idle with 3 captions
2025-12-31 12:41:46,684 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.50-10.60: work with 4 captions
2025-12-31 12:41:46,684 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.60-10.60: idle with 3 captions
2025-12-31 12:41:46,685 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.60-10.60: idle with 3 captions
2025-12-31 12:41:46,685 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.50-10.60: work with 4 captions
2025-12-31 12:41:46,686 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.60-10.60: idle with 3 captions
2025-12-31 12:41:46,686 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.60-10.60: idle with 3 captions
2025-12-31 12:41:46,686 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.50-10.60: work with 4 captions
2025-12-31 12:41:46,687 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.60-10.60: idle with 3 captions
2025-12-31 12:41:46,687 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.60-10.60: idle with 3 captions
2025-12-31 12:41:46,687 backend.stream_utils - INFO [PARSE_LLM] Removed 13 duplicate segment(s) in window
2025-12-31 12:41:48,736 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=10.77s with 4 samples
2025-12-31 12:41:54,602 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-10.70: work with 3 captions
2025-12-31 12:41:54,603 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.70-10.70: work with 3 captions
2025-12-31 12:41:54,603 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.80-10.80: idle with 1 captions
2025-12-31 12:41:54,604 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:41:56,956 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=10.90s with 4 samples
2025-12-31 12:42:04,539 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=11.03s with 4 samples
2025-12-31 12:42:13,775 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.90-11.00: idle with 4 captions
2025-12-31 12:42:13,776 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.00-11.00: work with 3 captions
2025-12-31 12:42:13,777 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.00-11.00: work with 3 captions
2025-12-31 12:42:13,777 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.90-11.00: idle with 4 captions
2025-12-31 12:42:13,777 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.00-11.00: work with 3 captions
2025-12-31 12:42:13,777 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.00-11.00: work with 3 captions
2025-12-31 12:42:13,778 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.90-11.00: idle with 4 captions
2025-12-31 12:42:13,778 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.00-11.00: work with 3 captions
2025-12-31 12:42:13,778 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.00-11.00: work with 3 captions
2025-12-31 12:42:13,778 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.90-11.00: idle with 4 captions
2025-12-31 12:42:13,778 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.00-11.00: work with 3 captions
2025-12-31 12:42:13,778 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.00-11.00: work with 3 captions
2025-12-31 12:42:13,779 backend.stream_utils - INFO [PARSE_LLM] Removed 10 duplicate segment(s) in window
2025-12-31 12:42:15,885 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=11.17s with 4 samples
2025-12-31 12:42:20,239 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.10-11.10: work with 3 captions
2025-12-31 12:42:20,239 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.10-11.20: work with 4 captions
2025-12-31 12:42:22,540 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=11.30s with 4 samples
2025-12-31 12:42:30,002 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.20-11.20: work with 2 captions
2025-12-31 12:42:30,004 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.30-11.30: idle with 2 captions
2025-12-31 12:42:30,004 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.30-11.30: work with 2 captions
2025-12-31 12:42:30,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.20-11.20: work with 2 captions
2025-12-31 12:42:30,006 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.30-11.30: idle with 2 captions
2025-12-31 12:42:30,006 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.30-11.30: work with 2 captions
2025-12-31 12:42:30,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.20-11.20: work with 2 captions
2025-12-31 12:42:30,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.30-11.30: idle with 2 captions
2025-12-31 12:42:30,008 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.30-11.30: work with 2 captions
2025-12-31 12:42:30,008 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:42:32,747 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=11.43s with 4 samples
2025-12-31 12:42:40,042 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.30-11.40: work with 4 captions
2025-12-31 12:42:40,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.30-11.40: work with 4 captions
2025-12-31 12:42:40,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.40-11.40: idle with 3 captions
2025-12-31 12:42:40,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.30-11.40: work with 4 captions
2025-12-31 12:42:40,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.40-11.40: idle with 3 captions
2025-12-31 12:42:40,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.30-11.40: work with 4 captions
2025-12-31 12:42:40,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.40-11.40: idle with 3 captions
2025-12-31 12:42:40,044 backend.stream_utils - INFO [PARSE_LLM] Removed 5 duplicate segment(s) in window
2025-12-31 12:42:42,250 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=11.57s with 4 samples
2025-12-31 12:42:49,797 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=11.70s with 4 samples
2025-12-31 12:42:52,862 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.60-11.60: work with 2 captions
2025-12-31 12:42:52,864 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.70-11.70: idle with 2 captions
2025-12-31 12:42:52,864 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.70-11.70: work with 2 captions
2025-12-31 12:42:55,821 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=11.83s with 4 samples
2025-12-31 12:43:05,896 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.70-11.80: work with 4 captions
2025-12-31 12:43:08,744 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=11.97s with 4 samples
2025-12-31 12:43:14,179 backend.stream_utils - INFO [PARSE_LLM] Created segment 11.90-12.00: work with 4 captions
2025-12-31 12:43:16,557 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=12.10s with 4 samples
2025-12-31 12:43:20,716 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 12:43:20,718 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 12:43:22,723 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=12.23s with 4 samples
2025-12-31 12:43:26,576 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.10-12.20: work with 4 captions
2025-12-31 12:43:26,576 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.20-12.20: idle with 3 captions
2025-12-31 12:43:26,577 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.10-12.20: work with 4 captions
2025-12-31 12:43:26,577 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.20-12.20: idle with 3 captions
2025-12-31 12:43:26,577 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:43:29,269 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=12.37s with 4 samples
2025-12-31 12:43:36,760 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=12.50s with 4 samples
2025-12-31 12:43:40,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.40-12.50: work with 4 captions
2025-12-31 12:43:40,282 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.50-12.50: idle with 2 captions
2025-12-31 12:43:42,207 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=12.63s with 4 samples
2025-12-31 12:43:45,853 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.50-12.60: work with 4 captions
2025-12-31 12:43:47,975 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=12.77s with 4 samples
2025-12-31 12:43:55,988 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=12.90s with 4 samples
2025-12-31 12:44:05,791 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=13.03s with 4 samples
2025-12-31 12:44:09,906 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.90-13.00: work with 4 captions
2025-12-31 12:44:09,906 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.00-13.00: idle with 3 captions
2025-12-31 12:44:12,198 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=13.17s with 4 samples
2025-12-31 12:44:17,637 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-13.10: work with 3 captions
2025-12-31 12:44:17,637 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.10-13.10: idle with 3 captions
2025-12-31 12:44:17,637 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.20-13.20: work with 1 captions
2025-12-31 12:44:17,638 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-13.10: work with 3 captions
2025-12-31 12:44:17,638 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.10-13.10: idle with 3 captions
2025-12-31 12:44:17,638 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.20-13.20: work with 1 captions
2025-12-31 12:44:17,638 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-31 12:44:19,664 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=13.30s with 4 samples
2025-12-31 12:44:25,505 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.20-13.30: work with 4 captions
2025-12-31 12:44:25,505 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.30-13.40: work with 2 captions
2025-12-31 12:44:27,492 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=13.43s with 4 samples
2025-12-31 12:44:31,213 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.30-13.40: work with 4 captions
2025-12-31 12:44:33,340 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=13.57s with 4 samples
2025-12-31 12:44:42,358 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=13.70s with 4 samples
2025-12-31 12:44:50,652 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=13.83s with 4 samples
2025-12-31 12:45:02,050 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.70-13.80: work with 4 captions
2025-12-31 12:45:04,149 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=13.97s with 4 samples
2025-12-31 12:45:08,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.90-13.90: work with 3 captions
2025-12-31 12:45:08,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.90-13.90: work with 3 captions
2025-12-31 12:45:08,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.90-13.90: work with 3 captions
2025-12-31 12:45:08,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.00-14.00: work with 1 captions
2025-12-31 12:45:08,677 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:45:10,673 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.10s with 4 samples
2025-12-31 12:45:18,927 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.10-14.10: idle with 2 captions
2025-12-31 12:45:18,927 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.10-14.10: idle with 2 captions
2025-12-31 12:45:18,927 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.10-14.10: idle with 2 captions
2025-12-31 12:45:18,928 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:45:20,803 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.23s with 4 samples
2025-12-31 12:45:26,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.10-14.20: work with 4 captions
2025-12-31 12:45:26,116 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.20-14.20: work with 3 captions
2025-12-31 12:45:26,116 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.10-14.20: work with 4 captions
2025-12-31 12:45:26,116 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.20-14.20: work with 3 captions
2025-12-31 12:45:26,116 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.10-14.20: work with 4 captions
2025-12-31 12:45:26,116 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.20-14.20: work with 3 captions
2025-12-31 12:45:26,117 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:45:28,254 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.37s with 4 samples
2025-12-31 12:45:34,806 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.50s with 4 samples
2025-12-31 12:45:49,557 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.63s with 4 samples
2025-12-31 12:45:57,351 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.50-14.60: work with 4 captions
2025-12-31 12:45:57,351 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.60-14.60: work with 3 captions
2025-12-31 12:45:57,351 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.60-14.60: work with 3 captions
2025-12-31 12:45:57,351 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.50-14.60: work with 4 captions
2025-12-31 12:45:57,352 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.60-14.60: work with 3 captions
2025-12-31 12:45:57,352 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.60-14.60: work with 3 captions
2025-12-31 12:45:57,352 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.50-14.60: work with 4 captions
2025-12-31 12:45:57,352 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.60-14.60: work with 3 captions
2025-12-31 12:45:57,352 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.60-14.60: work with 3 captions
2025-12-31 12:45:57,352 backend.stream_utils - INFO [PARSE_LLM] Removed 7 duplicate segment(s) in window
2025-12-31 12:45:59,527 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.77s with 4 samples
2025-12-31 12:46:07,088 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.90s with 4 samples
2025-12-31 12:46:13,582 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.80-14.80: work with 2 captions
2025-12-31 12:46:13,583 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.90-14.90: idle with 2 captions
2025-12-31 12:46:13,583 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.80-14.80: work with 2 captions
2025-12-31 12:46:13,583 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:46:15,678 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.03s with 4 samples
2025-12-31 12:46:23,516 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.90-15.00: work with 4 captions
2025-12-31 12:46:23,517 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 3 captions
2025-12-31 12:46:23,518 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 3 captions
2025-12-31 12:46:23,519 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.90-15.00: work with 4 captions
2025-12-31 12:46:23,519 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 3 captions
2025-12-31 12:46:23,519 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 3 captions
2025-12-31 12:46:23,520 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.90-15.00: work with 4 captions
2025-12-31 12:46:23,520 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 3 captions
2025-12-31 12:46:23,520 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 3 captions
2025-12-31 12:46:23,520 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.90-15.00: work with 4 captions
2025-12-31 12:46:23,520 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 3 captions
2025-12-31 12:46:23,520 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: work with 3 captions
2025-12-31 12:46:23,520 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-31 12:46:25,672 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.17s with 4 samples
2025-12-31 12:46:37,679 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.30s with 4 samples
2025-12-31 12:46:49,593 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.43s with 4 samples
2025-12-31 12:46:56,753 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.57s with 4 samples
2025-12-31 12:47:03,335 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-15.50: work with 3 captions
2025-12-31 12:47:03,335 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.50-15.50: work with 3 captions
2025-12-31 12:47:03,335 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-15.60: idle with 1 captions
2025-12-31 12:47:03,335 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-15.50: work with 3 captions
2025-12-31 12:47:03,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-15.60: idle with 1 captions
2025-12-31 12:47:03,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-15.50: work with 3 captions
2025-12-31 12:47:03,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-15.60: idle with 1 captions
2025-12-31 12:47:03,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-15.50: work with 3 captions
2025-12-31 12:47:03,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-15.60: idle with 1 captions
2025-12-31 12:47:03,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-15.50: work with 3 captions
2025-12-31 12:47:03,338 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-15.60: idle with 1 captions
2025-12-31 12:47:03,338 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-31 12:47:05,607 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.70s with 4 samples
2025-12-31 12:47:11,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-15.60: work with 2 captions
2025-12-31 12:47:11,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.70-15.70: idle with 2 captions
2025-12-31 12:47:11,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-15.60: work with 2 captions
2025-12-31 12:47:11,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.70-15.70: idle with 2 captions
2025-12-31 12:47:11,484 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.60-15.60: work with 2 captions
2025-12-31 12:47:11,485 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.70-15.70: idle with 2 captions
2025-12-31 12:47:11,485 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:47:13,518 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.83s with 4 samples
2025-12-31 12:47:20,319 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.70-15.80: work with 4 captions
2025-12-31 12:47:20,319 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.80-15.80: work with 3 captions
2025-12-31 12:47:20,319 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.80-15.80: work with 3 captions
2025-12-31 12:47:20,320 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:47:23,084 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.97s with 4 samples
2025-12-31 12:47:35,169 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-15.90: work with 3 captions
2025-12-31 12:47:35,170 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.90-15.90: work with 3 captions
2025-12-31 12:47:35,170 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-16.00: idle with 1 captions
2025-12-31 12:47:35,171 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.90-15.90: work with 3 captions
2025-12-31 12:47:35,172 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-16.00: idle with 1 captions
2025-12-31 12:47:35,173 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.90-15.90: work with 3 captions
2025-12-31 12:47:35,175 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.90-15.90: work with 3 captions
2025-12-31 12:47:35,177 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-16.00: idle with 1 captions
2025-12-31 12:47:35,179 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.90-15.90: work with 3 captions
2025-12-31 12:47:35,181 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-16.00: idle with 1 captions
2025-12-31 12:47:35,181 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.90-15.90: work with 3 captions
2025-12-31 12:47:35,182 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-16.00: idle with 1 captions
2025-12-31 12:47:35,183 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.90-15.90: work with 3 captions
2025-12-31 12:47:35,183 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-16.00: idle with 1 captions
2025-12-31 12:47:35,183 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.90-15.90: work with 3 captions
2025-12-31 12:47:35,184 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-16.00: idle with 1 captions
2025-12-31 12:47:35,184 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.90-15.90: work with 3 captions
2025-12-31 12:47:35,184 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-16.00: idle with 1 captions
2025-12-31 12:47:35,184 backend.stream_utils - INFO [PARSE_LLM] Removed 15 duplicate segment(s) in window
2025-12-31 12:47:37,301 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=16.10s with 4 samples
2025-12-31 12:47:48,526 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=16.23s with 4 samples
2025-12-31 12:47:52,661 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.10-16.10: work with 1 captions
2025-12-31 12:47:52,661 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.20-16.20: idle with 3 captions
2025-12-31 12:47:52,662 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.20-16.20: work with 3 captions
2025-12-31 12:47:55,019 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=16.37s with 4 samples
2025-12-31 12:47:59,137 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.30-16.30: work with 3 captions
2025-12-31 12:47:59,138 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.40-16.40: idle with 1 captions
2025-12-31 12:47:59,138 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.30-16.30: work with 3 captions
2025-12-31 12:47:59,138 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.40-16.40: idle with 1 captions
2025-12-31 12:47:59,138 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.30-16.30: work with 3 captions
2025-12-31 12:47:59,139 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.40-16.40: idle with 1 captions
2025-12-31 12:47:59,139 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:48:01,384 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=16.50s with 4 samples
2025-12-31 12:48:11,568 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.40-16.40: work with 2 captions
2025-12-31 12:48:11,568 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.50-16.50: work with 2 captions
2025-12-31 12:48:11,569 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.40-16.40: work with 2 captions
2025-12-31 12:48:11,569 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.50-16.50: work with 2 captions
2025-12-31 12:48:11,569 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.40-16.40: work with 2 captions
2025-12-31 12:48:11,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.50-16.50: work with 2 captions
2025-12-31 12:48:11,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.40-16.40: work with 2 captions
2025-12-31 12:48:11,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.50-16.50: work with 2 captions
2025-12-31 12:48:11,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.40-16.40: work with 2 captions
2025-12-31 12:48:11,570 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.50-16.50: work with 2 captions
2025-12-31 12:48:11,570 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-31 12:48:14,249 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=16.63s with 4 samples
2025-12-31 12:48:20,033 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=16.77s with 4 samples
2025-12-31 12:48:24,384 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.70-16.80: work with 4 captions
2025-12-31 12:48:27,179 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=16.90s with 4 samples
2025-12-31 12:48:38,146 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,147 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: work with 2 captions
2025-12-31 12:48:38,149 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,149 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: work with 2 captions
2025-12-31 12:48:38,150 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,150 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: idle with 2 captions
2025-12-31 12:48:38,151 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,152 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: work with 2 captions
2025-12-31 12:48:38,152 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,153 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: idle with 2 captions
2025-12-31 12:48:38,155 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,155 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,156 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: work with 2 captions
2025-12-31 12:48:38,157 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,158 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: work with 2 captions
2025-12-31 12:48:38,159 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.90: idle with 4 captions
2025-12-31 12:48:38,160 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,161 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,162 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: idle with 2 captions
2025-12-31 12:48:38,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: idle with 2 captions
2025-12-31 12:48:38,164 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,165 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: work with 2 captions
2025-12-31 12:48:38,166 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,167 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: idle with 2 captions
2025-12-31 12:48:38,167 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.80-16.80: work with 2 captions
2025-12-31 12:48:38,168 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-16.90: work with 2 captions
2025-12-31 12:48:38,169 backend.stream_utils - INFO [PARSE_LLM] Removed 23 duplicate segment(s) in window
2025-12-31 12:48:40,623 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=17.03s with 4 samples
2025-12-31 12:48:44,807 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-17.00: work with 4 captions
2025-12-31 12:48:44,813 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.00-17.00: work with 3 captions
2025-12-31 12:48:44,815 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.00-17.00: work with 3 captions
2025-12-31 12:48:44,817 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-17.00: work with 4 captions
2025-12-31 12:48:44,820 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.00-17.00: work with 3 captions
2025-12-31 12:48:44,821 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.00-17.00: work with 3 captions
2025-12-31 12:48:44,822 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.90-17.00: work with 4 captions
2025-12-31 12:48:44,822 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.00-17.00: work with 3 captions
2025-12-31 12:48:44,823 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.00-17.00: work with 3 captions
2025-12-31 12:48:44,824 backend.stream_utils - INFO [PARSE_LLM] Removed 7 duplicate segment(s) in window
2025-12-31 12:48:46,722 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=17.17s with 4 samples
2025-12-31 12:48:50,880 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 3 captions
2025-12-31 12:48:50,880 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.20-17.20: idle with 1 captions
2025-12-31 12:48:50,881 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 3 captions
2025-12-31 12:48:50,881 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.20-17.20: idle with 1 captions
2025-12-31 12:48:50,882 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.10-17.10: work with 3 captions
2025-12-31 12:48:50,883 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.20-17.20: idle with 1 captions
2025-12-31 12:48:50,883 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:48:52,890 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=17.30s with 4 samples
2025-12-31 12:48:56,727 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.20-17.20: work with 2 captions
2025-12-31 12:48:56,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.30-17.30: idle with 2 captions
2025-12-31 12:48:56,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.30-17.30: work with 2 captions
2025-12-31 12:48:58,690 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=17.43s with 4 samples
2025-12-31 12:49:14,874 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.30-17.40: work with 4 captions
2025-12-31 12:49:14,874 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.40-17.40: idle with 3 captions
2025-12-31 12:49:14,875 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.40-17.40: work with 3 captions
2025-12-31 12:49:16,665 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=17.57s with 4 samples
2025-12-31 12:49:34,727 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=17.70s with 4 samples
2025-12-31 12:49:40,023 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=17.83s with 4 samples
2025-12-31 12:49:44,428 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 12:49:44,428 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 12:49:46,854 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=17.97s with 4 samples
2025-12-31 12:49:51,805 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.90-17.90: work with 3 captions
2025-12-31 12:49:51,806 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-18.00: work with 1 captions
2025-12-31 12:49:54,305 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=18.10s with 4 samples
2025-12-31 12:49:58,058 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-18.00: work with 2 captions
2025-12-31 12:49:58,058 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-18.00: work with 2 captions
2025-12-31 12:49:58,058 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.10-18.10: work with 2 captions
2025-12-31 12:49:58,059 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.10-18.10: work with 2 captions
2025-12-31 12:49:58,059 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-18.00: work with 2 captions
2025-12-31 12:49:58,059 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-18.00: work with 2 captions
2025-12-31 12:49:58,059 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.10-18.10: work with 2 captions
2025-12-31 12:49:58,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.10-18.10: work with 2 captions
2025-12-31 12:49:58,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-18.00: work with 2 captions
2025-12-31 12:49:58,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-18.00: work with 2 captions
2025-12-31 12:49:58,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.10-18.10: work with 2 captions
2025-12-31 12:49:58,060 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.10-18.10: work with 2 captions
2025-12-31 12:49:58,060 backend.stream_utils - INFO [PARSE_LLM] Removed 10 duplicate segment(s) in window
2025-12-31 12:49:59,834 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=18.23s with 4 samples
2025-12-31 12:50:08,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.10-18.10: work with 1 captions
2025-12-31 12:50:11,052 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=18.37s with 4 samples
2025-12-31 12:50:15,460 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.30-18.30: work with 3 captions
2025-12-31 12:50:15,460 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.40-18.40: work with 1 captions
2025-12-31 12:50:17,211 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=18.50s with 4 samples
2025-12-31 12:50:22,991 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=18.63s with 4 samples
2025-12-31 12:50:33,175 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.50-18.60: work with 4 captions
2025-12-31 12:50:33,175 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.50-18.60: work with 4 captions
2025-12-31 12:50:33,175 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,176 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,176 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,176 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.50-18.60: work with 4 captions
2025-12-31 12:50:33,176 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,177 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,177 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,177 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.50-18.60: work with 4 captions
2025-12-31 12:50:33,177 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,177 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,177 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,177 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.50-18.60: work with 4 captions
2025-12-31 12:50:33,179 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,179 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,179 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,179 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.50-18.60: work with 4 captions
2025-12-31 12:50:33,179 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,180 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,180 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.60-18.60: work with 3 captions
2025-12-31 12:50:33,180 backend.stream_utils - INFO [PARSE_LLM] Removed 19 duplicate segment(s) in window
2025-12-31 12:50:35,645 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=18.77s with 4 samples
2025-12-31 12:50:41,759 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.70-18.70: work with 3 captions
2025-12-31 12:50:41,760 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.80-18.80: work with 1 captions
2025-12-31 12:50:44,439 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=18.90s with 4 samples
2025-12-31 12:50:48,275 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 12:50:48,276 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 12:50:50,695 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=19.03s with 4 samples
2025-12-31 12:51:07,533 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=19.17s with 4 samples
2025-12-31 12:51:14,545 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=19.30s with 4 samples
2025-12-31 12:51:19,430 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.20-19.20: work with 2 captions
2025-12-31 12:51:19,430 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-19.30: idle with 2 captions
2025-12-31 12:51:19,431 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.20-19.20: work with 2 captions
2025-12-31 12:51:19,431 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-19.30: idle with 2 captions
2025-12-31 12:51:19,431 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:51:22,077 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=19.43s with 4 samples
2025-12-31 12:51:24,541 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.30-19.40: work with 4 captions
2025-12-31 12:51:27,647 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=19.57s with 4 samples
2025-12-31 12:51:32,912 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.50-19.50: work with 3 captions
2025-12-31 12:51:32,912 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.60-19.60: work with 1 captions
2025-12-31 12:51:32,912 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.50-19.50: work with 3 captions
2025-12-31 12:51:32,913 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.60-19.60: work with 1 captions
2025-12-31 12:51:32,913 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.50-19.50: work with 3 captions
2025-12-31 12:51:32,913 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.60-19.60: work with 1 captions
2025-12-31 12:51:32,913 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:51:35,073 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=19.70s with 4 samples
2025-12-31 12:51:40,333 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.60-19.60: work with 2 captions
2025-12-31 12:51:40,337 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.70-19.70: idle with 2 captions
2025-12-31 12:51:40,338 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.60-19.60: work with 2 captions
2025-12-31 12:51:40,338 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.70-19.70: idle with 2 captions
2025-12-31 12:51:40,338 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.60-19.60: work with 2 captions
2025-12-31 12:51:40,338 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.70-19.70: idle with 2 captions
2025-12-31 12:51:40,339 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:51:42,234 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=19.83s with 4 samples
2025-12-31 12:51:51,687 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.80-19.80: work with 3 captions
2025-12-31 12:51:53,788 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=19.97s with 4 samples
2025-12-31 12:51:56,916 backend.stream_utils - INFO [PARSE_LLM] Created segment 19.90-19.90: work with 3 captions
2025-12-31 12:51:56,917 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-20.00: work with 1 captions
2025-12-31 12:51:58,671 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=20.10s with 4 samples
2025-12-31 12:52:03,341 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.00-20.10: work with 4 captions
2025-12-31 12:52:03,341 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.10-20.10: work with 2 captions
2025-12-31 12:52:05,122 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=20.23s with 4 samples
2025-12-31 12:52:10,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.10-20.10: work with 1 captions
2025-12-31 12:52:12,615 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=20.37s with 4 samples
2025-12-31 12:52:16,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.30-20.30: work with 3 captions
2025-12-31 12:52:16,746 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.40-20.40: work with 1 captions
2025-12-31 12:52:18,974 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=20.50s with 4 samples
2025-12-31 12:52:23,904 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.40-20.50: work with 4 captions
2025-12-31 12:52:23,904 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.50-20.50: work with 2 captions
2025-12-31 12:52:26,245 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=20.63s with 4 samples
2025-12-31 12:52:28,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.50-20.60: work with 4 captions
2025-12-31 12:52:31,373 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=20.77s with 4 samples
2025-12-31 12:52:38,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.70-20.70: work with 3 captions
2025-12-31 12:52:38,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.70-20.70: work with 3 captions
2025-12-31 12:52:38,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.80-20.80: work with 1 captions
2025-12-31 12:52:38,077 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:52:40,636 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=20.90s with 4 samples
2025-12-31 12:52:45,053 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.80-20.80: work with 2 captions
2025-12-31 12:52:45,053 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.90-20.90: idle with 2 captions
2025-12-31 12:52:45,054 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.80-20.80: work with 2 captions
2025-12-31 12:52:45,054 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.90-20.90: idle with 2 captions
2025-12-31 12:52:45,054 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:52:47,303 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=21.03s with 4 samples
2025-12-31 12:52:49,664 backend.stream_utils - INFO [PARSE_LLM] Created segment 20.90-20.90: work with 1 captions
2025-12-31 12:52:49,665 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.00-21.00: work with 3 captions
2025-12-31 12:52:51,756 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=21.17s with 4 samples
2025-12-31 12:52:55,179 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.10-21.10: work with 3 captions
2025-12-31 12:52:55,180 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.10-21.20: work with 4 captions
2025-12-31 12:52:57,047 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=21.30s with 4 samples
2025-12-31 12:53:00,375 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.20-21.20: work with 2 captions
2025-12-31 12:53:00,375 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.30-21.30: work with 2 captions
2025-12-31 12:53:00,376 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.20-21.20: work with 2 captions
2025-12-31 12:53:00,376 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.30-21.30: work with 2 captions
2025-12-31 12:53:00,376 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:53:03,026 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=21.43s with 4 samples
2025-12-31 12:53:09,600 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=21.57s with 4 samples
2025-12-31 12:53:18,336 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=21.70s with 4 samples
2025-12-31 12:53:22,024 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.60-21.60: work with 2 captions
2025-12-31 12:53:22,024 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.70-21.70: work with 2 captions
2025-12-31 12:53:24,380 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=21.83s with 4 samples
2025-12-31 12:53:27,447 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.70-21.80: work with 4 captions
2025-12-31 12:53:27,447 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.80-21.80: work with 3 captions
2025-12-31 12:53:27,447 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.80-21.80: work with 3 captions
2025-12-31 12:53:27,448 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.80-21.80: work with 3 captions
2025-12-31 12:53:27,448 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:53:30,035 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=21.97s with 4 samples
2025-12-31 12:53:35,947 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.90-21.90: work with 3 captions
2025-12-31 12:53:35,949 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.00-22.00: work with 1 captions
2025-12-31 12:53:35,950 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.90-21.90: work with 3 captions
2025-12-31 12:53:35,950 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.00-22.00: work with 1 captions
2025-12-31 12:53:35,950 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.90-21.90: work with 3 captions
2025-12-31 12:53:35,951 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.00-22.00: work with 1 captions
2025-12-31 12:53:35,951 backend.stream_utils - INFO [PARSE_LLM] Created segment 21.90-21.90: work with 3 captions
2025-12-31 12:53:35,952 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.00-22.00: work with 1 captions
2025-12-31 12:53:35,952 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:53:38,528 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.10s with 4 samples
2025-12-31 12:53:46,834 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.23s with 4 samples
2025-12-31 12:53:50,940 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.10-22.20: work with 4 captions
2025-12-31 12:53:50,941 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.20-22.20: work with 3 captions
2025-12-31 12:53:53,253 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.37s with 4 samples
2025-12-31 12:54:01,295 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.30-22.30: work with 3 captions
2025-12-31 12:54:01,296 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.30-22.30: work with 3 captions
2025-12-31 12:54:01,296 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.40-22.40: work with 1 captions
2025-12-31 12:54:01,296 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:54:03,425 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.50s with 4 samples
2025-12-31 12:54:10,629 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.63s with 4 samples
2025-12-31 12:54:19,942 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.77s with 4 samples
2025-12-31 12:54:23,353 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.70-22.80: work with 4 captions
2025-12-31 12:54:25,940 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.90s with 4 samples
2025-12-31 12:54:40,277 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.80-22.80: work with 2 captions
2025-12-31 12:54:43,240 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.03s with 4 samples
2025-12-31 12:54:47,446 backend.stream_utils - INFO [PARSE_LLM] Created segment 22.90-22.90: work with 1 captions
2025-12-31 12:54:47,447 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.00-23.00: idle with 3 captions
2025-12-31 12:54:49,523 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.17s with 4 samples
2025-12-31 12:55:00,674 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: work with 3 captions
2025-12-31 12:55:00,675 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: idle with 3 captions
2025-12-31 12:55:00,675 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.20-23.20: idle with 1 captions
2025-12-31 12:55:00,675 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: work with 3 captions
2025-12-31 12:55:00,675 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: idle with 3 captions
2025-12-31 12:55:00,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.20-23.20: idle with 1 captions
2025-12-31 12:55:00,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: work with 3 captions
2025-12-31 12:55:00,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: idle with 3 captions
2025-12-31 12:55:00,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.20-23.20: idle with 1 captions
2025-12-31 12:55:00,676 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: work with 3 captions
2025-12-31 12:55:00,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: idle with 3 captions
2025-12-31 12:55:00,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.20-23.20: idle with 1 captions
2025-12-31 12:55:00,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: work with 3 captions
2025-12-31 12:55:00,677 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: idle with 3 captions
2025-12-31 12:55:00,678 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.20-23.20: idle with 1 captions
2025-12-31 12:55:00,678 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: work with 3 captions
2025-12-31 12:55:00,678 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.10-23.10: idle with 3 captions
2025-12-31 12:55:00,678 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.20-23.20: idle with 1 captions
2025-12-31 12:55:00,678 backend.stream_utils - INFO [PARSE_LLM] Removed 15 duplicate segment(s) in window
2025-12-31 12:55:03,186 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.30s with 4 samples
2025-12-31 12:55:10,976 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.20-23.20: work with 2 captions
2025-12-31 12:55:10,978 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.30-23.30: idle with 2 captions
2025-12-31 12:55:10,979 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.30-23.30: work with 2 captions
2025-12-31 12:55:13,254 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.43s with 4 samples
2025-12-31 12:55:20,575 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.30-23.40: work with 4 captions
2025-12-31 12:55:20,575 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.40-23.40: work with 3 captions
2025-12-31 12:55:20,576 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.40-23.40: work with 3 captions
2025-12-31 12:55:20,576 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.30-23.40: work with 4 captions
2025-12-31 12:55:20,576 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.40-23.40: work with 3 captions
2025-12-31 12:55:20,577 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.40-23.40: work with 3 captions
2025-12-31 12:55:20,577 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:55:23,759 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.57s with 4 samples
2025-12-31 12:55:41,952 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.70s with 4 samples
2025-12-31 12:55:48,998 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.60-23.60: work with 2 captions
2025-12-31 12:55:48,999 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.70-23.70: work with 2 captions
2025-12-31 12:55:51,512 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.83s with 4 samples
2025-12-31 12:56:05,421 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.97s with 4 samples
2025-12-31 12:56:11,393 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.90-23.90: work with 3 captions
2025-12-31 12:56:11,394 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.00: idle with 1 captions
2025-12-31 12:56:11,395 backend.stream_utils - INFO [PARSE_LLM] Created segment 23.90-23.90: work with 3 captions
2025-12-31 12:56:11,395 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.00: idle with 1 captions
2025-12-31 12:56:11,396 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 12:56:13,474 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=24.10s with 4 samples
2025-12-31 12:56:20,259 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.00: work with 2 captions
2025-12-31 12:56:20,260 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.10-24.10: idle with 2 captions
2025-12-31 12:56:20,264 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.00: work with 2 captions
2025-12-31 12:56:20,267 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.10-24.10: idle with 2 captions
2025-12-31 12:56:20,269 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.00: work with 2 captions
2025-12-31 12:56:20,271 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.10-24.10: idle with 2 captions
2025-12-31 12:56:20,272 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.00-24.00: work with 2 captions
2025-12-31 12:56:20,273 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.10-24.10: idle with 2 captions
2025-12-31 12:56:20,275 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:56:23,102 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=24.23s with 4 samples
2025-12-31 12:56:33,219 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.20-24.20: work with 3 captions
2025-12-31 12:56:33,219 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.20-24.20: idle with 3 captions
2025-12-31 12:56:33,219 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.20-24.20: idle with 3 captions
2025-12-31 12:56:33,220 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.20-24.20: idle with 3 captions
2025-12-31 12:56:33,220 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.20-24.20: idle with 3 captions
2025-12-31 12:56:33,220 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.20-24.20: idle with 3 captions
2025-12-31 12:56:33,220 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 12:56:35,663 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=24.37s with 4 samples
2025-12-31 12:56:40,437 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.30-24.30: work with 3 captions
2025-12-31 12:56:40,437 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.30-24.30: work with 3 captions
2025-12-31 12:56:40,438 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.40-24.40: work with 1 captions
2025-12-31 12:56:40,439 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:56:42,981 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=24.50s with 4 samples
2025-12-31 12:56:48,954 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=24.63s with 4 samples
2025-12-31 12:56:57,932 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.50-24.60: work with 4 captions
2025-12-31 12:56:57,933 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.60-24.60: work with 3 captions
2025-12-31 12:56:57,933 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.50-24.60: work with 4 captions
2025-12-31 12:56:57,934 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.60-24.60: work with 3 captions
2025-12-31 12:56:57,934 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.50-24.60: work with 4 captions
2025-12-31 12:56:57,934 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.60-24.60: work with 3 captions
2025-12-31 12:56:57,934 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.50-24.60: work with 4 captions
2025-12-31 12:56:57,934 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.60-24.60: work with 3 captions
2025-12-31 12:56:57,934 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.50-24.60: work with 4 captions
2025-12-31 12:56:57,934 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.60-24.60: work with 3 captions
2025-12-31 12:56:57,935 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-31 12:57:00,089 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=24.77s with 4 samples
2025-12-31 12:57:03,190 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.70-24.70: work with 3 captions
2025-12-31 12:57:03,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.80-24.80: work with 1 captions
2025-12-31 12:57:05,107 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=24.90s with 4 samples
2025-12-31 12:57:09,201 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.80-24.80: work with 2 captions
2025-12-31 12:57:09,201 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.90-24.90: work with 2 captions
2025-12-31 12:57:11,202 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=25.03s with 4 samples
2025-12-31 12:57:15,799 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.90-24.90: work with 1 captions
2025-12-31 12:57:15,800 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.00-25.00: work with 3 captions
2025-12-31 12:57:15,800 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.00-25.00: idle with 3 captions
2025-12-31 12:57:15,801 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.00-25.00: work with 3 captions
2025-12-31 12:57:15,801 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.90-25.00: work with 4 captions
2025-12-31 12:57:15,801 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.00-25.00: work with 3 captions
2025-12-31 12:57:15,802 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.00-25.00: idle with 3 captions
2025-12-31 12:57:15,802 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.00-25.00: work with 3 captions
2025-12-31 12:57:15,802 backend.stream_utils - INFO [PARSE_LLM] Created segment 24.90-25.00: work with 4 captions
2025-12-31 12:57:15,803 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.00-25.00: work with 3 captions
2025-12-31 12:57:15,803 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.00-25.00: idle with 3 captions
2025-12-31 12:57:15,803 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.00-25.00: work with 3 captions
2025-12-31 12:57:15,804 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-31 12:57:17,678 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=25.17s with 4 samples
2025-12-31 12:57:24,683 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.10-25.10: work with 3 captions
2025-12-31 12:57:24,683 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.10-25.10: work with 3 captions
2025-12-31 12:57:24,683 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.20-25.20: work with 1 captions
2025-12-31 12:57:24,683 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.10-25.10: work with 3 captions
2025-12-31 12:57:24,684 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.10-25.10: work with 3 captions
2025-12-31 12:57:24,684 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.20-25.20: work with 1 captions
2025-12-31 12:57:24,684 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.10-25.10: work with 3 captions
2025-12-31 12:57:24,684 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.10-25.10: work with 3 captions
2025-12-31 12:57:24,685 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.20-25.20: work with 1 captions
2025-12-31 12:57:24,685 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.10-25.10: work with 3 captions
2025-12-31 12:57:24,686 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.10-25.10: work with 3 captions
2025-12-31 12:57:24,686 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.20-25.20: work with 1 captions
2025-12-31 12:57:24,688 backend.stream_utils - INFO [PARSE_LLM] Removed 10 duplicate segment(s) in window
2025-12-31 12:57:26,978 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=25.30s with 4 samples
2025-12-31 12:57:34,092 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.20-25.20: work with 2 captions
2025-12-31 12:57:34,092 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.30-25.30: idle with 2 captions
2025-12-31 12:57:34,092 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.30-25.30: idle with 2 captions
2025-12-31 12:57:34,093 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:57:36,233 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=25.43s with 4 samples
2025-12-31 12:57:40,903 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.30-25.30: work with 1 captions
2025-12-31 12:57:40,904 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.40-25.40: idle with 3 captions
2025-12-31 12:57:40,904 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.40-25.40: idle with 3 captions
2025-12-31 12:57:40,904 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.40-25.40: work with 3 captions
2025-12-31 12:57:40,905 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 12:57:43,549 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=25.57s with 4 samples
2025-12-31 12:57:46,186 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.50-25.50: work with 3 captions
2025-12-31 12:57:46,186 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.60-25.60: idle with 1 captions
2025-12-31 12:57:48,019 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=25.70s with 4 samples
2025-12-31 12:58:13,829 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=25.83s with 4 samples
2025-12-31 12:58:19,194 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-25.80: work with 4 captions
2025-12-31 12:58:19,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.80-25.80: idle with 3 captions
2025-12-31 12:58:19,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.80-25.80: idle with 3 captions
2025-12-31 12:58:19,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-25.80: work with 4 captions
2025-12-31 12:58:19,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.80-25.80: idle with 3 captions
2025-12-31 12:58:19,197 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.80-25.80: idle with 3 captions
2025-12-31 12:58:19,199 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.70-25.80: work with 4 captions
2025-12-31 12:58:19,199 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.80-25.80: idle with 3 captions
2025-12-31 12:58:19,200 backend.stream_utils - INFO [PARSE_LLM] Created segment 25.80-25.80: idle with 3 captions
2025-12-31 12:58:19,200 backend.stream_utils - INFO [PARSE_LLM] Removed 7 duplicate segment(s) in window
2025-12-31 12:58:21,895 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=25.97s with 4 samples
2025-12-31 12:58:28,460 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=26.10s with 4 samples
2025-12-31 12:58:46,296 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=26.23s with 4 samples
2025-12-31 12:58:57,188 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=26.37s with 4 samples
2025-12-31 12:59:04,889 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.30-26.30: work with 3 captions
2025-12-31 12:59:04,890 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.30-26.30: work with 3 captions
2025-12-31 12:59:04,891 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.40-26.40: idle with 1 captions
2025-12-31 12:59:04,891 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.30-26.30: work with 3 captions
2025-12-31 12:59:04,892 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.30-26.30: work with 3 captions
2025-12-31 12:59:04,893 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.40-26.40: idle with 1 captions
2025-12-31 12:59:04,894 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.30-26.30: work with 3 captions
2025-12-31 12:59:04,895 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.30-26.30: work with 3 captions
2025-12-31 12:59:04,896 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.40-26.40: idle with 1 captions
2025-12-31 12:59:04,896 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.30-26.30: work with 3 captions
2025-12-31 12:59:04,897 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.40-26.40: idle with 1 captions
2025-12-31 12:59:04,897 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-31 12:59:07,981 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=26.50s with 4 samples
2025-12-31 12:59:16,119 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.40-26.50: idle with 4 captions
2025-12-31 12:59:16,121 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.50-26.50: idle with 2 captions
2025-12-31 12:59:16,122 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.40-26.50: idle with 4 captions
2025-12-31 12:59:16,124 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.50-26.50: idle with 2 captions
2025-12-31 12:59:16,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.40-26.50: idle with 4 captions
2025-12-31 12:59:16,128 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.50-26.50: idle with 2 captions
2025-12-31 12:59:16,130 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.40-26.50: idle with 4 captions
2025-12-31 12:59:16,132 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.50-26.50: idle with 2 captions
2025-12-31 12:59:16,134 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 12:59:18,555 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=26.63s with 4 samples
2025-12-31 12:59:23,190 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.50-26.60: work with 4 captions
2025-12-31 12:59:23,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.60-26.60: work with 3 captions
2025-12-31 12:59:23,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.60-26.60: work with 3 captions
2025-12-31 12:59:23,192 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.60-26.60: work with 3 captions
2025-12-31 12:59:23,193 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.60-26.60: work with 3 captions
2025-12-31 12:59:23,194 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-31 12:59:25,631 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=26.77s with 4 samples
2025-12-31 12:59:33,161 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=26.90s with 4 samples
2025-12-31 12:59:47,456 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.03s with 4 samples
2025-12-31 12:59:53,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.90-27.00: work with 4 captions
2025-12-31 12:59:53,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.00-27.00: idle with 3 captions
2025-12-31 12:59:53,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.00-27.00: work with 3 captions
2025-12-31 12:59:53,045 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.90-27.00: work with 4 captions
2025-12-31 12:59:53,045 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.00-27.00: idle with 3 captions
2025-12-31 12:59:53,045 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.00-27.00: work with 3 captions
2025-12-31 12:59:53,046 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.90-27.00: work with 4 captions
2025-12-31 12:59:53,047 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.00-27.00: idle with 3 captions
2025-12-31 12:59:53,047 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.00-27.00: work with 3 captions
2025-12-31 12:59:53,047 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.90-27.00: work with 4 captions
2025-12-31 12:59:53,048 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.00-27.00: idle with 3 captions
2025-12-31 12:59:53,048 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.00-27.00: work with 3 captions
2025-12-31 12:59:53,048 backend.stream_utils - INFO [PARSE_LLM] Created segment 26.90-27.00: work with 4 captions
2025-12-31 12:59:53,049 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.00-27.00: idle with 3 captions
2025-12-31 12:59:53,049 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.00-27.00: work with 3 captions
2025-12-31 12:59:53,049 backend.stream_utils - INFO [PARSE_LLM] Removed 12 duplicate segment(s) in window
2025-12-31 12:59:55,347 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.17s with 4 samples
2025-12-31 12:59:59,032 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.10-27.10: work with 3 captions
2025-12-31 12:59:59,033 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.20-27.20: work with 1 captions
2025-12-31 13:00:01,053 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.30s with 4 samples
2025-12-31 13:00:10,494 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.43s with 4 samples
2025-12-31 13:00:14,470 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.30-27.40: work with 4 captions
2025-12-31 13:00:14,470 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.40-27.40: idle with 3 captions
2025-12-31 13:00:14,470 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.40-27.40: work with 3 captions
2025-12-31 13:00:14,471 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.30-27.40: work with 4 captions
2025-12-31 13:00:14,471 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.40-27.40: idle with 3 captions
2025-12-31 13:00:14,471 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.40-27.40: work with 3 captions
2025-12-31 13:00:14,471 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.30-27.40: work with 4 captions
2025-12-31 13:00:14,472 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.40-27.40: idle with 3 captions
2025-12-31 13:00:14,472 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.40-27.40: work with 3 captions
2025-12-31 13:00:14,472 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 13:00:17,235 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.57s with 4 samples
2025-12-31 13:00:24,521 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.50-27.50: work with 3 captions
2025-12-31 13:00:24,523 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.60-27.60: idle with 1 captions
2025-12-31 13:00:27,167 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.70s with 4 samples
2025-12-31 13:00:31,075 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.60-27.60: work with 2 captions
2025-12-31 13:00:31,075 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.70-27.70: idle with 2 captions
2025-12-31 13:00:33,952 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.83s with 4 samples
2025-12-31 13:00:39,434 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.70-27.80: work with 4 captions
2025-12-31 13:00:39,435 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.80-27.80: idle with 3 captions
2025-12-31 13:00:39,435 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.80-27.80: work with 3 captions
2025-12-31 13:00:41,943 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.97s with 4 samples
2025-12-31 13:00:47,480 backend.stream_utils - INFO [PARSE_LLM] Created segment 27.90-27.90: work with 3 captions
2025-12-31 13:00:47,482 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-28.00: work with 1 captions
2025-12-31 13:00:49,232 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=28.10s with 4 samples
2025-12-31 13:00:58,440 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-28.00: work with 2 captions
2025-12-31 13:00:58,441 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-28.10: work with 4 captions
2025-12-31 13:00:58,441 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.10: work with 2 captions
2025-12-31 13:00:58,441 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.10: idle with 2 captions
2025-12-31 13:00:58,442 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-28.00: work with 2 captions
2025-12-31 13:00:58,442 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-28.10: work with 4 captions
2025-12-31 13:00:58,442 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.10: work with 2 captions
2025-12-31 13:00:58,442 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.10: idle with 2 captions
2025-12-31 13:00:58,442 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-28.00: work with 2 captions
2025-12-31 13:00:58,443 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-28.10: work with 4 captions
2025-12-31 13:00:58,443 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.10: work with 2 captions
2025-12-31 13:00:58,443 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.10: idle with 2 captions
2025-12-31 13:00:58,443 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-28.00: work with 2 captions
2025-12-31 13:00:58,443 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.00-28.10: work with 4 captions
2025-12-31 13:00:58,444 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.10: work with 2 captions
2025-12-31 13:00:58,444 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.10: idle with 2 captions
2025-12-31 13:00:58,444 backend.stream_utils - INFO [PARSE_LLM] Removed 12 duplicate segment(s) in window
2025-12-31 13:01:01,178 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=28.23s with 4 samples
2025-12-31 13:01:15,187 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.20: work with 4 captions
2025-12-31 13:01:15,187 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.20-28.20: work with 3 captions
2025-12-31 13:01:15,188 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.20-28.20: work with 3 captions
2025-12-31 13:01:15,188 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.20: work with 4 captions
2025-12-31 13:01:15,188 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.20-28.20: work with 3 captions
2025-12-31 13:01:15,189 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.20-28.20: work with 3 captions
2025-12-31 13:01:15,189 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.20-28.20: work with 3 captions
2025-12-31 13:01:15,190 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.20: work with 4 captions
2025-12-31 13:01:15,190 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.20-28.20: work with 3 captions
2025-12-31 13:01:15,190 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.20-28.20: work with 3 captions
2025-12-31 13:01:15,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.20-28.20: work with 3 captions
2025-12-31 13:01:15,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.10-28.20: work with 4 captions
2025-12-31 13:01:15,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.20-28.20: work with 3 captions
2025-12-31 13:01:15,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.20-28.20: work with 3 captions
2025-12-31 13:01:15,192 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.20-28.20: work with 3 captions
2025-12-31 13:01:15,192 backend.stream_utils - INFO [PARSE_LLM] Removed 13 duplicate segment(s) in window
2025-12-31 13:01:17,431 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=28.37s with 4 samples
2025-12-31 13:01:26,276 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=28.50s with 4 samples
2025-12-31 13:01:35,310 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.40-28.40: work with 2 captions
2025-12-31 13:01:35,310 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.50-28.50: idle with 2 captions
2025-12-31 13:01:38,540 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=28.63s with 4 samples
2025-12-31 13:01:41,687 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.50-28.60: work with 4 captions
2025-12-31 13:01:44,272 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=28.77s with 4 samples
2025-12-31 13:03:44,305 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:03:44,305 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:03:47,106 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=28.90s with 4 samples
2025-12-31 13:03:52,359 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.80-28.80: work with 2 captions
2025-12-31 13:03:52,359 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.90-28.90: idle with 2 captions
2025-12-31 13:03:52,359 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.80-28.80: work with 2 captions
2025-12-31 13:03:52,359 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.90-28.90: idle with 2 captions
2025-12-31 13:03:52,359 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:03:55,247 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=29.03s with 4 samples
2025-12-31 13:04:17,085 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.90-29.00: work with 4 captions
2025-12-31 13:04:17,085 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.00-29.00: work with 3 captions
2025-12-31 13:04:17,085 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.90-29.00: work with 4 captions
2025-12-31 13:04:17,086 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.00-29.00: work with 3 captions
2025-12-31 13:04:17,086 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.90-29.00: work with 4 captions
2025-12-31 13:04:17,086 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.00-29.00: work with 3 captions
2025-12-31 13:04:17,088 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.90-29.00: work with 4 captions
2025-12-31 13:04:17,089 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.00-29.00: work with 3 captions
2025-12-31 13:04:17,091 backend.stream_utils - INFO [PARSE_LLM] Created segment 28.90-29.00: work with 4 captions
2025-12-31 13:04:17,091 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.00-29.00: work with 3 captions
2025-12-31 13:04:17,094 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-31 13:04:19,649 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=29.17s with 4 samples
2025-12-31 13:04:31,580 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=29.30s with 4 samples
2025-12-31 13:04:38,022 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.20-29.20: work with 2 captions
2025-12-31 13:04:38,023 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.30-29.30: idle with 2 captions
2025-12-31 13:04:38,023 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.20-29.20: work with 2 captions
2025-12-31 13:04:38,023 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.30-29.30: idle with 2 captions
2025-12-31 13:04:38,023 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:04:40,655 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=29.43s with 4 samples
2025-12-31 13:05:00,998 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.30-29.40: work with 4 captions
2025-12-31 13:05:01,000 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.40-29.40: idle with 3 captions
2025-12-31 13:05:01,001 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.40-29.40: idle with 3 captions
2025-12-31 13:05:01,003 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.40-29.40: idle with 3 captions
2025-12-31 13:05:01,004 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.30-29.40: work with 4 captions
2025-12-31 13:05:01,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.40-29.40: idle with 3 captions
2025-12-31 13:05:01,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.40-29.40: idle with 3 captions
2025-12-31 13:05:01,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.40-29.40: idle with 3 captions
2025-12-31 13:05:01,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.30-29.40: work with 4 captions
2025-12-31 13:05:01,008 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.40-29.40: idle with 3 captions
2025-12-31 13:05:01,008 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.40-29.40: idle with 3 captions
2025-12-31 13:05:01,009 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.40-29.40: idle with 3 captions
2025-12-31 13:05:01,010 backend.stream_utils - INFO [PARSE_LLM] Removed 10 duplicate segment(s) in window
2025-12-31 13:05:03,728 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=29.57s with 4 samples
2025-12-31 13:05:22,041 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=29.70s with 4 samples
2025-12-31 13:05:26,877 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.60-29.60: work with 2 captions
2025-12-31 13:05:26,878 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.70-29.70: idle with 2 captions
2025-12-31 13:05:29,174 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=29.83s with 4 samples
2025-12-31 13:05:36,466 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.70-29.80: work with 4 captions
2025-12-31 13:05:39,684 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=29.97s with 4 samples
2025-12-31 13:05:44,881 backend.stream_utils - INFO [PARSE_LLM] Created segment 29.90-30.00: work with 4 captions
2025-12-31 13:05:44,881 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.00: idle with 1 captions
2025-12-31 13:05:47,168 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.10s with 4 samples
2025-12-31 13:05:59,373 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.10: work with 4 captions
2025-12-31 13:05:59,373 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.10-30.10: idle with 2 captions
2025-12-31 13:05:59,373 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.10: work with 4 captions
2025-12-31 13:05:59,373 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.10-30.10: idle with 2 captions
2025-12-31 13:05:59,373 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.10: work with 4 captions
2025-12-31 13:05:59,374 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.10-30.10: idle with 2 captions
2025-12-31 13:05:59,374 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.00-30.10: work with 4 captions
2025-12-31 13:05:59,374 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.10-30.10: idle with 2 captions
2025-12-31 13:05:59,374 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 13:06:02,224 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.23s with 4 samples
2025-12-31 13:06:11,664 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.10-30.20: work with 4 captions
2025-12-31 13:06:11,664 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.20-30.20: idle with 3 captions
2025-12-31 13:06:11,665 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.10-30.20: work with 4 captions
2025-12-31 13:06:11,665 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.20-30.20: idle with 3 captions
2025-12-31 13:06:11,665 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:06:14,441 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.37s with 4 samples
2025-12-31 13:06:29,162 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.30-30.40: work with 4 captions
2025-12-31 13:06:29,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.30-30.40: work with 4 captions
2025-12-31 13:06:29,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.30-30.40: work with 4 captions
2025-12-31 13:06:29,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.30-30.40: work with 4 captions
2025-12-31 13:06:29,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.30-30.40: work with 4 captions
2025-12-31 13:06:29,163 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.30-30.40: work with 4 captions
2025-12-31 13:06:29,164 backend.stream_utils - INFO [PARSE_LLM] Removed 5 duplicate segment(s) in window
2025-12-31 13:06:31,726 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.50s with 4 samples
2025-12-31 13:06:38,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.40-30.40: work with 2 captions
2025-12-31 13:06:38,042 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.50-30.50: idle with 2 captions
2025-12-31 13:06:40,957 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.63s with 4 samples
2025-12-31 13:07:04,212 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.77s with 4 samples
2025-12-31 13:07:09,326 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.70-30.70: work with 3 captions
2025-12-31 13:07:09,326 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.80-30.80: work with 1 captions
2025-12-31 13:07:11,630 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.90s with 4 samples
2025-12-31 13:07:16,709 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.80-30.80: work with 2 captions
2025-12-31 13:07:16,709 backend.stream_utils - INFO [PARSE_LLM] Created segment 30.90-30.90: work with 2 captions
2025-12-31 13:07:18,864 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=31.03s with 4 samples
2025-12-31 13:07:27,304 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=31.17s with 4 samples
2025-12-31 13:07:43,957 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.10-31.10: work with 3 captions
2025-12-31 13:07:43,958 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.20-31.20: work with 1 captions
2025-12-31 13:07:45,976 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=31.30s with 4 samples
2025-12-31 13:08:17,598 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=31.43s with 4 samples
2025-12-31 13:08:31,315 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.30-31.30: work with 1 captions
2025-12-31 13:08:31,316 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: idle with 3 captions
2025-12-31 13:08:31,319 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: idle with 3 captions
2025-12-31 13:08:31,320 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: work with 3 captions
2025-12-31 13:08:31,320 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.30-31.30: work with 1 captions
2025-12-31 13:08:31,322 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: idle with 3 captions
2025-12-31 13:08:31,323 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: idle with 3 captions
2025-12-31 13:08:31,323 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: work with 3 captions
2025-12-31 13:08:31,323 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.30-31.30: work with 1 captions
2025-12-31 13:08:31,323 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: idle with 3 captions
2025-12-31 13:08:31,324 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: idle with 3 captions
2025-12-31 13:08:31,324 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: work with 3 captions
2025-12-31 13:08:31,324 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.30-31.30: work with 1 captions
2025-12-31 13:08:31,324 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: idle with 3 captions
2025-12-31 13:08:31,324 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: idle with 3 captions
2025-12-31 13:08:31,325 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: work with 3 captions
2025-12-31 13:08:31,325 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.30-31.30: work with 1 captions
2025-12-31 13:08:31,325 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: idle with 3 captions
2025-12-31 13:08:31,325 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: idle with 3 captions
2025-12-31 13:08:31,325 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.40-31.40: work with 3 captions
2025-12-31 13:08:31,326 backend.stream_utils - INFO [PARSE_LLM] Removed 17 duplicate segment(s) in window
2025-12-31 13:08:33,890 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=31.57s with 4 samples
2025-12-31 13:08:43,772 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.50-31.50: work with 3 captions
2025-12-31 13:08:43,773 backend.stream_utils - INFO [PARSE_LLM] Created segment 31.60-31.60: work with 1 captions
2025-12-31 13:08:46,006 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=31.70s with 4 samples
2025-12-31 13:08:56,185 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=31.83s with 4 samples
2025-12-31 13:09:05,837 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=31.97s with 4 samples
2025-12-31 13:09:25,643 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-32.00: work with 4 captions
2025-12-31 13:09:25,644 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.00-32.10: work with 1 captions
2025-12-31 13:09:25,644 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-32.00: work with 4 captions
2025-12-31 13:09:25,644 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.00-32.10: work with 1 captions
2025-12-31 13:09:25,645 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:09:27,698 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.10s with 4 samples
2025-12-31 13:09:33,554 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:09:33,555 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:09:36,126 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.23s with 4 samples
2025-12-31 13:09:44,699 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-32.10: work with 1 captions
2025-12-31 13:09:44,699 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.20-32.20: idle with 3 captions
2025-12-31 13:09:44,699 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.20-32.20: work with 3 captions
2025-12-31 13:09:44,699 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-32.10: work with 1 captions
2025-12-31 13:09:44,699 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.20-32.20: idle with 3 captions
2025-12-31 13:09:44,700 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.20-32.20: work with 3 captions
2025-12-31 13:09:44,700 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.10-32.10: work with 1 captions
2025-12-31 13:09:44,700 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.20-32.20: idle with 3 captions
2025-12-31 13:09:44,700 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.20-32.20: work with 3 captions
2025-12-31 13:09:44,700 backend.stream_utils - INFO [PARSE_LLM] Removed 5 duplicate segment(s) in window
2025-12-31 13:09:47,268 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.37s with 4 samples
2025-12-31 13:09:55,797 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.50s with 4 samples
2025-12-31 13:10:02,279 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.40-32.40: work with 2 captions
2025-12-31 13:10:02,280 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.50-32.50: idle with 2 captions
2025-12-31 13:10:02,280 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.40-32.40: work with 2 captions
2025-12-31 13:10:02,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.50-32.50: idle with 2 captions
2025-12-31 13:10:02,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.40-32.40: work with 2 captions
2025-12-31 13:10:02,281 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.50-32.50: idle with 2 captions
2025-12-31 13:10:02,281 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:10:05,014 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.63s with 4 samples
2025-12-31 13:10:20,717 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.50-32.60: work with 4 captions
2025-12-31 13:10:20,717 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,717 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,717 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.50-32.60: work with 4 captions
2025-12-31 13:10:20,718 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,718 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,718 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.50-32.60: work with 4 captions
2025-12-31 13:10:20,719 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,719 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,719 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.50-32.60: work with 4 captions
2025-12-31 13:10:20,720 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,720 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.50-32.60: work with 4 captions
2025-12-31 13:10:20,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.50-32.60: work with 4 captions
2025-12-31 13:10:20,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.60-32.60: work with 3 captions
2025-12-31 13:10:20,722 backend.stream_utils - INFO [PARSE_LLM] Removed 16 duplicate segment(s) in window
2025-12-31 13:10:24,252 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.77s with 4 samples
2025-12-31 13:10:32,064 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.70-32.70: work with 3 captions
2025-12-31 13:10:32,065 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.80-32.80: idle with 1 captions
2025-12-31 13:10:32,065 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.70-32.70: work with 3 captions
2025-12-31 13:10:32,065 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.80-32.80: idle with 1 captions
2025-12-31 13:10:32,065 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.70-32.70: work with 3 captions
2025-12-31 13:10:32,065 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.80-32.80: idle with 1 captions
2025-12-31 13:10:32,066 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:10:34,546 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=32.90s with 4 samples
2025-12-31 13:10:39,986 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.80-32.80: work with 2 captions
2025-12-31 13:10:39,989 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.90-32.90: idle with 2 captions
2025-12-31 13:10:39,990 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.80-32.80: work with 2 captions
2025-12-31 13:10:39,992 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.90-32.90: idle with 2 captions
2025-12-31 13:10:39,992 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.80-32.80: work with 2 captions
2025-12-31 13:10:39,993 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.90-32.90: idle with 2 captions
2025-12-31 13:10:39,993 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:10:42,669 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=33.03s with 4 samples
2025-12-31 13:10:54,164 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.90-33.00: work with 4 captions
2025-12-31 13:10:54,164 backend.stream_utils - INFO [PARSE_LLM] Created segment 33.00-33.00: idle with 3 captions
2025-12-31 13:10:54,165 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.90-33.00: work with 4 captions
2025-12-31 13:10:54,165 backend.stream_utils - INFO [PARSE_LLM] Created segment 33.00-33.00: idle with 3 captions
2025-12-31 13:10:54,165 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.90-33.00: work with 4 captions
2025-12-31 13:10:54,165 backend.stream_utils - INFO [PARSE_LLM] Created segment 33.00-33.00: idle with 3 captions
2025-12-31 13:10:54,166 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:10:56,781 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=33.17s with 4 samples
2025-12-31 13:11:02,158 backend.stream_utils - INFO [PARSE_LLM] Created segment 33.10-33.10: work with 3 captions
2025-12-31 13:11:02,160 backend.stream_utils - INFO [PARSE_LLM] Created segment 33.20-33.20: work with 1 captions
2025-12-31 13:11:05,369 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=33.30s with 4 samples
2025-12-31 13:11:14,255 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=33.43s with 4 samples
2025-12-31 13:11:19,761 backend.stream_utils - INFO [PARSE_LLM] Created segment 33.30-33.40: work with 4 captions
2025-12-31 13:11:19,762 backend.stream_utils - INFO [PARSE_LLM] Created segment 33.40-33.40: idle with 3 captions
2025-12-31 13:11:19,762 backend.stream_utils - INFO [PARSE_LLM] Created segment 33.40-33.40: work with 3 captions
2025-12-31 13:11:22,249 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=33.57s with 4 samples
2025-12-31 13:11:46,942 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=33.70s with 4 samples
2025-12-31 13:11:58,381 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=33.83s with 4 samples
2025-12-31 13:12:36,455 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=33.97s with 4 samples
2025-12-31 13:12:45,558 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=34.10s with 4 samples
2025-12-31 13:13:00,148 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=34.23s with 4 samples
2025-12-31 13:13:12,779 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=34.37s with 4 samples
2025-12-31 13:13:23,099 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=34.50s with 4 samples
2025-12-31 13:13:29,337 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=34.63s with 4 samples
2025-12-31 13:13:38,147 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=34.77s with 4 samples
2025-12-31 13:13:45,741 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=34.90s with 4 samples
2025-12-31 13:13:53,246 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.80-34.80: work with 2 captions
2025-12-31 13:13:53,247 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.90-34.90: idle with 2 captions
2025-12-31 13:13:53,247 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.90-34.90: work with 2 captions
2025-12-31 13:13:53,248 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.80-34.80: work with 2 captions
2025-12-31 13:13:53,248 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.90-34.90: idle with 2 captions
2025-12-31 13:13:53,248 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.90-34.90: work with 2 captions
2025-12-31 13:13:53,248 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.80-34.80: work with 2 captions
2025-12-31 13:13:53,249 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.90-34.90: idle with 2 captions
2025-12-31 13:13:53,249 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.90-34.90: work with 2 captions
2025-12-31 13:13:53,249 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 13:13:57,035 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=35.03s with 4 samples
2025-12-31 13:14:11,648 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=35.17s with 4 samples
2025-12-31 13:14:22,459 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:14:22,459 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 0.50-2.30: work (from first two entries), 3.10-5.20: idle (from next two entries). But the user's input is not in that format. Wait, the user's problem statement says that the example input is t=0.50,
2025-12-31 13:14:24,623 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=35.30s with 4 samples
2025-12-31 13:14:34,057 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=35.43s with 4 samples
2025-12-31 13:14:45,470 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=35.57s with 4 samples
2025-12-31 13:14:54,819 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.50-35.50: work with 3 captions
2025-12-31 13:14:54,820 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.60-35.60: work with 1 captions
2025-12-31 13:14:57,383 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=35.70s with 4 samples
2025-12-31 13:15:03,755 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.60-35.60: work with 2 captions
2025-12-31 13:15:03,755 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.70-35.70: idle with 2 captions
2025-12-31 13:15:03,755 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.70-35.70: idle with 2 captions
2025-12-31 13:15:03,755 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 13:15:06,566 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=35.83s with 4 samples
2025-12-31 13:15:17,718 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.70-35.80: work with 4 captions
2025-12-31 13:15:17,718 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.80-35.80: work with 3 captions
2025-12-31 13:15:17,718 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.70-35.80: work with 4 captions
2025-12-31 13:15:17,718 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.80-35.80: work with 3 captions
2025-12-31 13:15:17,719 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.70-35.80: work with 4 captions
2025-12-31 13:15:17,719 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.80-35.80: work with 3 captions
2025-12-31 13:15:17,719 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:15:20,800 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=35.97s with 4 samples
2025-12-31 13:15:30,432 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=36.10s with 4 samples
2025-12-31 13:15:39,022 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=36.23s with 4 samples
2025-12-31 13:15:48,399 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=36.37s with 4 samples
2025-12-31 13:15:57,315 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=36.50s with 4 samples
2025-12-31 13:16:07,898 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=36.63s with 4 samples
2025-12-31 13:16:27,076 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.50-36.60: work with 4 captions
2025-12-31 13:16:27,076 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.60-36.60: work with 3 captions
2025-12-31 13:16:27,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.50-36.60: work with 4 captions
2025-12-31 13:16:27,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.60-36.60: work with 3 captions
2025-12-31 13:16:27,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.50-36.60: work with 4 captions
2025-12-31 13:16:27,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.60-36.60: work with 3 captions
2025-12-31 13:16:27,078 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:16:29,778 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=36.77s with 4 samples
2025-12-31 13:16:37,626 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-36.70: work with 3 captions
2025-12-31 13:16:37,626 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.70-36.80: idle with 4 captions
2025-12-31 13:16:37,626 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-36.70: work with 3 captions
2025-12-31 13:16:37,626 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.70-36.80: idle with 4 captions
2025-12-31 13:16:37,626 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-36.70: work with 3 captions
2025-12-31 13:16:37,627 backend.stream_utils - INFO [PARSE_LLM] Created segment 36.70-36.80: idle with 4 captions
2025-12-31 13:16:37,627 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:16:40,858 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=36.90s with 4 samples
2025-12-31 13:16:51,746 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.03s with 4 samples
2025-12-31 13:16:56,240 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:16:56,244 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:16:59,019 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.17s with 4 samples
2025-12-31 13:17:01,794 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.10-37.10: work with 3 captions
2025-12-31 13:17:01,794 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.20-37.20: idle with 1 captions
2025-12-31 13:17:03,918 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.30s with 4 samples
2025-12-31 13:17:09,783 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.20-37.20: work with 2 captions
2025-12-31 13:17:09,783 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.30-37.30: idle with 2 captions
2025-12-31 13:17:09,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.30-37.30: work with 2 captions
2025-12-31 13:17:09,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.20-37.20: work with 2 captions
2025-12-31 13:17:09,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.30-37.30: idle with 2 captions
2025-12-31 13:17:09,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.20-37.20: work with 2 captions
2025-12-31 13:17:09,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.30-37.30: idle with 2 captions
2025-12-31 13:17:09,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.20-37.20: work with 2 captions
2025-12-31 13:17:09,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.30-37.30: idle with 2 captions
2025-12-31 13:17:09,785 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 13:17:11,811 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.43s with 4 samples
2025-12-31 13:17:23,671 backend.stream_utils - INFO [PARSE_LLM] Created segment 37.30-37.40: work with 4 captions
2025-12-31 13:17:26,513 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.57s with 4 samples
2025-12-31 13:17:35,143 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.70s with 4 samples
2025-12-31 13:17:48,360 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.83s with 4 samples
2025-12-31 13:17:59,342 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.97s with 4 samples
2025-12-31 13:18:16,587 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.10s with 4 samples
2025-12-31 13:18:23,794 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.00-38.10: work with 4 captions
2025-12-31 13:18:25,890 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.23s with 4 samples
2025-12-31 13:18:32,553 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:18:32,553 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:18:34,907 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.37s with 4 samples
2025-12-31 13:18:51,382 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.50s with 4 samples
2025-12-31 13:18:57,118 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.40-38.50: work with 4 captions
2025-12-31 13:18:57,119 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.50-38.50: idle with 2 captions
2025-12-31 13:18:59,477 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.63s with 4 samples
2025-12-31 13:19:13,381 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.50-38.60: work with 4 captions
2025-12-31 13:19:13,382 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: work with 3 captions
2025-12-31 13:19:13,382 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.60-38.60: work with 3 captions
2025-12-31 13:19:13,382 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 13:19:16,175 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.77s with 4 samples
2025-12-31 13:19:21,370 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:19:21,371 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:19:24,508 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.90s with 4 samples
2025-12-31 13:19:28,986 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:19:28,986 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:19:31,219 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=39.03s with 4 samples
2025-12-31 13:19:34,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 38.90-39.00: work with 4 captions
2025-12-31 13:19:37,982 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=39.17s with 4 samples
2025-12-31 13:19:43,207 backend.stream_utils - INFO [PARSE_LLM] Created segment 39.10-39.10: work with 3 captions
2025-12-31 13:19:43,208 backend.stream_utils - INFO [PARSE_LLM] Created segment 39.20-39.20: idle with 1 captions
2025-12-31 13:19:43,208 backend.stream_utils - INFO [PARSE_LLM] Created segment 39.10-39.10: work with 3 captions
2025-12-31 13:19:43,209 backend.stream_utils - INFO [PARSE_LLM] Created segment 39.20-39.20: idle with 1 captions
2025-12-31 13:19:43,209 backend.stream_utils - INFO [PARSE_LLM] Created segment 39.10-39.10: work with 3 captions
2025-12-31 13:19:43,209 backend.stream_utils - INFO [PARSE_LLM] Created segment 39.20-39.20: idle with 1 captions
2025-12-31 13:19:43,209 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:19:45,399 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=39.30s with 4 samples
2025-12-31 13:19:56,750 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=39.43s with 4 samples
2025-12-31 13:20:08,247 backend.stream_utils - INFO [PARSE_LLM] Created segment 39.30-39.40: work with 4 captions
2025-12-31 13:20:10,688 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=39.57s with 4 samples
2025-12-31 13:20:17,920 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:20:17,921 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:20:20,255 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=39.70s with 4 samples
2025-12-31 13:20:29,362 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=39.83s with 4 samples
2025-12-31 13:20:34,134 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:20:34,134 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:20:37,191 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=39.97s with 4 samples
2025-12-31 13:20:44,687 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.10s with 4 samples
2025-12-31 13:20:55,137 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-40.10: idle with 4 captions
2025-12-31 13:20:55,137 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-40.10: idle with 4 captions
2025-12-31 13:20:55,137 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-40.10: idle with 4 captions
2025-12-31 13:20:55,138 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:20:57,486 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.23s with 4 samples
2025-12-31 13:21:06,519 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-40.10: work with 1 captions
2025-12-31 13:21:06,519 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.20-40.20: work with 3 captions
2025-12-31 13:21:06,520 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-40.10: work with 1 captions
2025-12-31 13:21:06,520 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.20-40.20: work with 3 captions
2025-12-31 13:21:06,521 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-40.10: work with 1 captions
2025-12-31 13:21:06,521 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.20-40.20: work with 3 captions
2025-12-31 13:21:06,522 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:21:08,898 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.37s with 4 samples
2025-12-31 13:21:26,487 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.50s with 4 samples
2025-12-31 13:21:37,699 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.40-40.50: work with 4 captions
2025-12-31 13:21:37,700 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.50-40.50: work with 2 captions
2025-12-31 13:21:40,229 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.63s with 4 samples
2025-12-31 13:22:00,266 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.77s with 4 samples
2025-12-31 13:22:05,636 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.70-40.80: work with 4 captions
2025-12-31 13:22:08,085 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=40.90s with 4 samples
2025-12-31 13:22:14,186 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.80-40.80: work with 2 captions
2025-12-31 13:22:14,187 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.90-40.90: idle with 2 captions
2025-12-31 13:22:16,327 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=41.03s with 4 samples
2025-12-31 13:22:27,761 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-41.00: work with 4 captions
2025-12-31 13:22:27,761 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.00-41.00: work with 3 captions
2025-12-31 13:22:27,761 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.90-41.00: work with 4 captions
2025-12-31 13:22:27,761 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.00-41.00: work with 3 captions
2025-12-31 13:22:27,761 backend.stream_utils - INFO [PARSE_LLM] Created segment 40.90-41.00: work with 4 captions
2025-12-31 13:22:27,761 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.00-41.00: work with 3 captions
2025-12-31 13:22:27,762 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-31 13:22:30,405 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=41.17s with 4 samples
2025-12-31 13:22:46,909 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=41.30s with 4 samples
2025-12-31 13:22:51,598 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.20-41.20: work with 2 captions
2025-12-31 13:22:51,600 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.30-41.30: idle with 2 captions
2025-12-31 13:22:54,080 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=41.43s with 4 samples
2025-12-31 13:23:25,379 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.30-41.30: work with 1 captions
2025-12-31 13:23:25,380 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-41.40: work with 3 captions
2025-12-31 13:23:25,380 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-41.40: work with 3 captions
2025-12-31 13:23:25,381 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.30-41.30: work with 1 captions
2025-12-31 13:23:25,381 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.30-41.30: work with 1 captions
2025-12-31 13:23:25,381 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.30-41.30: work with 1 captions
2025-12-31 13:23:25,381 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-41.40: work with 3 captions
2025-12-31 13:23:25,382 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-41.40: idle with 3 captions
2025-12-31 13:23:25,382 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.30-41.30: work with 1 captions
2025-12-31 13:23:25,382 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.30-41.30: work with 1 captions
2025-12-31 13:23:25,382 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-41.40: work with 3 captions
2025-12-31 13:23:25,383 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.30-41.30: work with 1 captions
2025-12-31 13:23:25,383 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-41.40: work with 3 captions
2025-12-31 13:23:25,383 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-41.40: idle with 3 captions
2025-12-31 13:23:25,383 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.30-41.30: work with 1 captions
2025-12-31 13:23:25,384 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-41.40: work with 3 captions
2025-12-31 13:23:25,384 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.40-41.40: idle with 3 captions
2025-12-31 13:23:25,384 backend.stream_utils - INFO [PARSE_LLM] Removed 14 duplicate segment(s) in window
2025-12-31 13:23:27,737 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=41.57s with 4 samples
2025-12-31 13:23:48,897 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.50-41.60: work with 4 captions
2025-12-31 13:23:48,899 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.50-41.60: work with 4 captions
2025-12-31 13:23:48,900 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.50-41.60: work with 4 captions
2025-12-31 13:23:48,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.50-41.60: work with 4 captions
2025-12-31 13:23:48,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.50-41.60: work with 4 captions
2025-12-31 13:23:48,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.50-41.60: work with 4 captions
2025-12-31 13:23:48,902 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.50-41.60: work with 4 captions
2025-12-31 13:23:48,902 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.50-41.60: work with 4 captions
2025-12-31 13:23:48,906 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.50-41.60: work with 4 captions
2025-12-31 13:23:48,907 backend.stream_utils - INFO [PARSE_LLM] Created segment 41.50-41.60: work with 4 captions
2025-12-31 13:23:48,907 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-31 13:23:51,494 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=41.70s with 4 samples
2025-12-31 13:24:01,078 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=41.83s with 4 samples
2025-12-31 13:24:08,664 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=41.97s with 4 samples
2025-12-31 13:24:15,828 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=42.10s with 4 samples
2025-12-31 13:24:20,018 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:24:20,019 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:24:22,211 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=42.23s with 4 samples
2025-12-31 13:24:38,225 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=42.37s with 4 samples
2025-12-31 13:24:44,761 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=42.50s with 4 samples
2025-12-31 13:24:51,497 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.40-42.40: work with 2 captions
2025-12-31 13:24:51,500 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.50-42.50: idle with 2 captions
2025-12-31 13:24:53,660 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=42.63s with 4 samples
2025-12-31 13:25:05,152 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.50-42.50: work with 1 captions
2025-12-31 13:25:05,153 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.60-42.60: work with 3 captions
2025-12-31 13:25:05,154 backend.stream_utils - INFO [PARSE_LLM] Created segment 42.60-42.60: work with 3 captions
2025-12-31 13:25:05,154 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 13:25:07,308 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=42.77s with 4 samples
2025-12-31 13:25:11,959 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:25:11,960 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:25:14,155 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=42.90s with 4 samples
2025-12-31 13:25:18,021 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:25:18,021 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:25:20,325 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=43.03s with 4 samples
2025-12-31 13:25:39,386 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=43.17s with 4 samples
2025-12-31 13:25:45,783 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.10-43.10: work with 3 captions
2025-12-31 13:25:45,783 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.10-43.10: idle with 3 captions
2025-12-31 13:25:45,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.20-43.20: work with 1 captions
2025-12-31 13:25:45,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.10-43.10: work with 3 captions
2025-12-31 13:25:45,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.10-43.10: idle with 3 captions
2025-12-31 13:25:45,784 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.20-43.20: work with 1 captions
2025-12-31 13:25:45,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.10-43.10: work with 3 captions
2025-12-31 13:25:45,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.10-43.10: idle with 3 captions
2025-12-31 13:25:45,785 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.20-43.20: work with 1 captions
2025-12-31 13:25:45,785 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 13:25:47,999 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=43.30s with 4 samples
2025-12-31 13:25:54,540 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.20-43.20: work with 2 captions
2025-12-31 13:25:54,541 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.30-43.30: idle with 2 captions
2025-12-31 13:25:54,542 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.20-43.20: work with 2 captions
2025-12-31 13:25:54,544 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.30-43.30: idle with 2 captions
2025-12-31 13:25:54,544 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.20-43.20: work with 2 captions
2025-12-31 13:25:54,545 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.30-43.30: idle with 2 captions
2025-12-31 13:25:54,545 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:25:57,180 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=43.43s with 4 samples
2025-12-31 13:26:04,872 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.30-43.40: work with 4 captions
2025-12-31 13:26:04,872 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.40-43.40: work with 3 captions
2025-12-31 13:26:04,873 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.30-43.40: work with 4 captions
2025-12-31 13:26:04,873 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.40-43.40: work with 3 captions
2025-12-31 13:26:04,873 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:26:06,858 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=43.57s with 4 samples
2025-12-31 13:26:19,561 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=43.70s with 4 samples
2025-12-31 13:26:58,189 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=43.83s with 4 samples
2025-12-31 13:27:10,338 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=43.97s with 4 samples
2025-12-31 13:27:16,175 backend.stream_utils - INFO [PARSE_LLM] Created segment 43.90-43.90: work with 3 captions
2025-12-31 13:27:16,176 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.00-44.00: idle with 1 captions
2025-12-31 13:27:18,284 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=44.10s with 4 samples
2025-12-31 13:27:28,375 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=44.23s with 4 samples
2025-12-31 13:27:59,621 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-44.20: work with 4 captions
2025-12-31 13:27:59,622 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-44.20: work with 4 captions
2025-12-31 13:27:59,622 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-44.20: work with 4 captions
2025-12-31 13:27:59,622 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-44.20: work with 4 captions
2025-12-31 13:27:59,623 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-44.20: work with 4 captions
2025-12-31 13:27:59,623 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:28:02,081 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=44.37s with 4 samples
2025-12-31 13:28:12,725 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.40-44.40: idle with 1 captions
2025-12-31 13:28:12,726 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.40-44.40: idle with 1 captions
2025-12-31 13:28:12,726 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.40-44.40: idle with 1 captions
2025-12-31 13:28:12,727 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:28:15,532 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=44.50s with 4 samples
2025-12-31 13:28:22,147 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.40-44.40: work with 2 captions
2025-12-31 13:28:22,147 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.50-44.50: idle with 2 captions
2025-12-31 13:28:22,147 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.50-44.50: work with 2 captions
2025-12-31 13:28:22,147 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.40-44.40: work with 2 captions
2025-12-31 13:28:22,148 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.50-44.50: idle with 2 captions
2025-12-31 13:28:22,148 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.50-44.50: work with 2 captions
2025-12-31 13:28:22,148 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-31 13:28:24,381 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=44.63s with 4 samples
2025-12-31 13:28:33,263 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.50-44.50: work with 1 captions
2025-12-31 13:28:35,831 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=44.77s with 4 samples
2025-12-31 13:28:44,992 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=44.90s with 4 samples
2025-12-31 13:28:51,450 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.80-44.80: work with 2 captions
2025-12-31 13:28:51,450 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.90-44.90: idle with 2 captions
2025-12-31 13:28:51,450 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.80-44.80: work with 2 captions
2025-12-31 13:28:51,450 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.90-44.90: idle with 2 captions
2025-12-31 13:28:51,450 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.80-44.80: work with 2 captions
2025-12-31 13:28:51,451 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.90-44.90: idle with 2 captions
2025-12-31 13:28:51,451 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:28:53,525 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=45.03s with 4 samples
2025-12-31 13:29:14,392 backend.stream_utils - INFO [PARSE_LLM] Created segment 44.90-45.00: work with 4 captions
2025-12-31 13:29:14,393 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.00-45.00: work with 3 captions
2025-12-31 13:29:16,764 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=45.17s with 4 samples
2025-12-31 13:29:21,723 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.10-45.10: work with 3 captions
2025-12-31 13:29:21,724 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.20-45.20: idle with 1 captions
2025-12-31 13:29:23,987 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=45.30s with 4 samples
2025-12-31 13:29:32,036 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.20-45.20: work with 2 captions
2025-12-31 13:29:32,036 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.30-45.30: idle with 2 captions
2025-12-31 13:29:34,614 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=45.43s with 4 samples
2025-12-31 13:29:40,066 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.40-45.40: work with 3 captions
2025-12-31 13:29:42,960 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=45.57s with 4 samples
2025-12-31 13:29:58,797 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=45.70s with 4 samples
2025-12-31 13:30:07,248 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.60-45.60: work with 2 captions
2025-12-31 13:30:07,249 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.70-45.70: idle with 2 captions
2025-12-31 13:30:10,510 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=45.83s with 4 samples
2025-12-31 13:30:18,298 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.70-45.80: work with 4 captions
2025-12-31 13:30:18,298 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.80-45.80: idle with 3 captions
2025-12-31 13:30:18,301 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.80-45.80: work with 3 captions
2025-12-31 13:30:21,203 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=45.97s with 4 samples
2025-12-31 13:30:27,640 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.90-45.90: work with 3 captions
2025-12-31 13:30:27,641 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.90-45.90: work with 3 captions
2025-12-31 13:30:27,641 backend.stream_utils - INFO [PARSE_LLM] Created segment 45.90-45.90: work with 3 captions
2025-12-31 13:30:27,641 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.00-46.00: idle with 1 captions
2025-12-31 13:30:27,641 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:30:30,338 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.10s with 4 samples
2025-12-31 13:30:38,922 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.23s with 4 samples
2025-12-31 13:31:02,117 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.10-46.20: work with 4 captions
2025-12-31 13:31:02,120 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,122 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,124 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.10-46.20: work with 4 captions
2025-12-31 13:31:02,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,129 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,131 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.10-46.20: work with 4 captions
2025-12-31 13:31:02,133 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,135 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,136 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.10-46.20: work with 4 captions
2025-12-31 13:31:02,138 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,140 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.10-46.20: work with 4 captions
2025-12-31 13:31:02,141 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,143 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.10-46.20: work with 4 captions
2025-12-31 13:31:02,145 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.10-46.20: work with 4 captions
2025-12-31 13:31:02,148 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,150 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.10-46.20: work with 4 captions
2025-12-31 13:31:02,152 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,153 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.10-46.20: work with 4 captions
2025-12-31 13:31:02,155 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,156 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.10-46.20: work with 4 captions
2025-12-31 13:31:02,158 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,158 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.10-46.20: work with 4 captions
2025-12-31 13:31:02,160 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.20-46.20: work with 3 captions
2025-12-31 13:31:02,163 backend.stream_utils - INFO [PARSE_LLM] Removed 22 duplicate segment(s) in window
2025-12-31 13:31:04,336 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.37s with 4 samples
2025-12-31 13:31:11,636 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.30-46.30: work with 3 captions
2025-12-31 13:31:14,573 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.50s with 4 samples
2025-12-31 13:31:20,608 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.40-46.40: work with 2 captions
2025-12-31 13:31:20,608 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.50-46.50: idle with 2 captions
2025-12-31 13:31:22,973 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.63s with 4 samples
2025-12-31 13:31:43,004 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.60-46.60: work with 3 captions
2025-12-31 13:31:43,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.60-46.60: work with 3 captions
2025-12-31 13:31:43,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.60-46.60: work with 3 captions
2025-12-31 13:31:43,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.50-46.60: work with 4 captions
2025-12-31 13:31:43,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.60-46.60: work with 3 captions
2025-12-31 13:31:43,005 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.50-46.60: work with 4 captions
2025-12-31 13:31:43,006 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.60-46.60: work with 3 captions
2025-12-31 13:31:43,006 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.60-46.60: work with 3 captions
2025-12-31 13:31:43,006 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.50-46.60: work with 4 captions
2025-12-31 13:31:43,006 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.50-46.60: work with 4 captions
2025-12-31 13:31:43,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.60-46.60: work with 3 captions
2025-12-31 13:31:43,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.50-46.60: work with 4 captions
2025-12-31 13:31:43,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.50-46.60: work with 4 captions
2025-12-31 13:31:43,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.60-46.60: work with 3 captions
2025-12-31 13:31:43,007 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.50-46.60: work with 4 captions
2025-12-31 13:31:43,008 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.60-46.60: work with 3 captions
2025-12-31 13:31:43,008 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.50-46.60: work with 4 captions
2025-12-31 13:31:43,008 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.60-46.60: work with 3 captions
2025-12-31 13:31:43,008 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.50-46.60: work with 4 captions
2025-12-31 13:31:43,009 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.60-46.60: work with 3 captions
2025-12-31 13:31:43,009 backend.stream_utils - INFO [PARSE_LLM] Removed 18 duplicate segment(s) in window
2025-12-31 13:31:45,302 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.77s with 4 samples
2025-12-31 13:31:53,869 backend.stream_utils - INFO [PARSE_LLM] Created segment 46.70-46.80: work with 4 captions
2025-12-31 13:31:56,685 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.90s with 4 samples
2025-12-31 13:32:09,375 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.03s with 4 samples
2025-12-31 13:32:12,964 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.00-47.00: work with 3 captions
2025-12-31 13:32:15,168 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.17s with 4 samples
2025-12-31 13:32:20,750 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-47.20: idle with 4 captions
2025-12-31 13:32:20,751 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-47.20: idle with 4 captions
2025-12-31 13:32:20,751 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.10-47.20: idle with 4 captions
2025-12-31 13:32:20,751 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:32:22,840 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.30s with 4 samples
2025-12-31 13:32:26,643 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.20-47.20: work with 2 captions
2025-12-31 13:32:26,643 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.30-47.30: idle with 2 captions
2025-12-31 13:32:29,917 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.43s with 4 samples
2025-12-31 13:32:38,290 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-47.30: work with 1 captions
2025-12-31 13:32:38,290 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.40-47.40: work with 3 captions
2025-12-31 13:32:38,290 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.40-47.40: work with 3 captions
2025-12-31 13:32:38,291 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.40-47.40: work with 3 captions
2025-12-31 13:32:38,291 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.30-47.30: work with 1 captions
2025-12-31 13:32:38,291 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.40-47.40: work with 3 captions
2025-12-31 13:32:38,292 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.40-47.40: work with 3 captions
2025-12-31 13:32:38,292 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.40-47.40: work with 3 captions
2025-12-31 13:32:38,292 backend.stream_utils - INFO [PARSE_LLM] Removed 5 duplicate segment(s) in window
2025-12-31 13:32:40,355 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.57s with 4 samples
2025-12-31 13:32:49,153 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.70s with 4 samples
2025-12-31 13:32:57,323 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.60-47.60: work with 2 captions
2025-12-31 13:32:57,323 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.70-47.70: idle with 2 captions
2025-12-31 13:32:57,323 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.70-47.70: work with 2 captions
2025-12-31 13:32:59,802 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.83s with 4 samples
2025-12-31 13:33:16,250 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.97s with 4 samples
2025-12-31 13:33:29,661 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.00: work with 1 captions
2025-12-31 13:33:29,662 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.00: work with 1 captions
2025-12-31 13:33:29,662 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.00: work with 1 captions
2025-12-31 13:33:29,662 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.00: work with 1 captions
2025-12-31 13:33:29,663 backend.stream_utils - INFO [PARSE_LLM] Created segment 47.90-47.90: work with 3 captions
2025-12-31 13:33:29,663 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.00-48.00: work with 1 captions
2025-12-31 13:33:29,664 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:33:32,030 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=48.10s with 4 samples
2025-12-31 13:33:38,767 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.10-48.10: idle with 2 captions
2025-12-31 13:33:38,768 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.10-48.10: idle with 2 captions
2025-12-31 13:33:38,768 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 13:33:41,082 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=48.23s with 4 samples
2025-12-31 13:33:52,853 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=48.37s with 4 samples
2025-12-31 13:34:03,130 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.30-48.30: work with 3 captions
2025-12-31 13:34:03,130 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.40-48.40: idle with 1 captions
2025-12-31 13:34:03,130 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.30-48.30: work with 3 captions
2025-12-31 13:34:03,130 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.40-48.40: idle with 1 captions
2025-12-31 13:34:03,132 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.30-48.30: work with 3 captions
2025-12-31 13:34:03,132 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.40-48.40: idle with 1 captions
2025-12-31 13:34:03,133 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.30-48.30: work with 3 captions
2025-12-31 13:34:03,134 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.40-48.40: idle with 1 captions
2025-12-31 13:34:03,136 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.30-48.30: work with 3 captions
2025-12-31 13:34:03,136 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.40-48.40: idle with 1 captions
2025-12-31 13:34:03,137 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2025-12-31 13:34:05,309 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=48.50s with 4 samples
2025-12-31 13:34:15,581 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=48.63s with 4 samples
2025-12-31 13:34:20,747 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.60-48.60: idle with 3 captions
2025-12-31 13:34:20,748 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.60-48.60: work with 3 captions
2025-12-31 13:34:20,748 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.60-48.60: work with 3 captions
2025-12-31 13:34:20,749 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 13:34:23,270 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=48.77s with 4 samples
2025-12-31 13:34:32,720 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.70-48.70: work with 3 captions
2025-12-31 13:34:32,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.80-48.80: idle with 1 captions
2025-12-31 13:34:32,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.70-48.70: work with 3 captions
2025-12-31 13:34:32,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.80-48.80: idle with 1 captions
2025-12-31 13:34:32,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.70-48.70: work with 3 captions
2025-12-31 13:34:32,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.80-48.80: idle with 1 captions
2025-12-31 13:34:32,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.70-48.70: work with 3 captions
2025-12-31 13:34:32,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 48.80-48.80: idle with 1 captions
2025-12-31 13:34:32,723 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 13:34:35,917 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=48.90s with 4 samples
2025-12-31 13:34:59,302 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.03s with 4 samples
2025-12-31 13:35:06,332 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.17s with 4 samples
2025-12-31 13:35:19,731 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-49.10: idle with 3 captions
2025-12-31 13:35:19,731 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.20-49.20: work with 1 captions
2025-12-31 13:35:19,732 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-49.10: idle with 3 captions
2025-12-31 13:35:19,732 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.20-49.20: work with 1 captions
2025-12-31 13:35:19,732 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-49.10: idle with 3 captions
2025-12-31 13:35:19,733 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.20-49.20: work with 1 captions
2025-12-31 13:35:19,733 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.10-49.10: idle with 3 captions
2025-12-31 13:35:19,733 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.20-49.20: work with 1 captions
2025-12-31 13:35:19,734 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 13:35:21,989 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.30s with 4 samples
2025-12-31 13:35:32,689 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.43s with 4 samples
2025-12-31 13:35:46,406 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.57s with 4 samples
2025-12-31 13:35:54,802 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.50-49.50: work with 3 captions
2025-12-31 13:35:54,803 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.50-49.50: work with 3 captions
2025-12-31 13:35:54,803 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.50-49.50: work with 3 captions
2025-12-31 13:35:54,803 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.50-49.50: work with 3 captions
2025-12-31 13:35:54,804 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.50-49.50: work with 3 captions
2025-12-31 13:35:54,804 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.50-49.50: work with 3 captions
2025-12-31 13:35:54,804 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.60-49.60: work with 1 captions
2025-12-31 13:35:54,804 backend.stream_utils - INFO [PARSE_LLM] Removed 5 duplicate segment(s) in window
2025-12-31 13:35:58,113 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.70s with 4 samples
2025-12-31 13:36:18,158 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.83s with 4 samples
2025-12-31 13:36:27,224 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.70-49.80: work with 4 captions
2025-12-31 13:36:27,224 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.80-49.80: work with 3 captions
2025-12-31 13:36:27,225 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.80-49.80: work with 3 captions
2025-12-31 13:36:27,225 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.70-49.80: work with 4 captions
2025-12-31 13:36:27,225 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.80-49.80: work with 3 captions
2025-12-31 13:36:27,225 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.80-49.80: work with 3 captions
2025-12-31 13:36:27,225 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.70-49.80: work with 4 captions
2025-12-31 13:36:27,226 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.80-49.80: work with 3 captions
2025-12-31 13:36:27,226 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.80-49.80: work with 3 captions
2025-12-31 13:36:27,226 backend.stream_utils - INFO [PARSE_LLM] Removed 7 duplicate segment(s) in window
2025-12-31 13:36:29,586 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=49.97s with 4 samples
2025-12-31 13:36:34,948 backend.stream_utils - INFO [PARSE_LLM] Created segment 49.90-49.90: work with 3 captions
2025-12-31 13:36:34,949 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.00-50.00: idle with 1 captions
2025-12-31 13:36:37,989 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=50.10s with 4 samples
2025-12-31 13:36:48,124 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.00-50.00: work with 2 captions
2025-12-31 13:36:48,125 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.10: idle with 2 captions
2025-12-31 13:36:48,125 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.00-50.00: work with 2 captions
2025-12-31 13:36:48,125 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.10: idle with 2 captions
2025-12-31 13:36:48,125 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.10: work with 2 captions
2025-12-31 13:36:48,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.00-50.00: work with 2 captions
2025-12-31 13:36:48,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.10: idle with 2 captions
2025-12-31 13:36:48,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.10: work with 2 captions
2025-12-31 13:36:48,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.00-50.00: work with 2 captions
2025-12-31 13:36:48,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.10: idle with 2 captions
2025-12-31 13:36:48,127 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.10: work with 2 captions
2025-12-31 13:36:48,127 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.00-50.00: work with 2 captions
2025-12-31 13:36:48,127 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.10: idle with 2 captions
2025-12-31 13:36:48,127 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.10: work with 2 captions
2025-12-31 13:36:48,127 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.00-50.00: work with 2 captions
2025-12-31 13:36:48,128 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.10: idle with 2 captions
2025-12-31 13:36:48,128 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.10: work with 2 captions
2025-12-31 13:36:48,128 backend.stream_utils - INFO [PARSE_LLM] Removed 14 duplicate segment(s) in window
2025-12-31 13:36:50,976 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=50.23s with 4 samples
2025-12-31 13:36:58,068 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.10-50.20: work with 4 captions
2025-12-31 13:36:58,069 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.20-50.20: idle with 3 captions
2025-12-31 13:37:00,273 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=50.37s with 4 samples
2025-12-31 13:37:10,664 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=50.50s with 4 samples
2025-12-31 13:37:37,085 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.40-50.40: work with 2 captions
2025-12-31 13:37:37,085 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.50-50.50: work with 2 captions
2025-12-31 13:37:39,306 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=50.63s with 4 samples
2025-12-31 13:39:39,335 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:39:39,335 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:39:41,806 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=50.77s with 4 samples
2025-12-31 13:39:52,191 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.70-50.70: work with 3 captions
2025-12-31 13:39:52,192 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.70-50.70: work with 3 captions
2025-12-31 13:39:52,192 backend.stream_utils - INFO [PARSE_LLM] Created segment 50.80-50.80: idle with 1 captions
2025-12-31 13:39:52,193 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 13:39:54,986 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=50.90s with 4 samples
2025-12-31 13:40:10,335 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=51.03s with 4 samples
2025-12-31 13:40:26,819 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=51.17s with 4 samples
2025-12-31 13:40:40,410 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=51.30s with 4 samples
2025-12-31 13:40:46,076 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.20-51.20: work with 2 captions
2025-12-31 13:40:46,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.30-51.30: idle with 2 captions
2025-12-31 13:40:46,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.20-51.20: work with 2 captions
2025-12-31 13:40:46,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.30-51.30: idle with 2 captions
2025-12-31 13:40:46,077 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.20-51.20: work with 2 captions
2025-12-31 13:40:46,078 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.30-51.30: idle with 2 captions
2025-12-31 13:40:46,078 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:40:48,594 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=51.43s with 4 samples
2025-12-31 13:40:54,074 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.30-51.40: work with 4 captions
2025-12-31 13:40:56,554 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=51.57s with 4 samples
2025-12-31 13:41:19,923 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.50-51.60: work with 4 captions
2025-12-31 13:41:22,120 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=51.70s with 4 samples
2025-12-31 13:41:31,648 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:41:31,649 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:41:34,155 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=51.83s with 4 samples
2025-12-31 13:41:43,170 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=51.97s with 4 samples
2025-12-31 13:41:55,181 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.90-51.90: work with 3 captions
2025-12-31 13:41:55,181 backend.stream_utils - INFO [PARSE_LLM] Created segment 51.90-51.90: work with 3 captions
2025-12-31 13:41:55,181 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.00-52.00: work with 1 captions
2025-12-31 13:41:55,182 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 13:41:58,386 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=52.10s with 4 samples
2025-12-31 13:42:06,716 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=52.23s with 4 samples
2025-12-31 13:42:25,105 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=52.37s with 4 samples
2025-12-31 13:42:37,306 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=52.50s with 4 samples
2025-12-31 13:42:44,781 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=52.63s with 4 samples
2025-12-31 13:42:57,698 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.50-52.60: work with 4 captions
2025-12-31 13:42:57,698 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.60-52.60: work with 3 captions
2025-12-31 13:43:00,100 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=52.77s with 4 samples
2025-12-31 13:43:11,468 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=52.90s with 4 samples
2025-12-31 13:43:29,319 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=53.03s with 4 samples
2025-12-31 13:43:33,146 backend.stream_utils - INFO [PARSE_LLM] Created segment 52.90-53.00: work with 4 captions
2025-12-31 13:43:36,127 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=53.17s with 4 samples
2025-12-31 13:43:41,203 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.10-53.10: work with 3 captions
2025-12-31 13:43:41,204 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.20-53.20: idle with 1 captions
2025-12-31 13:43:43,453 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=53.30s with 4 samples
2025-12-31 13:43:50,092 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.20-53.20: work with 2 captions
2025-12-31 13:43:50,094 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.30-53.30: idle with 2 captions
2025-12-31 13:43:50,094 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.20-53.20: work with 2 captions
2025-12-31 13:43:50,094 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.30-53.30: idle with 2 captions
2025-12-31 13:43:50,095 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.20-53.20: work with 2 captions
2025-12-31 13:43:50,095 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.30-53.30: idle with 2 captions
2025-12-31 13:43:50,095 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:43:53,444 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=53.43s with 4 samples
2025-12-31 13:43:57,721 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.30-53.30: work with 1 captions
2025-12-31 13:43:57,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.40-53.40: work with 3 captions
2025-12-31 13:43:57,722 backend.stream_utils - INFO [PARSE_LLM] Created segment 53.40-53.40: work with 3 captions
2025-12-31 13:43:57,723 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2025-12-31 13:44:00,077 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=53.57s with 4 samples
2025-12-31 13:44:10,708 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=53.70s with 4 samples
2025-12-31 13:44:22,866 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=53.83s with 4 samples
2025-12-31 13:44:33,637 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=53.97s with 4 samples
2025-12-31 13:44:52,380 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.10s with 4 samples
2025-12-31 13:45:01,575 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.00-54.00: work with 2 captions
2025-12-31 13:45:01,576 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.10-54.10: idle with 2 captions
2025-12-31 13:45:01,576 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.10-54.10: work with 2 captions
2025-12-31 13:45:01,576 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.10-54.10: idle with 2 captions
2025-12-31 13:45:01,576 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.00-54.00: work with 2 captions
2025-12-31 13:45:01,577 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.10-54.10: idle with 2 captions
2025-12-31 13:45:01,577 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.10-54.10: work with 2 captions
2025-12-31 13:45:01,577 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.10-54.10: idle with 2 captions
2025-12-31 13:45:01,577 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.00-54.00: work with 2 captions
2025-12-31 13:45:01,578 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.10-54.10: idle with 2 captions
2025-12-31 13:45:01,578 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.10-54.10: work with 2 captions
2025-12-31 13:45:01,579 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.10-54.10: idle with 2 captions
2025-12-31 13:45:01,579 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-31 13:45:03,397 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.23s with 4 samples
2025-12-31 13:45:11,074 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.10-54.20: work with 4 captions
2025-12-31 13:45:11,075 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.20-54.20: work with 3 captions
2025-12-31 13:45:13,126 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.37s with 4 samples
2025-12-31 13:45:29,416 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.30-54.30: work with 3 captions
2025-12-31 13:45:29,416 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.30-54.30: work with 3 captions
2025-12-31 13:45:29,417 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.30-54.30: work with 3 captions
2025-12-31 13:45:29,417 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.30-54.30: work with 3 captions
2025-12-31 13:45:29,417 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-31 13:45:31,999 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.50s with 4 samples
2025-12-31 13:45:54,815 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.63s with 4 samples
2025-12-31 13:46:02,571 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.50-54.50: work with 1 captions
2025-12-31 13:46:02,571 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.60-54.60: work with 3 captions
2025-12-31 13:46:02,572 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.60-54.60: work with 3 captions
2025-12-31 13:46:02,572 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.60-54.60: work with 3 captions
2025-12-31 13:46:02,572 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:46:04,885 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.77s with 4 samples
2025-12-31 13:46:13,245 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.70-54.70: work with 3 captions
2025-12-31 13:46:13,245 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.80-54.80: idle with 1 captions
2025-12-31 13:46:15,538 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.90s with 4 samples
2025-12-31 13:46:26,531 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.80-54.80: work with 2 captions
2025-12-31 13:46:26,532 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.90-54.90: idle with 2 captions
2025-12-31 13:46:26,532 backend.stream_utils - INFO [PARSE_LLM] Created segment 54.90-54.90: work with 2 captions
2025-12-31 13:46:29,134 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=55.03s with 4 samples
2025-12-31 13:46:49,640 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=55.17s with 4 samples
2025-12-31 13:47:00,001 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.10-55.10: work with 3 captions
2025-12-31 13:47:00,001 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.10-55.10: work with 3 captions
2025-12-31 13:47:00,001 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.20-55.20: work with 1 captions
2025-12-31 13:47:00,001 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.10-55.10: work with 3 captions
2025-12-31 13:47:00,003 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.10-55.10: work with 3 captions
2025-12-31 13:47:00,003 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.20-55.20: work with 1 captions
2025-12-31 13:47:00,003 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.10-55.10: work with 3 captions
2025-12-31 13:47:00,004 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.10-55.10: work with 3 captions
2025-12-31 13:47:00,004 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.20-55.20: work with 1 captions
2025-12-31 13:47:00,004 backend.stream_utils - INFO [PARSE_LLM] Removed 7 duplicate segment(s) in window
2025-12-31 13:47:01,995 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=55.30s with 4 samples
2025-12-31 13:47:12,019 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=55.43s with 4 samples
2025-12-31 13:47:29,704 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.30-55.30: work with 1 captions
2025-12-31 13:47:29,705 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.40-55.40: idle with 3 captions
2025-12-31 13:47:29,705 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.40-55.40: idle with 3 captions
2025-12-31 13:47:29,705 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.30-55.30: work with 1 captions
2025-12-31 13:47:29,705 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.40-55.40: idle with 3 captions
2025-12-31 13:47:29,705 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.40-55.40: idle with 3 captions
2025-12-31 13:47:29,706 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.30-55.30: work with 1 captions
2025-12-31 13:47:29,706 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.40-55.40: idle with 3 captions
2025-12-31 13:47:29,706 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.40-55.40: idle with 3 captions
2025-12-31 13:47:29,706 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.40-55.40: idle with 3 captions
2025-12-31 13:47:29,707 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.30-55.30: work with 1 captions
2025-12-31 13:47:29,707 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.40-55.40: idle with 3 captions
2025-12-31 13:47:29,707 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.40-55.40: idle with 3 captions
2025-12-31 13:47:29,707 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.30-55.30: work with 1 captions
2025-12-31 13:47:29,708 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.40-55.40: idle with 3 captions
2025-12-31 13:47:29,708 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.40-55.40: idle with 3 captions
2025-12-31 13:47:29,708 backend.stream_utils - INFO [PARSE_LLM] Removed 14 duplicate segment(s) in window
2025-12-31 13:47:31,910 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=55.57s with 4 samples
2025-12-31 13:47:37,924 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:47:37,924 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:47:40,035 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=55.70s with 4 samples
2025-12-31 13:47:45,914 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.60-55.60: work with 2 captions
2025-12-31 13:47:45,914 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: idle with 2 captions
2025-12-31 13:47:45,917 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: work with 2 captions
2025-12-31 13:47:48,335 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=55.83s with 4 samples
2025-12-31 13:48:17,658 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.70-55.70: work with 1 captions
2025-12-31 13:48:19,754 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=55.97s with 4 samples
2025-12-31 13:48:33,094 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.90-56.00: idle with 4 captions
2025-12-31 13:48:33,094 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.90-55.90: work with 3 captions
2025-12-31 13:48:33,094 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.90-56.00: idle with 4 captions
2025-12-31 13:48:33,094 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.90-55.90: work with 3 captions
2025-12-31 13:48:33,095 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.90-56.00: idle with 4 captions
2025-12-31 13:48:33,095 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.90-55.90: work with 3 captions
2025-12-31 13:48:33,095 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.90-56.00: idle with 4 captions
2025-12-31 13:48:33,095 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.90-55.90: work with 3 captions
2025-12-31 13:48:33,095 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.90-56.00: idle with 4 captions
2025-12-31 13:48:33,095 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.90-55.90: work with 3 captions
2025-12-31 13:48:33,096 backend.stream_utils - INFO [PARSE_LLM] Created segment 55.90-56.00: idle with 4 captions
2025-12-31 13:48:33,096 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2025-12-31 13:48:35,718 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=56.10s with 4 samples
2025-12-31 13:48:45,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-56.00: work with 2 captions
2025-12-31 13:48:45,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-56.00: idle with 2 captions
2025-12-31 13:48:45,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.10-56.10: work with 2 captions
2025-12-31 13:48:45,115 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-56.00: work with 2 captions
2025-12-31 13:48:45,116 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.00-56.00: idle with 2 captions
2025-12-31 13:48:45,116 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.10-56.10: work with 2 captions
2025-12-31 13:48:45,116 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2025-12-31 13:48:47,587 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=56.23s with 4 samples
2025-12-31 13:48:52,243 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.10-56.20: work with 4 captions
2025-12-31 13:48:54,748 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=56.37s with 4 samples
2025-12-31 13:49:03,104 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:49:03,104 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:49:05,456 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=56.50s with 4 samples
2025-12-31 13:49:17,852 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.40-56.50: work with 4 captions
2025-12-31 13:49:17,853 backend.stream_utils - INFO [PARSE_LLM] Created segment 56.50-56.50: work with 2 captions
2025-12-31 13:49:20,200 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=56.63s with 4 samples
2025-12-31 13:49:32,269 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=56.77s with 4 samples
2025-12-31 13:49:44,769 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=56.90s with 4 samples
2025-12-31 13:49:49,621 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:49:49,621 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:49:51,433 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.03s with 4 samples
2025-12-31 13:49:58,861 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.17s with 4 samples
2025-12-31 13:50:05,579 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.30s with 4 samples
2025-12-31 13:50:12,859 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.20-57.20: work with 2 captions
2025-12-31 13:50:12,859 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.30-57.30: work with 2 captions
2025-12-31 13:50:14,386 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.43s with 4 samples
2025-12-31 13:50:23,424 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.30-57.40: work with 4 captions
2025-12-31 13:50:23,424 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.40-57.40: work with 3 captions
2025-12-31 13:50:23,425 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.30-57.40: work with 4 captions
2025-12-31 13:50:23,425 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.40-57.40: work with 3 captions
2025-12-31 13:50:23,425 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.30-57.40: work with 4 captions
2025-12-31 13:50:23,425 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.40-57.40: work with 3 captions
2025-12-31 13:50:23,425 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:50:24,727 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.57s with 4 samples
2025-12-31 13:50:48,816 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.70s with 4 samples
2025-12-31 13:50:54,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.60-57.60: work with 2 captions
2025-12-31 13:50:54,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.70-57.70: idle with 2 captions
2025-12-31 13:50:54,599 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.60-57.60: work with 2 captions
2025-12-31 13:50:54,600 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.70-57.70: idle with 2 captions
2025-12-31 13:50:54,600 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.60-57.60: work with 2 captions
2025-12-31 13:50:54,600 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.70-57.70: idle with 2 captions
2025-12-31 13:50:54,600 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:50:56,213 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.83s with 4 samples
2025-12-31 13:51:04,408 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.97s with 4 samples
2025-12-31 13:51:31,763 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,764 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,764 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.00-58.00: idle with 1 captions
2025-12-31 13:51:31,764 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,764 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,765 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.00-58.00: idle with 1 captions
2025-12-31 13:51:31,765 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,765 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,765 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,766 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.00-58.00: idle with 1 captions
2025-12-31 13:51:31,766 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,766 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,766 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.00-58.00: idle with 1 captions
2025-12-31 13:51:31,766 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,766 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,766 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.00-58.00: work with 1 captions
2025-12-31 13:51:31,766 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,766 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,767 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.00-58.00: work with 1 captions
2025-12-31 13:51:31,767 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,767 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,767 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.00-58.00: work with 1 captions
2025-12-31 13:51:31,767 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,767 backend.stream_utils - INFO [PARSE_LLM] Created segment 57.90-57.90: work with 3 captions
2025-12-31 13:51:31,767 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.00-58.00: work with 1 captions
2025-12-31 13:51:31,767 backend.stream_utils - INFO [PARSE_LLM] Removed 22 duplicate segment(s) in window
2025-12-31 13:51:33,181 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=58.10s with 4 samples
2025-12-31 13:51:57,891 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=58.23s with 4 samples
2025-12-31 13:52:26,887 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=58.37s with 4 samples
2025-12-31 13:52:39,933 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.30-58.40: work with 4 captions
2025-12-31 13:52:41,573 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=58.50s with 4 samples
2025-12-31 13:52:50,105 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.40-58.40: work with 2 captions
2025-12-31 13:52:50,106 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.50-58.50: idle with 2 captions
2025-12-31 13:52:51,529 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=58.63s with 4 samples
2025-12-31 13:53:07,101 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.50-58.60: work with 4 captions
2025-12-31 13:53:08,570 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=58.77s with 4 samples
2025-12-31 13:53:20,901 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.70-58.70: work with 3 captions
2025-12-31 13:53:20,902 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.80-58.80: idle with 1 captions
2025-12-31 13:53:20,902 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.70-58.70: work with 3 captions
2025-12-31 13:53:20,902 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.70-58.70: work with 3 captions
2025-12-31 13:53:20,902 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.80-58.80: idle with 1 captions
2025-12-31 13:53:20,903 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.70-58.70: work with 3 captions
2025-12-31 13:53:20,903 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.70-58.70: work with 3 captions
2025-12-31 13:53:20,903 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.80-58.80: idle with 1 captions
2025-12-31 13:53:20,903 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.70-58.70: work with 3 captions
2025-12-31 13:53:20,903 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.70-58.70: work with 3 captions
2025-12-31 13:53:20,904 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.80-58.80: idle with 1 captions
2025-12-31 13:53:20,904 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.70-58.70: work with 3 captions
2025-12-31 13:53:20,904 backend.stream_utils - INFO [PARSE_LLM] Removed 10 duplicate segment(s) in window
2025-12-31 13:53:22,572 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=58.90s with 4 samples
2025-12-31 13:53:28,949 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=59.03s with 4 samples
2025-12-31 13:53:36,609 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.90-59.00: work with 4 captions
2025-12-31 13:53:36,610 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.00-59.00: idle with 3 captions
2025-12-31 13:53:36,610 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.00-59.00: work with 3 captions
2025-12-31 13:53:36,610 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.90-59.00: work with 4 captions
2025-12-31 13:53:36,610 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.00-59.00: idle with 3 captions
2025-12-31 13:53:36,611 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.00-59.00: work with 3 captions
2025-12-31 13:53:36,611 backend.stream_utils - INFO [PARSE_LLM] Created segment 58.90-59.00: work with 4 captions
2025-12-31 13:53:36,611 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.00-59.00: idle with 3 captions
2025-12-31 13:53:36,611 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.00-59.00: work with 3 captions
2025-12-31 13:53:36,612 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2025-12-31 13:53:38,165 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=59.17s with 4 samples
2025-12-31 13:53:51,009 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=59.30s with 4 samples
2025-12-31 13:54:03,929 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=59.43s with 4 samples
2025-12-31 13:54:09,517 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.30-59.40: work with 4 captions
2025-12-31 13:54:11,090 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=59.57s with 4 samples
2025-12-31 13:54:17,549 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.50-59.50: work with 3 captions
2025-12-31 13:54:17,549 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.60-59.60: idle with 1 captions
2025-12-31 13:54:19,172 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=59.70s with 4 samples
2025-12-31 13:54:37,536 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=59.83s with 4 samples
2025-12-31 13:55:09,040 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.70-59.70: work with 1 captions
2025-12-31 13:55:09,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.70-59.70: work with 1 captions
2025-12-31 13:55:09,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,041 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,042 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.70-59.70: work with 1 captions
2025-12-31 13:55:09,042 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,042 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.70-59.70: work with 1 captions
2025-12-31 13:55:09,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,043 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.70-59.70: work with 1 captions
2025-12-31 13:55:09,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.70-59.70: work with 1 captions
2025-12-31 13:55:09,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,044 backend.stream_utils - INFO [PARSE_LLM] Created segment 59.80-59.80: work with 3 captions
2025-12-31 13:55:09,044 backend.stream_utils - INFO [PARSE_LLM] Removed 16 duplicate segment(s) in window
2025-12-31 13:55:10,565 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=59.97s with 4 samples
2025-12-31 13:55:32,534 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=60.10s with 4 samples
2025-12-31 13:55:39,597 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:55:39,597 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:55:41,181 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=60.23s with 4 samples
2025-12-31 13:55:55,315 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.10-60.20: work with 4 captions
2025-12-31 13:55:55,315 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.20-60.20: idle with 3 captions
2025-12-31 13:55:55,316 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.20-60.20: work with 3 captions
2025-12-31 13:55:56,857 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=60.37s with 4 samples
2025-12-31 13:56:07,019 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.30-60.30: work with 3 captions
2025-12-31 13:56:07,019 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.40-60.40: work with 1 captions
2025-12-31 13:56:08,493 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=60.50s with 4 samples
2025-12-31 13:56:16,547 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.40-60.40: work with 2 captions
2025-12-31 13:56:16,547 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.50-60.50: idle with 2 captions
2025-12-31 13:56:17,974 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=60.63s with 4 samples
2025-12-31 13:56:35,472 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.60-60.60: work with 3 captions
2025-12-31 13:56:35,473 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.50-60.60: work with 4 captions
2025-12-31 13:56:35,473 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.60-60.60: work with 3 captions
2025-12-31 13:56:35,473 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-60.60: work with 4 captions
2025-12-31 13:56:35,473 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.60-60.60: work with 3 captions
2025-12-31 13:56:35,473 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:56:37,449 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=60.77s with 4 samples
2025-12-31 13:56:42,865 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.70-60.70: work with 3 captions
2025-12-31 13:56:42,865 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.80-60.80: work with 1 captions
2025-12-31 13:56:44,419 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=60.90s with 4 samples
2025-12-31 13:56:50,081 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.80-60.80: work with 2 captions
2025-12-31 13:56:50,081 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.90-60.90: idle with 2 captions
2025-12-31 13:56:51,565 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=61.03s with 4 samples
2025-12-31 13:57:19,110 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=61.17s with 4 samples
2025-12-31 13:57:29,460 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=61.30s with 4 samples
2025-12-31 13:57:34,551 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.20-61.20: work with 2 captions
2025-12-31 13:57:34,551 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.30-61.30: idle with 2 captions
2025-12-31 13:57:34,551 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.30-61.30: work with 2 captions
2025-12-31 13:57:36,208 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=61.43s with 4 samples
2025-12-31 13:57:48,702 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.40-61.40: work with 3 captions
2025-12-31 13:57:48,703 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.40-61.40: work with 3 captions
2025-12-31 13:57:48,703 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.40-61.40: work with 3 captions
2025-12-31 13:57:48,703 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:57:50,406 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=61.57s with 4 samples
2025-12-31 13:57:55,926 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.50-61.50: work with 3 captions
2025-12-31 13:57:55,926 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.50-61.60: idle with 4 captions
2025-12-31 13:57:57,461 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=61.70s with 4 samples
2025-12-31 13:58:03,356 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=61.83s with 4 samples
2025-12-31 13:58:06,781 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:58:06,781 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:58:08,478 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=61.97s with 4 samples
2025-12-31 13:58:19,776 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.90-61.90: work with 3 captions
2025-12-31 13:58:19,776 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.90-62.00: work with 4 captions
2025-12-31 13:58:19,776 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.90-61.90: work with 3 captions
2025-12-31 13:58:19,777 backend.stream_utils - INFO [PARSE_LLM] Created segment 61.90-62.00: work with 4 captions
2025-12-31 13:58:19,777 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 13:58:21,604 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.10s with 4 samples
2025-12-31 13:58:28,705 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:58:28,705 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:58:30,551 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.23s with 4 samples
2025-12-31 13:58:43,727 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.10-62.20: work with 4 captions
2025-12-31 13:58:43,727 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.20-62.20: work with 3 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.10-62.20: work with 4 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.20-62.20: work with 3 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.10-62.20: work with 4 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.20-62.20: work with 3 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.10-62.20: work with 4 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.20-62.20: work with 3 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.10-62.20: work with 4 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.20-62.20: work with 3 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.10-62.20: work with 4 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.20-62.20: work with 3 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.10-62.20: work with 4 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.20-62.20: work with 3 captions
2025-12-31 13:58:43,728 backend.stream_utils - INFO [PARSE_LLM] Removed 12 duplicate segment(s) in window
2025-12-31 13:58:45,302 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.37s with 4 samples
2025-12-31 13:58:49,096 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.30-62.30: work with 3 captions
2025-12-31 13:58:49,096 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.30-62.40: idle with 4 captions
2025-12-31 13:58:50,661 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.50s with 4 samples
2025-12-31 13:58:59,730 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.40-62.40: work with 2 captions
2025-12-31 13:58:59,731 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.50-62.50: work with 2 captions
2025-12-31 13:58:59,731 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.40-62.40: work with 2 captions
2025-12-31 13:58:59,731 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.50-62.50: work with 2 captions
2025-12-31 13:58:59,731 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.40-62.40: work with 2 captions
2025-12-31 13:58:59,731 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.50-62.50: work with 2 captions
2025-12-31 13:58:59,732 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2025-12-31 13:59:01,271 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.63s with 4 samples
2025-12-31 13:59:17,031 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.77s with 4 samples
2025-12-31 13:59:25,068 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:59:25,069 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 13:59:26,937 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.90s with 4 samples
2025-12-31 13:59:35,928 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=63.03s with 4 samples
2025-12-31 13:59:43,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 62.90-63.00: work with 4 captions
2025-12-31 13:59:43,860 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.00-63.00: work with 3 captions
2025-12-31 13:59:45,680 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=63.17s with 4 samples
2025-12-31 13:59:51,061 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.10-63.10: work with 3 captions
2025-12-31 13:59:51,061 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.20-63.20: work with 1 captions
2025-12-31 13:59:52,825 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=63.30s with 4 samples
2025-12-31 13:59:58,679 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 13:59:58,679 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 14:00:00,387 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=63.43s with 4 samples
2025-12-31 14:00:08,203 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.30-63.40: work with 4 captions
2025-12-31 14:00:08,203 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.40-63.40: work with 3 captions
2025-12-31 14:00:08,204 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.40-63.40: work with 3 captions
2025-12-31 14:00:08,204 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.40-63.40: work with 3 captions
2025-12-31 14:00:08,204 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 14:00:09,835 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=63.57s with 4 samples
2025-12-31 14:00:18,623 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.50-63.50: work with 3 captions
2025-12-31 14:00:18,623 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.60-63.60: idle with 1 captions
2025-12-31 14:00:20,328 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=63.70s with 4 samples
2025-12-31 14:00:28,532 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.60-63.60: work with 2 captions
2025-12-31 14:00:28,532 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.70-63.70: work with 2 captions
2025-12-31 14:00:28,533 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.60-63.60: work with 2 captions
2025-12-31 14:00:28,533 backend.stream_utils - INFO [PARSE_LLM] Created segment 63.70-63.70: work with 2 captions
2025-12-31 14:00:28,534 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2025-12-31 14:00:30,133 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=63.83s with 4 samples
2025-12-31 14:00:32,747 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2025-12-31 14:00:32,748 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 14:00:34,417 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=63.97s with 4 samples
2025-12-31 14:01:09,742 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=64.10s with 4 samples
2025-12-31 14:01:43,740 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=64.23s with 4 samples
2025-12-31 14:02:03,031 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2025-12-31 14:02:06,500 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 1 captions.
2025-12-31 14:02:06,501 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2025-12-31 14:02:06,503 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 1929
2025-12-31 14:02:06,503 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 483
2025-12-31 14:02:06,503 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (0.03333333333333333, 'arafed image of a man working in a facto'), (0.06666666666666667, 'arafed image of a man working in a facto'), (0.1, 'arafed image of a man working in a facto'), (0.13333333333333333, 'there is a man that is working on a mach'), (0.16666666666666666, 'there is a man that is working on a mach'), (0.2, 'arafed image of a man working on a machi'), (0.23333333333333334, 'arafed image of a man working in a facto'), (0.26666666666666666, 'there is a man that is working on a mach'), (0.3, 'there is a man that is working on a mach')]...
2025-12-31 14:02:06,504 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=0.1: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=0.0s: arafed image of a man work...
2025-12-31 14:02:06,504 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=0.23333333333333334: 4 samples, timeline=t=0.1s: there is a man that is working on a machine in a factory
t=0.2s: there is a man that is work...
2025-12-31 14:02:06,504 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=0.36666666666666664: 4 samples, timeline=t=0.3s: there is a man that is working on a machine in a factory
t=0.3s: there is a man that is work...
2025-12-31 14:02:06,505 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=0.5: 4 samples, timeline=t=0.4s: there is a man that is working on a machine in a factory
t=0.4s: arafed man standing in a fa...
2025-12-31 14:02:06,505 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=0.6333333333333333: 4 samples, timeline=t=0.5s: arafed man in a factory with a blue shirt and black gloves
t=0.6s: arafed man standing in a ...
2025-12-31 14:02:06,505 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=0.7666666666666667: 4 samples, timeline=t=0.7s: arafed man standing in a factory with a suitcase in his hand
t=0.7s: arafed man standing in ...
2025-12-31 14:02:06,505 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=0.9: 4 samples, timeline=t=0.8s: arafed man standing in a factory with a machine in the background
t=0.8s: arafed man standin...
2025-12-31 14:02:06,506 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=1.0333333333333334: 4 samples, timeline=t=0.9s: arafed man in blue shirt standing in factory with machines
t=1.0s: arafed man in blue shirt ...
2025-12-31 14:02:06,506 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=1.1666666666666667: 4 samples, timeline=t=1.1s: arafed man standing in a factory with a lot of machines
t=1.1s: arafed man standing in a fac...
2025-12-31 14:02:06,506 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #10 at t=1.3: 4 samples, timeline=t=1.2s: arafed man in blue shirt standing in factory with machines
t=1.2s: arafed man in a factory w...
2025-12-31 14:02:06,506 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #11 at t=1.4333333333333333: 4 samples, timeline=t=1.3s: arafed man in a factory with a machine in the background
t=1.4s: arafed man standing in a fa...
2025-12-31 14:02:06,507 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #12 at t=1.5666666666666667: 4 samples, timeline=t=1.5s: arafed man in blue shirt standing in factory with machine
t=1.5s: arafed man in a factory wi...
2025-12-31 14:02:06,507 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #13 at t=1.7: 4 samples, timeline=t=1.6s: arafed man in a factory with a machine in the background
t=1.6s: arafed man in a factory wit...
2025-12-31 14:02:06,507 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #14 at t=1.8333333333333333: 4 samples, timeline=t=1.7s: arafed man in a factory with a machine and a box
t=1.8s: arafed man in a factory with a mach...
2025-12-31 14:02:06,507 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #15 at t=1.9666666666666666: 4 samples, timeline=t=1.9s: arafed man in a factory with a machine in the background
t=1.9s: arafed man in a factory wit...
2025-12-31 14:02:06,507 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #16 at t=2.1: 4 samples, timeline=t=2.0s: someone is working on a laptop with a lot of tools
t=2.0s: someone is working on a laptop in...
2025-12-31 14:02:06,508 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #17 at t=2.2333333333333334: 4 samples, timeline=t=2.1s: there is a man that is standing in front of a computer
t=2.2s: someone is working on a compu...
2025-12-31 14:02:06,508 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #18 at t=2.3666666666666667: 4 samples, timeline=t=2.3s: arafed man working on a computer in a workshop
t=2.3s: there is a man that is playing a dj i...
2025-12-31 14:02:06,508 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #19 at t=2.5: 4 samples, timeline=t=2.4s: someone is working on a computer in a room with many electronics
t=2.4s: someone is typing o...
2025-12-31 14:02:06,508 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #20 at t=2.6333333333333333: 4 samples, timeline=t=2.5s: arafed man working on a computer in a factory
t=2.6s: arafed man working on a computer in a ...
2025-12-31 14:02:06,509 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #21 at t=2.7666666666666666: 4 samples, timeline=t=2.7s: arafed man in a blue shirt is working on a computer
t=2.7s: there is a man that is working o...
2025-12-31 14:02:06,509 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #22 at t=2.9: 4 samples, timeline=t=2.8s: there is a man that is working on a computer in a room
t=2.8s: araffe worker in a factory wo...
2025-12-31 14:02:06,509 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #23 at t=3.033333333333333: 4 samples, timeline=t=2.9s: arafed man in a blue shirt is working on a computer
t=3.0s: arafed man in a blue shirt is wo...
2025-12-31 14:02:06,509 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #24 at t=3.1666666666666665: 4 samples, timeline=t=3.1s: arafed man working on a computer in a factory
t=3.1s: araffe worker in a factory checking ou...
2025-12-31 14:02:06,509 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #25 at t=3.3: 4 samples, timeline=t=3.2s: arafed man in a blue shirt is looking at a shelf of wine bottles
t=3.2s: araffe worker in a ...
2025-12-31 14:02:06,509 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #26 at t=3.433333333333333: 4 samples, timeline=t=3.3s: there is a man that is looking at some bottles in a store
t=3.4s: there is a man that is loo...
2025-12-31 14:02:06,509 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #27 at t=3.566666666666667: 4 samples, timeline=t=3.5s: there is a man that is looking at some items in a store
t=3.5s: there is a man that is looki...
2025-12-31 14:02:06,509 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #28 at t=3.7: 4 samples, timeline=t=3.6s: arafed man working on a motorcycle in a factory
t=3.6s: arafed man working on a motorcycle i...
2025-12-31 14:02:06,510 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #29 at t=3.8333333333333335: 4 samples, timeline=t=3.7s: there is a man working on a motorcycle in a factory
t=3.8s: arafed man working on a motorcyc...
2025-12-31 14:02:06,510 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #30 at t=3.966666666666667: 4 samples, timeline=t=3.9s: araffe worker working on a motorcycle in a factory
t=3.9s: araffe worker working on a motorc...
2025-12-31 14:02:06,510 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #31 at t=4.1: 4 samples, timeline=t=4.0s: arafed worker working on a machine in a factory
t=4.0s: arafed worker working on a machine i...
2025-12-31 14:02:06,510 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #32 at t=4.233333333333333: 4 samples, timeline=t=4.1s: araffe worker working on a motorcycle in a factory
t=4.2s: arafed man working on a car in a ...
2025-12-31 14:02:06,510 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #33 at t=4.366666666666666: 4 samples, timeline=t=4.3s: arafed man working on a car in a factory
t=4.3s: arafed man working on a motorcycle in a fac...
2025-12-31 14:02:06,510 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #34 at t=4.5: 4 samples, timeline=t=4.4s: arafed man working on a motorcycle in a factory
t=4.4s: arafed man working on a motorcycle i...
2025-12-31 14:02:06,510 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #35 at t=4.633333333333334: 4 samples, timeline=t=4.5s: arafed man working on a motorcycle in a factory
t=4.6s: arafed man working on a motorcycle i...
2025-12-31 14:02:06,511 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #36 at t=4.766666666666667: 4 samples, timeline=t=4.7s: arafed man working on a computer in a factory
t=4.7s: arafed worker in a factory working on ...
2025-12-31 14:02:06,511 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #37 at t=4.9: 4 samples, timeline=t=4.8s: araffe worker in a factory working on a computer
t=4.8s: araffe worker in a factory working ...
2025-12-31 14:02:06,511 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #38 at t=5.033333333333333: 4 samples, timeline=t=4.9s: araffe worker in a factory working on a motorcycle
t=5.0s: araffe worker in a factory workin...
2025-12-31 14:02:06,511 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #39 at t=5.166666666666667: 4 samples, timeline=t=5.1s: arafed man in blue shirt working on a machine in a factory
t=5.1s: arafed man in blue shirt ...
2025-12-31 14:02:06,511 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #40 at t=5.3: 4 samples, timeline=t=5.2s: arafed man in a blue shirt and black hat working on a machine
t=5.2s: arafed man in blue shi...
2025-12-31 14:02:06,511 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #41 at t=5.433333333333334: 4 samples, timeline=t=5.3s: there is a man that is standing in a room with a baseball bat
t=5.4s: there is a man that is...
2025-12-31 14:02:06,511 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #42 at t=5.566666666666666: 4 samples, timeline=t=5.5s: arafed man standing in a factory with a lot of machines
t=5.5s: arafed man standing in a fac...
2025-12-31 14:02:06,511 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #43 at t=5.7: 4 samples, timeline=t=5.6s: arafed man standing in a factory with a lot of machines
t=5.6s: arafed man standing in a fac...
2025-12-31 14:02:06,511 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #44 at t=5.833333333333333: 4 samples, timeline=t=5.7s: arafed man standing in a factory with a lot of machines
t=5.8s: arafed man standing in a fac...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #45 at t=5.966666666666667: 4 samples, timeline=t=5.9s: arafed man standing in a factory with a machine in the background
t=5.9s: arafed man standin...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #46 at t=6.1: 4 samples, timeline=t=6.0s: arafed man standing in a factory with a camera in his hand
t=6.0s: arafed man standing in a ...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #47 at t=6.233333333333333: 4 samples, timeline=t=6.1s: arafed man standing in a factory with a machine in the background
t=6.2s: arafed man standin...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #48 at t=6.366666666666666: 4 samples, timeline=t=6.3s: there is a man that is standing in front of a table with a bunch of wine glasses
t=6.3s: the...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #49 at t=6.5: 4 samples, timeline=t=6.4s: there are many people standing around a table with a bunch of tools
t=6.4s: there is a man t...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #50 at t=6.633333333333334: 4 samples, timeline=t=6.5s: there are many bottles of wine on a table with a man
t=6.6s: there are many bottles of wine ...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #51 at t=6.766666666666667: 4 samples, timeline=t=6.7s: there is a man standing at a table with bottles of wine
t=6.7s: there are many bottles of wi...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #52 at t=6.9: 4 samples, timeline=t=6.8s: there are many bottles of wine on a table with a man
t=6.8s: there are many bottles of wine ...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #53 at t=7.033333333333333: 4 samples, timeline=t=6.9s: there is a man standing in front of a table with many bottles
t=7.0s: there is a man standin...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #54 at t=7.166666666666667: 4 samples, timeline=t=7.1s: there is a man standing at a counter with a bunch of bottles
t=7.1s: there is a man standing...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #55 at t=7.3: 4 samples, timeline=t=7.2s: there is a man standing at a counter with a bunch of bottles
t=7.2s: there is a man standing...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #56 at t=7.433333333333334: 4 samples, timeline=t=7.3s: there is a man standing at a table with a bunch of bottles
t=7.4s: there is a man standing a...
2025-12-31 14:02:06,512 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #57 at t=7.566666666666666: 4 samples, timeline=t=7.5s: there is a man standing at a counter with a bunch of bottles
t=7.5s: there is a man standing...
2025-12-31 14:02:06,513 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #58 at t=7.7: 4 samples, timeline=t=7.6s: there is a man standing at a table with a bunch of bottles
t=7.6s: there are many jars of fo...
2025-12-31 14:02:06,513 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #59 at t=7.833333333333333: 4 samples, timeline=t=7.7s: there are many bottles of wine on a table with a man
t=7.8s: there are many bottles of wine ...
2025-12-31 14:02:06,513 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #60 at t=7.966666666666667: 4 samples, timeline=t=7.9s: there is a man standing in front of a counter with a bunch of bottles
t=7.9s: there is a man...
2025-12-31 14:02:06,513 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #61 at t=8.1: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=8.0s: there is a man...
2025-12-31 14:02:06,513 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #62 at t=8.233333333333333: 4 samples, timeline=t=8.1s: there is a man standing in front of a table with a bunch of bottles
t=8.2s: there is a man s...
2025-12-31 14:02:06,513 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #63 at t=8.366666666666667: 4 samples, timeline=t=8.3s: there is a man standing in front of a counter with a bunch of bottles
t=8.3s: there is a man...
2025-12-31 14:02:06,513 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #64 at t=8.5: 4 samples, timeline=t=8.4s: there is a man standing at a table with a bunch of wine bottles
t=8.4s: there is a man stand...
2025-12-31 14:02:06,515 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #65 at t=8.633333333333333: 4 samples, timeline=t=8.5s: there is a man standing at a counter with bottles of wine
t=8.6s: there is a man standing in...
2025-12-31 14:02:06,515 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #66 at t=8.766666666666667: 4 samples, timeline=t=8.7s: there is a man standing at a counter with a bunch of bottles
t=8.7s: there is a man standing...
2025-12-31 14:02:06,515 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #67 at t=8.9: 4 samples, timeline=t=8.8s: there is a table with a bunch of bottles of wine on it
t=8.8s: there are many bottles of win...
2025-12-31 14:02:06,515 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #68 at t=9.033333333333333: 4 samples, timeline=t=8.9s: someone is working on a machine in a factory with many machines
t=9.0s: there is a man that ...
2025-12-31 14:02:06,515 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #69 at t=9.166666666666666: 4 samples, timeline=t=9.1s: someone is working on a machine in a factory with a lot of tools
t=9.1s: someone is working ...
2025-12-31 14:02:06,515 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #70 at t=9.3: 4 samples, timeline=t=9.2s: there is a man that is working on a machine in a factory
t=9.2s: there is a man that is work...
2025-12-31 14:02:06,515 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #71 at t=9.433333333333334: 4 samples, timeline=t=9.3s: arafed man working on a computer in a factory
t=9.4s: arafed man working on a computer in a ...
2025-12-31 14:02:06,515 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #72 at t=9.566666666666666: 4 samples, timeline=t=9.5s: someone is working on a machine in a factory with a blue shirt
t=9.5s: someone is working on...
2025-12-31 14:02:06,515 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #73 at t=9.7: 4 samples, timeline=t=9.6s: there is a man that is petting a cat in a kitchen
t=9.6s: there is a man that is petting a c...
2025-12-31 14:02:06,516 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #74 at t=9.833333333333334: 4 samples, timeline=t=9.7s: there is a man that is holding a tennis racquet in his hand
t=9.8s: there is a man that is h...
2025-12-31 14:02:06,516 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #75 at t=9.966666666666667: 4 samples, timeline=t=9.9s: someone is cutting a piece of food with a knife in a kitchen
t=9.9s: someone is holding a do...
2025-12-31 14:02:06,516 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #76 at t=10.1: 4 samples, timeline=t=10.0s: someone is holding a cat in a glove while it is sitting on a table
t=10.0s: someone is cutt...
2025-12-31 14:02:06,516 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #77 at t=10.233333333333333: 4 samples, timeline=t=10.1s: someone is holding a cat in their hand while it is being worked on
t=10.2s: someone is hold...
2025-12-31 14:02:06,516 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #78 at t=10.366666666666667: 4 samples, timeline=t=10.3s: someone is working on a machine in a factory with a lot of tools
t=10.3s: someone is workin...
2025-12-31 14:02:06,516 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #79 at t=10.5: 4 samples, timeline=t=10.4s: someone is working on a machine in a factory with a blue shirt
t=10.4s: someone is working ...
2025-12-31 14:02:06,516 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #80 at t=10.633333333333333: 4 samples, timeline=t=10.5s: there is a man that is working on a machine in a factory
t=10.6s: there is a man that is ho...
2025-12-31 14:02:06,516 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #81 at t=10.766666666666667: 4 samples, timeline=t=10.7s: there is a man holding a knife in his hand in a kitchen
t=10.7s: there is a man that is sta...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #82 at t=10.9: 4 samples, timeline=t=10.8s: someone is taking a picture of a man holding a cell phone
t=10.8s: someone is taking a pict...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #83 at t=11.033333333333333: 4 samples, timeline=t=10.9s: there is a man that is standing in front of a shelf with many electronics
t=11.0s: there is...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #84 at t=11.166666666666666: 4 samples, timeline=t=11.1s: there is a man that is working on a machine in a room
t=11.1s: there is a man that is worki...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #85 at t=11.3: 4 samples, timeline=t=11.2s: there is a man that is working on a machine in a factory
t=11.2s: there is a man that is st...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #86 at t=11.433333333333334: 4 samples, timeline=t=11.3s: arafed man in a factory with a camera and a camera
t=11.4s: arafed man in a factory with a ...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #87 at t=11.566666666666666: 4 samples, timeline=t=11.5s: arafed man standing in a factory with a camera in his hand
t=11.5s: arafed man standing in ...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #88 at t=11.7: 4 samples, timeline=t=11.6s: arafed man standing in a factory with a camera in his hand
t=11.6s: arafed man in a factory...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #89 at t=11.833333333333334: 4 samples, timeline=t=11.7s: arafed man standing in a factory with a camera in his hand
t=11.8s: arafed man standing in ...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #90 at t=11.966666666666667: 4 samples, timeline=t=11.9s: arafed man standing in a factory with a lot of machines
t=11.9s: arafed man standing in a f...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #91 at t=12.1: 4 samples, timeline=t=12.0s: arafed man standing in a factory with a tablet computer
t=12.0s: arafed man standing in a f...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #92 at t=12.233333333333333: 4 samples, timeline=t=12.1s: arafed man standing in a factory with a tablet computer
t=12.2s: arafed man standing in a f...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #93 at t=12.366666666666667: 4 samples, timeline=t=12.3s: arafed man standing in a factory with a camera in his hand
t=12.3s: arafed man standing in ...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #94 at t=12.5: 4 samples, timeline=t=12.4s: arafed man standing in a factory with a machine in the background
t=12.4s: arafed man stand...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #95 at t=12.633333333333333: 4 samples, timeline=t=12.5s: arafed man standing in a factory with a lot of machines
t=12.6s: arafed man standing in a f...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #96 at t=12.766666666666667: 4 samples, timeline=t=12.7s: arafed man standing in a factory with a lot of machines
t=12.7s: arafed man standing in a f...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #97 at t=12.9: 4 samples, timeline=t=12.8s: arafed man standing in a factory with a camera in his hand
t=12.8s: arafed man standing in ...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #98 at t=13.033333333333333: 4 samples, timeline=t=12.9s: arafed man in a factory with a wren and a wrenet
t=13.0s: arafed man standing in a factory ...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #99 at t=13.166666666666666: 4 samples, timeline=t=13.1s: arafed man working on a computer in a factory
t=13.1s: arafed man working on a machine in a...
2025-12-31 14:02:06,517 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #100 at t=13.3: 4 samples, timeline=t=13.2s: arafed worker working on a machine in a factory
t=13.2s: arafed worker working on a machine...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #101 at t=13.433333333333334: 4 samples, timeline=t=13.3s: arafed worker working on a machine in a factory
t=13.4s: arafed worker working on a machine...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #102 at t=13.566666666666666: 4 samples, timeline=t=13.5s: arafed worker working on a computer in a factory
t=13.5s: arafed worker working on a machin...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #103 at t=13.7: 4 samples, timeline=t=13.6s: arafed worker working on a machine in a factory
t=13.6s: arafed worker working on a machine...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #104 at t=13.833333333333334: 4 samples, timeline=t=13.7s: arafed worker working on a machine in a factory
t=13.8s: arafed worker working on a machine...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #105 at t=13.966666666666667: 4 samples, timeline=t=13.9s: araffe worker working on a machine in a factory
t=13.9s: arafed worker working on a machine...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #106 at t=14.1: 4 samples, timeline=t=14.0s: arafed worker working on a machine in a factory
t=14.0s: arafed worker working on a machine...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #107 at t=14.233333333333333: 4 samples, timeline=t=14.1s: arafed worker in a factory working on a machine
t=14.2s: arafed worker in a factory working...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #108 at t=14.366666666666667: 4 samples, timeline=t=14.3s: there is a man that is standing in front of a machine
t=14.3s: arafed worker in a factory w...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #109 at t=14.5: 4 samples, timeline=t=14.4s: there is a man that is standing in front of a machine
t=14.4s: there is a man that is stand...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #110 at t=14.633333333333333: 4 samples, timeline=t=14.5s: there is a man that is standing in front of a machine
t=14.6s: arafed man in blue shirt wor...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #111 at t=14.766666666666667: 4 samples, timeline=t=14.7s: there is a man that is standing in front of a machine
t=14.7s: there is a man that is stand...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #112 at t=14.9: 4 samples, timeline=t=14.8s: there is a man standing in a kitchen with a microwave
t=14.8s: there is a man standing in a...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #113 at t=15.033333333333333: 4 samples, timeline=t=14.9s: there is a man standing in a factory with a machine
t=15.0s: there is a man standing in a f...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #114 at t=15.166666666666666: 4 samples, timeline=t=15.1s: there is a man that is looking at a computer screen
t=15.1s: there is a man that is standin...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #115 at t=15.3: 4 samples, timeline=t=15.2s: there is a man that is holding a remote control in his hand
t=15.2s: there is a man that is...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #116 at t=15.433333333333334: 4 samples, timeline=t=15.3s: there is a man that is working on a machine in a factory
t=15.4s: there is a man that is wo...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #117 at t=15.566666666666666: 4 samples, timeline=t=15.5s: there is a man that is holding a gun in his hand
t=15.5s: there is a man that is holding a ...
2025-12-31 14:02:06,518 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #118 at t=15.7: 4 samples, timeline=t=15.6s: there are many people sitting at a table in a room
t=15.6s: there is a table with a white t...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #119 at t=15.833333333333334: 4 samples, timeline=t=15.7s: there is a man that is sitting at a table with a laptop
t=15.8s: there is a man that is sit...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #120 at t=15.966666666666667: 4 samples, timeline=t=15.9s: there is a blurry photo of a room with a bunch of items
t=15.9s: there is a man that is sta...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #121 at t=16.1: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=16.0s: there is a truck that is parked in a g...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #122 at t=16.233333333333334: 4 samples, timeline=t=16.1s: there is a man that is holding a snowboard in his hand
t=16.2s: there is a man that is sitt...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #123 at t=16.366666666666667: 4 samples, timeline=t=16.3s: someone is holding a remote control in front of a television
t=16.3s: someone is holding a ...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #124 at t=16.5: 4 samples, timeline=t=16.4s: there is a man standing at a counter with a glass of wine
t=16.4s: someone is standing at a...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #125 at t=16.633333333333333: 4 samples, timeline=t=16.5s: there is a man standing at a counter with a laptop
t=16.6s: someone is standing at a counte...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #126 at t=16.766666666666666: 4 samples, timeline=t=16.7s: there is a computer monitor sitting on a desk in a room
t=16.7s: there is a computer monito...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #127 at t=16.9: 4 samples, timeline=t=16.8s: there is a computer monitor sitting on a desk in a room
t=16.8s: there is a computer monito...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #128 at t=17.033333333333335: 4 samples, timeline=t=16.9s: there is a computer monitor sitting on a desk in a room
t=17.0s: there is a computer monito...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #129 at t=17.166666666666668: 4 samples, timeline=t=17.1s: there is a computer monitor sitting on a desk in a room
t=17.1s: there is a large monitor o...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #130 at t=17.3: 4 samples, timeline=t=17.2s: there is a large screen tv sitting on a table in a room
t=17.2s: there is a computer monito...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #131 at t=17.433333333333334: 4 samples, timeline=t=17.3s: there is a large screen that is on the wall in the room
t=17.4s: there is a computer monito...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #132 at t=17.566666666666666: 4 samples, timeline=t=17.5s: there is a computer monitor sitting on a desk in a room
t=17.5s: there is a computer monito...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #133 at t=17.7: 4 samples, timeline=t=17.6s: there is a large screen tv sitting on a desk in a room
t=17.6s: there is a large screen tv ...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #134 at t=17.833333333333332: 4 samples, timeline=t=17.7s: there is a computer monitor sitting on a desk in a room
t=17.8s: there is a computer monito...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #135 at t=17.966666666666665: 4 samples, timeline=t=17.9s: there is a computer monitor sitting on a desk in a room
t=17.9s: there is a computer monito...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #136 at t=18.1: 4 samples, timeline=t=18.0s: there is a computer monitor sitting on a desk in a room
t=18.0s: there is a computer monito...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #137 at t=18.233333333333334: 4 samples, timeline=t=18.1s: there is a computer monitor sitting on a desk in a room
t=18.2s: there is a computer monito...
2025-12-31 14:02:06,519 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #138 at t=18.366666666666667: 4 samples, timeline=t=18.3s: there is a computer monitor sitting on a desk in a room
t=18.3s: there is a computer monito...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #139 at t=18.5: 4 samples, timeline=t=18.4s: there is a computer monitor sitting on a desk in a room
t=18.4s: there is a computer monito...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #140 at t=18.633333333333333: 4 samples, timeline=t=18.5s: there is a computer monitor sitting on a desk in a room
t=18.6s: there is a computer monito...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #141 at t=18.766666666666666: 4 samples, timeline=t=18.7s: arafed worker in a factory working on a computer
t=18.7s: arafed worker in a factory workin...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #142 at t=18.9: 4 samples, timeline=t=18.8s: arafed worker in a factory working on a machine
t=18.8s: arafed worker in a factory working...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #143 at t=19.033333333333335: 4 samples, timeline=t=18.9s: arafed worker in a factory working on a machine
t=19.0s: arafed worker in a factory working...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #144 at t=19.166666666666668: 4 samples, timeline=t=19.1s: arafed worker in a factory working on a machine
t=19.1s: arafed worker in a factory working...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #145 at t=19.3: 4 samples, timeline=t=19.2s: arafed worker in a factory working on a machine
t=19.2s: arafed worker in a factory working...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #146 at t=19.433333333333334: 4 samples, timeline=t=19.3s: arafed worker in a factory working on a machine
t=19.4s: arafed worker in a factory working...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #147 at t=19.566666666666666: 4 samples, timeline=t=19.5s: arafed worker in a factory working on a machine
t=19.5s: arafed worker in a factory working...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #148 at t=19.7: 4 samples, timeline=t=19.6s: arafed worker in a factory working on a machine
t=19.6s: arafed worker in a factory working...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #149 at t=19.833333333333332: 4 samples, timeline=t=19.7s: arafed worker in a factory working on a machine
t=19.8s: arafed worker in a factory working...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #150 at t=19.966666666666665: 4 samples, timeline=t=19.9s: arafed worker in a factory working on a machine
t=19.9s: arafed worker in a factory working...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #151 at t=20.1: 4 samples, timeline=t=20.0s: arafed worker in a factory working on a machine
t=20.0s: arafed worker in a factory working...
2025-12-31 14:02:06,520 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #152 at t=20.233333333333334: 4 samples, timeline=t=20.1s: arafed worker in a factory working on a machine
t=20.2s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #153 at t=20.366666666666667: 4 samples, timeline=t=20.3s: arafed worker in a factory working on a machine
t=20.3s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #154 at t=20.5: 4 samples, timeline=t=20.4s: arafed worker in a factory working on a machine
t=20.4s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #155 at t=20.633333333333333: 4 samples, timeline=t=20.5s: arafed worker in a factory working on a machine
t=20.6s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #156 at t=20.766666666666666: 4 samples, timeline=t=20.7s: arafed worker in a factory working on a machine
t=20.7s: arafed worker in a factory operati...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #157 at t=20.9: 4 samples, timeline=t=20.8s: arafed worker in a factory operating machines in a factory
t=20.8s: arafed worker in a fact...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #158 at t=21.033333333333335: 4 samples, timeline=t=20.9s: arafed worker in a factory working on a machine
t=21.0s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #159 at t=21.166666666666668: 4 samples, timeline=t=21.1s: arafed worker in a factory working on a machine
t=21.1s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #160 at t=21.3: 4 samples, timeline=t=21.2s: arafed worker in a factory working on a machine
t=21.2s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #161 at t=21.433333333333334: 4 samples, timeline=t=21.3s: arafed worker in a factory working on a machine
t=21.4s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #162 at t=21.566666666666666: 4 samples, timeline=t=21.5s: arafed worker in a factory working on a machine
t=21.5s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #163 at t=21.7: 4 samples, timeline=t=21.6s: arafed worker in a factory working on a machine
t=21.6s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #164 at t=21.833333333333332: 4 samples, timeline=t=21.7s: arafed worker in a factory working on a machine
t=21.8s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #165 at t=21.966666666666665: 4 samples, timeline=t=21.9s: arafed worker in a factory working on a machine
t=21.9s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #166 at t=22.1: 4 samples, timeline=t=22.0s: arafed worker in a factory working on a machine
t=22.0s: arafed worker in a factory working...
2025-12-31 14:02:06,522 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #167 at t=22.233333333333334: 4 samples, timeline=t=22.1s: arafed worker in a factory working on a machine
t=22.2s: arafed worker in a factory working...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #168 at t=22.366666666666667: 4 samples, timeline=t=22.3s: arafed worker working on a machine in a factory
t=22.3s: arafed worker working on a machine...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #169 at t=22.5: 4 samples, timeline=t=22.4s: arafed worker in a factory working on a machine
t=22.4s: arafed worker in a factory working...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #170 at t=22.633333333333333: 4 samples, timeline=t=22.5s: arafed worker in a factory working on a machine
t=22.6s: arafed man in blue shirt working o...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #171 at t=22.766666666666666: 4 samples, timeline=t=22.7s: arafed man working in a factory with a lot of machines
t=22.7s: arafed man working in a fac...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #172 at t=22.9: 4 samples, timeline=t=22.8s: arafed worker in a factory working on a machine
t=22.8s: arafed man working in a factory wi...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #173 at t=23.033333333333335: 4 samples, timeline=t=22.9s: arafed worker in a factory working on a machine
t=23.0s: arafed worker in a factory with a ...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #174 at t=23.166666666666668: 4 samples, timeline=t=23.1s: arafed worker in a factory working on a machine
t=23.1s: arafed worker in a factory working...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #175 at t=23.3: 4 samples, timeline=t=23.2s: arafed man in blue shirt working in a factory with machines
t=23.2s: arafed man in blue shi...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #176 at t=23.433333333333334: 4 samples, timeline=t=23.3s: arafed worker in a factory working on a machine
t=23.4s: arafed man in blue shirt working o...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #177 at t=23.566666666666666: 4 samples, timeline=t=23.5s: arafed man in blue shirt standing in front of a machine
t=23.5s: arafed man in blue shirt s...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #178 at t=23.7: 4 samples, timeline=t=23.6s: arafed man in blue shirt standing in a factory with a lot of machines
t=23.6s: arafed man i...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #179 at t=23.833333333333332: 4 samples, timeline=t=23.7s: arafed man in blue shirt standing in a factory with a lot of appliances
t=23.8s: arafed man...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #180 at t=23.966666666666665: 4 samples, timeline=t=23.9s: arafed worker in a factory working on a machine
t=23.9s: there are two people standing in a...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #181 at t=24.1: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=24.0s: araffes in a factory with a cat and a ma...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #182 at t=24.233333333333334: 4 samples, timeline=t=24.1s: araffes in a factory with a dog and a man
t=24.2s: araffes in a factory with a dog and a ma...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #183 at t=24.366666666666667: 4 samples, timeline=t=24.3s: there are two people standing in a factory with a machine
t=24.3s: there is a black cat sit...
2025-12-31 14:02:06,523 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #184 at t=24.5: 4 samples, timeline=t=24.4s: there are two people standing in a factory with a cat
t=24.4s: there are two men working on...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #185 at t=24.633333333333333: 4 samples, timeline=t=24.5s: there are two men working on electronics in a factory
t=24.6s: people are working on electr...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #186 at t=24.766666666666666: 4 samples, timeline=t=24.7s: there are two men working on a machine in a factory
t=24.7s: there are two people working o...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #187 at t=24.9: 4 samples, timeline=t=24.8s: there are two men working on a machine in a factory
t=24.8s: araffes in a factory with a lo...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #188 at t=25.033333333333335: 4 samples, timeline=t=24.9s: there are two people in a factory that are working on electronics
t=25.0s: there are two pe...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #189 at t=25.166666666666668: 4 samples, timeline=t=25.1s: there are two people in a factory that are working on a machine
t=25.1s: there are two peop...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #190 at t=25.3: 4 samples, timeline=t=25.2s: there are two people in a room with a lot of tools
t=25.2s: there are two men in the back o...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #191 at t=25.433333333333334: 4 samples, timeline=t=25.3s: there are two men in the back of a boat working on electronics
t=25.4s: there are two men i...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #192 at t=25.566666666666666: 4 samples, timeline=t=25.5s: there are two men working on a machine in a factory
t=25.5s: there are two men working on a...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #193 at t=25.7: 4 samples, timeline=t=25.6s: there are two men standing in a room with a laptop
t=25.6s: there are two men standing in a...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #194 at t=25.833333333333332: 4 samples, timeline=t=25.7s: there are two men standing in a room with a laptop
t=25.8s: there are two men standing in a...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #195 at t=25.966666666666665: 4 samples, timeline=t=25.9s: there are two men standing in a room with a laptop
t=25.9s: there are two men standing in a...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #196 at t=26.1: 4 samples, timeline=t=26.0s: there are people standing in a bus with a dog on the floor
t=26.0s: there are people and a ...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #197 at t=26.233333333333334: 4 samples, timeline=t=26.1s: there are two men standing in a room with a table and a laptop
t=26.2s: there are two men w...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #198 at t=26.366666666666667: 4 samples, timeline=t=26.3s: there are two cows standing in a room with a man
t=26.3s: there are two cows standing in a ...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #199 at t=26.5: 4 samples, timeline=t=26.4s: there is a man that is standing in a room with a dog
t=26.4s: there is a man standing in a ...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #200 at t=26.633333333333333: 4 samples, timeline=t=26.5s: there is a man that is standing in a room with a frisbee
t=26.6s: there is a man standing i...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #201 at t=26.766666666666666: 4 samples, timeline=t=26.7s: there is a man standing in a room with a laptop
t=26.7s: there is a man standing in a room ...
2025-12-31 14:02:06,525 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #202 at t=26.9: 4 samples, timeline=t=26.8s: there are many people on a bus with their luggage
t=26.8s: there are many people on a bus w...
2025-12-31 14:02:06,527 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #203 at t=27.033333333333335: 4 samples, timeline=t=26.9s: there is a man that is standing in a factory with a computer
t=27.0s: there is a man that i...
2025-12-31 14:02:06,527 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #204 at t=27.166666666666668: 4 samples, timeline=t=27.1s: araffe worker in a factory working on a machine
t=27.1s: araffe worker in a factory working...
2025-12-31 14:02:06,527 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #205 at t=27.3: 4 samples, timeline=t=27.2s: arafed man working in a factory with a lot of machines
t=27.2s: arafed worker operating mac...
2025-12-31 14:02:06,527 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #206 at t=27.433333333333334: 4 samples, timeline=t=27.3s: araffe worker working on a machine in a factory
t=27.4s: arafed worker in a factory operati...
2025-12-31 14:02:06,527 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #207 at t=27.566666666666666: 4 samples, timeline=t=27.5s: arafed worker in a factory working on a machine
t=27.5s: arafed man in a factory working on...
2025-12-31 14:02:06,528 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #208 at t=27.7: 4 samples, timeline=t=27.6s: arafed man in a blue shirt and blue pants working in a factory
t=27.6s: arafed man in a fac...
2025-12-31 14:02:06,528 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #209 at t=27.833333333333332: 4 samples, timeline=t=27.7s: arafed man in a factory with a machine and a lot of tools
t=27.8s: there is a man standing ...
2025-12-31 14:02:06,528 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #210 at t=27.966666666666665: 4 samples, timeline=t=27.9s: there is a man that is standing in a factory with a machine
t=27.9s: there is a man that is...
2025-12-31 14:02:06,528 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #211 at t=28.1: 4 samples, timeline=t=28.0s: arafed man in a factory working on a machine
t=28.0s: arafed man in a factory working on a ...
2025-12-31 14:02:06,529 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #212 at t=28.233333333333334: 4 samples, timeline=t=28.1s: arafed man in a factory holding a baseball bat in his hand
t=28.2s: arafed man in a factory...
2025-12-31 14:02:06,529 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #213 at t=28.366666666666667: 4 samples, timeline=t=28.3s: arafed man in a factory holding a baseball bat in his hand
t=28.3s: arafed man in a factory...
2025-12-31 14:02:06,529 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #214 at t=28.5: 4 samples, timeline=t=28.4s: arafed man in a factory holding a baseball bat in his hand
t=28.4s: arafed man in a factory...
2025-12-31 14:02:06,529 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #215 at t=28.633333333333333: 4 samples, timeline=t=28.5s: arafed man in a factory holding a baseball bat in his hand
t=28.6s: arafed man in a factory...
2025-12-31 14:02:06,530 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #216 at t=28.766666666666666: 4 samples, timeline=t=28.7s: arafed man in a factory holding a baseball bat in his hand
t=28.7s: arafed man in a factory...
2025-12-31 14:02:06,530 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #217 at t=28.9: 4 samples, timeline=t=28.8s: arafed man in a factory with a baseball bat in his hand
t=28.8s: arafed man in a factory wi...
2025-12-31 14:02:06,530 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #218 at t=29.033333333333335: 4 samples, timeline=t=28.9s: arafed man in a factory with a camera and a camera strap
t=29.0s: arafed man in a factory w...
2025-12-31 14:02:06,530 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #219 at t=29.166666666666668: 4 samples, timeline=t=29.1s: arafed man in a factory with a camera and a video camera
t=29.1s: arafed image of a woman i...
2025-12-31 14:02:06,531 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #220 at t=29.3: 4 samples, timeline=t=29.2s: arafed man standing in a factory with a lot of machines
t=29.2s: arafed man standing in a f...
2025-12-31 14:02:06,531 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #221 at t=29.433333333333334: 4 samples, timeline=t=29.3s: arafed man standing in a factory with a lot of machines
t=29.4s: arafed man in a factory wi...
2025-12-31 14:02:06,531 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #222 at t=29.566666666666666: 4 samples, timeline=t=29.5s: arafed man in a factory with a machine in the background
t=29.5s: arafed man in a factory w...
2025-12-31 14:02:06,531 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #223 at t=29.7: 4 samples, timeline=t=29.6s: arafed man in a factory with a machine in the background
t=29.6s: arafed man in a factory w...
2025-12-31 14:02:06,531 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #224 at t=29.833333333333332: 4 samples, timeline=t=29.7s: arafed man standing in a factory with a machine in the background
t=29.8s: arafed man stand...
2025-12-31 14:02:06,532 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #225 at t=29.966666666666665: 4 samples, timeline=t=29.9s: arafed man standing in a factory with a machine in the background
t=29.9s: arafed man stand...
2025-12-31 14:02:06,532 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #226 at t=30.1: 4 samples, timeline=t=30.0s: arafed man standing in a factory with a machine behind him
t=30.0s: arafed man standing in ...
2025-12-31 14:02:06,532 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #227 at t=30.233333333333334: 4 samples, timeline=t=30.1s: arafed man standing in a factory with a machine in the background
t=30.2s: arafed man stand...
2025-12-31 14:02:06,532 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #228 at t=30.366666666666667: 4 samples, timeline=t=30.3s: arafed man standing in a factory with a machine in the background
t=30.3s: arafed man stand...
2025-12-31 14:02:06,532 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #229 at t=30.5: 4 samples, timeline=t=30.4s: arafed man standing in a factory with a machine in the background
t=30.4s: arafed man stand...
2025-12-31 14:02:06,533 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #230 at t=30.633333333333333: 4 samples, timeline=t=30.5s: arafed man standing in a factory with a machine in the background
t=30.6s: arafed man stand...
2025-12-31 14:02:06,533 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #231 at t=30.766666666666666: 4 samples, timeline=t=30.7s: arafed man standing in a factory with a lot of machines
t=30.7s: arafed man standing in a f...
2025-12-31 14:02:06,533 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #232 at t=30.9: 4 samples, timeline=t=30.8s: arafed man in a factory with a blue shirt and a blue apron
t=30.8s: arafed man in a factory...
2025-12-31 14:02:06,533 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #233 at t=31.033333333333335: 4 samples, timeline=t=30.9s: arafed worker in a factory with a laptop computer
t=31.0s: arafed worker in a factory with ...
2025-12-31 14:02:06,534 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #234 at t=31.166666666666668: 4 samples, timeline=t=31.1s: there is a man that is standing in a room with a laptop
t=31.1s: arafed man in a blue shirt...
2025-12-31 14:02:06,534 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #235 at t=31.3: 4 samples, timeline=t=31.2s: arafed worker in a factory with a box of electronics
t=31.2s: arafed worker in a factory wi...
2025-12-31 14:02:06,534 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #236 at t=31.433333333333334: 4 samples, timeline=t=31.3s: arafed man in a factory with a box of something
t=31.4s: arafed man in a factory with a box...
2025-12-31 14:02:06,534 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #237 at t=31.566666666666666: 4 samples, timeline=t=31.5s: arafed man in a blue shirt is working on a machine
t=31.5s: arafed man in a blue shirt is h...
2025-12-31 14:02:06,535 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #238 at t=31.7: 4 samples, timeline=t=31.6s: arafed man in a factory with a box of food
t=31.6s: arafed man in a factory with a box of f...
2025-12-31 14:02:06,535 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #239 at t=31.833333333333332: 4 samples, timeline=t=31.7s: arafed man in a factory with a box of electronics
t=31.8s: arafed man in a factory with a l...
2025-12-31 14:02:06,535 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #240 at t=31.966666666666665: 4 samples, timeline=t=31.9s: arafed man in a factory with a box of something
t=31.9s: arafed man in a factory with a box...
2025-12-31 14:02:06,535 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #241 at t=32.1: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=32.0s: arafed man in a factory with a lap...
2025-12-31 14:02:06,535 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #242 at t=32.233333333333334: 4 samples, timeline=t=32.1s: arafed man in a factory with a laptop and a box
t=32.2s: arafed man in a factory with a lap...
2025-12-31 14:02:06,535 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #243 at t=32.36666666666667: 4 samples, timeline=t=32.3s: arafed man in a factory with a laptop and a cell phone
t=32.3s: arafed man in a factory wit...
2025-12-31 14:02:06,535 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #244 at t=32.5: 4 samples, timeline=t=32.4s: arafed man in a factory talking on a cell phone
t=32.4s: arafed man in a factory with a lap...
2025-12-31 14:02:06,535 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #245 at t=32.63333333333333: 4 samples, timeline=t=32.5s: arafed man in a factory with a laptop and a monitor
t=32.6s: arafed man in a factory with a...
2025-12-31 14:02:06,536 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #246 at t=32.766666666666666: 4 samples, timeline=t=32.7s: arafed man in a blue shirt working on a machine
t=32.7s: arafed man in a blue shirt and blu...
2025-12-31 14:02:06,536 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #247 at t=32.9: 4 samples, timeline=t=32.8s: arafed man in a blue shirt and blue apron in a kitchen
t=32.8s: arafed man in a blue shirt ...
2025-12-31 14:02:06,536 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #248 at t=33.03333333333333: 4 samples, timeline=t=32.9s: there is a man in a blue shirt and a blue apron
t=33.0s: arafed man in a blue shirt and glo...
2025-12-31 14:02:06,536 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #249 at t=33.166666666666664: 4 samples, timeline=t=33.1s: arafed man in a blue shirt and gloves using a drill
t=33.1s: arafed man in a blue shirt and...
2025-12-31 14:02:06,536 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #250 at t=33.3: 4 samples, timeline=t=33.2s: arafed man in blue shirt and black gloves working on a machine
t=33.2s: arafed man in blue ...
2025-12-31 14:02:06,536 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #251 at t=33.43333333333333: 4 samples, timeline=t=33.3s: there is a man in a blue shirt and a mask holding a bag
t=33.4s: arafed worker in a factory...
2025-12-31 14:02:06,536 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #252 at t=33.56666666666667: 4 samples, timeline=t=33.5s: someone in a blue shirt is using a machine to clean a bag
t=33.5s: arafed man in a blue shi...
2025-12-31 14:02:06,536 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #253 at t=33.7: 4 samples, timeline=t=33.6s: arafed man in a blue shirt and mask holding a bag of food
t=33.6s: arafed man in a blue shi...
2025-12-31 14:02:06,537 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #254 at t=33.833333333333336: 4 samples, timeline=t=33.7s: arafed man in a blue shirt holding a bag of food
t=33.8s: arafed man in a blue shirt holdin...
2025-12-31 14:02:06,537 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #255 at t=33.96666666666667: 4 samples, timeline=t=33.9s: arafed man in a factory holding a large white object
t=33.9s: arafed man in a factory holdi...
2025-12-31 14:02:06,537 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #256 at t=34.1: 4 samples, timeline=t=34.0s: arafed man in a factory holding a large piece of metal
t=34.0s: arafed man in a factory hol...
2025-12-31 14:02:06,537 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #257 at t=34.233333333333334: 4 samples, timeline=t=34.1s: arafed man in blue shirt holding a large piece of plastic
t=34.2s: there is a man holding a...
2025-12-31 14:02:06,538 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #258 at t=34.36666666666667: 4 samples, timeline=t=34.3s: arafed man holding a large piece of plastic in a room
t=34.3s: arafed man in blue shirt hol...
2025-12-31 14:02:06,538 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #259 at t=34.5: 4 samples, timeline=t=34.4s: someone is holding a plastic bag in a room with a machine
t=34.4s: someone is holding a pla...
2025-12-31 14:02:06,538 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #260 at t=34.63333333333333: 4 samples, timeline=t=34.5s: there is a man in a blue shirt holding a large object
t=34.6s: someone is holding a large p...
2025-12-31 14:02:06,538 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #261 at t=34.766666666666666: 4 samples, timeline=t=34.7s: someone is working on a laptop in a factory with a lot of tools
t=34.7s: someone is working...
2025-12-31 14:02:06,538 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #262 at t=34.9: 4 samples, timeline=t=34.8s: arafed man in a factory working on a laptop computer
t=34.8s: there is a man that is standi...
2025-12-31 14:02:06,539 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #263 at t=35.03333333333333: 4 samples, timeline=t=34.9s: arafed man working on a machine in a factory with a lot of machines
t=35.0s: arafed man wor...
2025-12-31 14:02:06,539 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #264 at t=35.166666666666664: 4 samples, timeline=t=35.1s: arafed man working on a machine in a factory with a lot of machines
t=35.1s: arafed man wor...
2025-12-31 14:02:06,539 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #265 at t=35.3: 4 samples, timeline=t=35.2s: arafed man in blue shirt working on machine in factory
t=35.2s: arafed man in blue shirt wo...
2025-12-31 14:02:06,539 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #266 at t=35.43333333333333: 4 samples, timeline=t=35.3s: arafed man in a blue shirt and mask working on a machine
t=35.4s: arafed worker in a factor...
2025-12-31 14:02:06,539 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #267 at t=35.56666666666667: 4 samples, timeline=t=35.5s: arafed man in a factory with a mask on and a face mask on
t=35.5s: arafed worker in a facto...
2025-12-31 14:02:06,539 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #268 at t=35.7: 4 samples, timeline=t=35.6s: arafed man in a factory working on a machine
t=35.6s: arafed man in a factory with a bag of...
2025-12-31 14:02:06,540 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #269 at t=35.833333333333336: 4 samples, timeline=t=35.7s: arafed man in a factory looking at a bag of food
t=35.8s: arafed man in a factory with a ba...
2025-12-31 14:02:06,540 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #270 at t=35.96666666666667: 4 samples, timeline=t=35.9s: arafed man in a factory working on a machine
t=35.9s: there is a man that is cutting a mans...
2025-12-31 14:02:06,540 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #271 at t=36.1: 4 samples, timeline=t=36.0s: there is a man that is standing in a factory with a machine
t=36.0s: there is a man that is...
2025-12-31 14:02:06,540 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #272 at t=36.233333333333334: 4 samples, timeline=t=36.1s: arafed man in a factory with a blue shirt and a blue shirt
t=36.2s: arafed man in a factory...
2025-12-31 14:02:06,540 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #273 at t=36.36666666666667: 4 samples, timeline=t=36.3s: there are many people in a factory that are working on something
t=36.3s: arafed man in a f...
2025-12-31 14:02:06,540 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #274 at t=36.5: 4 samples, timeline=t=36.4s: there is a man that is standing in a factory with a machine
t=36.4s: there is a man that is...
2025-12-31 14:02:06,541 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #275 at t=36.63333333333333: 4 samples, timeline=t=36.5s: there is a man that is standing in a factory talking on the phone
t=36.6s: arafed man stand...
2025-12-31 14:02:06,541 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #276 at t=36.766666666666666: 4 samples, timeline=t=36.7s: arafed man standing in a factory with a lot of machines
t=36.7s: arafed man standing in a f...
2025-12-31 14:02:06,541 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #277 at t=36.9: 4 samples, timeline=t=36.8s: arafed man standing in a factory with a lot of machines
t=36.8s: arafed man standing in a f...
2025-12-31 14:02:06,542 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #278 at t=37.03333333333333: 4 samples, timeline=t=36.9s: arafed man standing in a factory with a lot of machines
t=37.0s: arafed man standing in a f...
2025-12-31 14:02:06,542 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #279 at t=37.166666666666664: 4 samples, timeline=t=37.1s: arafed man standing in a factory with a lot of machines
t=37.1s: arafed man standing in a f...
2025-12-31 14:02:06,542 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #280 at t=37.3: 4 samples, timeline=t=37.2s: arafed man standing in a factory with a lot of machines
t=37.2s: arafed man standing in a f...
2025-12-31 14:02:06,542 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #281 at t=37.43333333333333: 4 samples, timeline=t=37.3s: arafed man standing in a factory with a lot of machines
t=37.4s: arafed man standing in a f...
2025-12-31 14:02:06,542 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #282 at t=37.56666666666667: 4 samples, timeline=t=37.5s: arafed man standing in a factory with a lot of machines
t=37.5s: arafed man standing in a f...
2025-12-31 14:02:06,542 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #283 at t=37.7: 4 samples, timeline=t=37.6s: arafed man standing in a factory with a lot of machines
t=37.6s: arafed man standing in a f...
2025-12-31 14:02:06,542 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #284 at t=37.833333333333336: 4 samples, timeline=t=37.7s: arafed man standing in a factory with a lot of machines
t=37.8s: arafed man standing in a f...
2025-12-31 14:02:06,542 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #285 at t=37.96666666666667: 4 samples, timeline=t=37.9s: arafed man standing in a factory with a lot of machines
t=37.9s: arafed man standing in a f...
2025-12-31 14:02:06,543 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #286 at t=38.1: 4 samples, timeline=t=38.0s: arafed man standing in a factory with a lot of machines
t=38.0s: arafed man standing in a f...
2025-12-31 14:02:06,543 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #287 at t=38.233333333333334: 4 samples, timeline=t=38.1s: arafed man standing in a factory with a lot of machines
t=38.2s: arafed man standing in a f...
2025-12-31 14:02:06,543 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #288 at t=38.36666666666667: 4 samples, timeline=t=38.3s: arafed man standing in a factory with a lot of machines
t=38.3s: arafed man standing in a f...
2025-12-31 14:02:06,543 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #289 at t=38.5: 4 samples, timeline=t=38.4s: arafed man standing in a factory with a lot of machines
t=38.4s: arafed man standing in a f...
2025-12-31 14:02:06,543 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #290 at t=38.63333333333333: 4 samples, timeline=t=38.5s: arafed man standing in a factory with a lot of machines
t=38.6s: arafed man standing in a f...
2025-12-31 14:02:06,543 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #291 at t=38.766666666666666: 4 samples, timeline=t=38.7s: arafed man standing in a factory with a lot of machines
t=38.7s: arafed man standing in a f...
2025-12-31 14:02:06,543 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #292 at t=38.9: 4 samples, timeline=t=38.8s: arafed man standing in a factory with a lot of machines
t=38.8s: arafed man standing in a f...
2025-12-31 14:02:06,543 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #293 at t=39.03333333333333: 4 samples, timeline=t=38.9s: arafed man standing in a factory with a lot of machines
t=39.0s: arafed man standing in a f...
2025-12-31 14:02:06,543 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #294 at t=39.166666666666664: 4 samples, timeline=t=39.1s: arafed man standing in a factory with a lot of machines
t=39.1s: arafed man standing in a f...
2025-12-31 14:02:06,544 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #295 at t=39.3: 4 samples, timeline=t=39.2s: arafed man standing in a factory with a lot of machines
t=39.2s: arafed man standing in a f...
2025-12-31 14:02:06,544 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #296 at t=39.43333333333333: 4 samples, timeline=t=39.3s: arafed man standing in a factory with a lot of machines
t=39.4s: arafed man standing in a f...
2025-12-31 14:02:06,544 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #297 at t=39.56666666666667: 4 samples, timeline=t=39.5s: arafed man standing in a factory with a lot of machines
t=39.5s: arafed man standing in a f...
2025-12-31 14:02:06,544 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #298 at t=39.7: 4 samples, timeline=t=39.6s: arafed man standing in a factory with a lot of machines
t=39.6s: arafed man standing in a f...
2025-12-31 14:02:06,544 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #299 at t=39.833333333333336: 4 samples, timeline=t=39.7s: arafed man standing in a factory with a lot of machines
t=39.8s: arafed man standing in a f...
2025-12-31 14:02:06,544 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #300 at t=39.96666666666667: 4 samples, timeline=t=39.9s: arafed man standing in a factory with a lot of machines
t=39.9s: arafed man standing in a f...
2025-12-31 14:02:06,544 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #301 at t=40.1: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=40.0s: arafed man standing in a f...
2025-12-31 14:02:06,544 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #302 at t=40.233333333333334: 4 samples, timeline=t=40.1s: arafed man in a blue shirt and black gloves in a factory
t=40.2s: arafed man in a blue shir...
2025-12-31 14:02:06,544 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #303 at t=40.36666666666667: 4 samples, timeline=t=40.3s: arafed man in a blue shirt and mask holding a helmet
t=40.3s: arafed man in a blue shirt an...
2025-12-31 14:02:06,544 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #304 at t=40.5: 4 samples, timeline=t=40.4s: arafed man in a blue shirt and mask is using a machine
t=40.4s: arafed man in a blue shirt ...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #305 at t=40.63333333333333: 4 samples, timeline=t=40.5s: arafed man in a blue shirt and mask holding a gun
t=40.6s: arafed man in a blue shirt and m...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #306 at t=40.766666666666666: 4 samples, timeline=t=40.7s: arafed man in a blue shirt and black gloves is working on a machine
t=40.7s: arafed man in ...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #307 at t=40.9: 4 samples, timeline=t=40.8s: arafed man in a blue shirt and mask working on a machine
t=40.8s: arafed man in a blue shir...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #308 at t=41.03333333333333: 4 samples, timeline=t=40.9s: arafed man in a blue shirt and mask is working on a machine
t=41.0s: arafed man in a blue s...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #309 at t=41.166666666666664: 4 samples, timeline=t=41.1s: arafed man in a blue shirt and mask in a factory
t=41.1s: arafed man in a blue shirt and ma...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #310 at t=41.3: 4 samples, timeline=t=41.2s: arafed man in a blue shirt and mask standing in a factory
t=41.2s: arafed man in a blue shi...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #311 at t=41.43333333333333: 4 samples, timeline=t=41.3s: arafed man in a blue shirt and mask working on a machine
t=41.4s: arafed man in a blue shir...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #312 at t=41.56666666666667: 4 samples, timeline=t=41.5s: arafed man in a blue shirt and mask working on a machine
t=41.5s: arafed man in a blue shir...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #313 at t=41.7: 4 samples, timeline=t=41.6s: arafed worker in a factory wearing a mask and gloves
t=41.6s: arafed man in a blue shirt an...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #314 at t=41.833333333333336: 4 samples, timeline=t=41.7s: arafed man in a blue shirt and mask working on a machine
t=41.8s: arafed man in a blue shir...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #315 at t=41.96666666666667: 4 samples, timeline=t=41.9s: arafed worker in a factory with a mask on and gloves on
t=41.9s: arafed worker in a factory...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #316 at t=42.1: 4 samples, timeline=t=42.0s: arafed man in a blue shirt and mask working on a machine
t=42.0s: arafed man in a blue shir...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #317 at t=42.233333333333334: 4 samples, timeline=t=42.1s: arafed worker in a factory checking a machine for a new product
t=42.2s: arafed worker in a...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #318 at t=42.36666666666667: 4 samples, timeline=t=42.3s: arafed man in a factory with a box of electronics
t=42.3s: arafed man in a factory with a b...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #319 at t=42.5: 4 samples, timeline=t=42.4s: arafed man in a factory working on a machine
t=42.4s: arafed man in a factory working on a ...
2025-12-31 14:02:06,545 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #320 at t=42.63333333333333: 4 samples, timeline=t=42.5s: arafed worker in a factory working on a machine
t=42.6s: arafed worker in a factory working...
2025-12-31 14:02:06,547 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #321 at t=42.766666666666666: 4 samples, timeline=t=42.7s: arafed man in a factory working on a machine
t=42.7s: arafed man in a factory working on a ...
2025-12-31 14:02:06,547 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #322 at t=42.9: 4 samples, timeline=t=42.8s: arafed man in a factory working on a machine
t=42.8s: arafed man in a factory working on a ...
2025-12-31 14:02:06,547 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #323 at t=43.03333333333333: 4 samples, timeline=t=42.9s: arafed man in a factory with a machine in the background
t=43.0s: arafed man in a factory w...
2025-12-31 14:02:06,547 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #324 at t=43.166666666666664: 4 samples, timeline=t=43.1s: arafed man in a factory with a lot of boxes and machines
t=43.1s: arafed man in a factory w...
2025-12-31 14:02:06,547 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #325 at t=43.3: 4 samples, timeline=t=43.2s: arafed man in a factory with a large amount of equipment
t=43.2s: arafed man in a factory w...
2025-12-31 14:02:06,547 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #326 at t=43.43333333333333: 4 samples, timeline=t=43.3s: arafed man in a factory with a lot of machines
t=43.4s: arafed man in a factory working on ...
2025-12-31 14:02:06,547 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #327 at t=43.56666666666667: 4 samples, timeline=t=43.5s: arafed man in a factory with a machine and boxes
t=43.5s: arafed man in a factory working o...
2025-12-31 14:02:06,547 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #328 at t=43.7: 4 samples, timeline=t=43.6s: arafed man in a factory with a large amount of machinery
t=43.6s: arafed man in a factory w...
2025-12-31 14:02:06,547 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #329 at t=43.833333333333336: 4 samples, timeline=t=43.7s: arafed man in a factory with a machine in the background
t=43.8s: arafed man in a factory l...
2025-12-31 14:02:06,547 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #330 at t=43.96666666666667: 4 samples, timeline=t=43.9s: arafed man in a factory with a machine in the background
t=43.9s: arafed man in a factory w...
2025-12-31 14:02:06,548 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #331 at t=44.1: 4 samples, timeline=t=44.0s: arafed man in a factory looking at machinery in a factory
t=44.0s: arafed man in a factory ...
2025-12-31 14:02:06,548 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #332 at t=44.233333333333334: 4 samples, timeline=t=44.1s: arafed man in a factory looking at a computer screen
t=44.2s: arafed man in a factory looki...
2025-12-31 14:02:06,548 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #333 at t=44.36666666666667: 4 samples, timeline=t=44.3s: arafed man in a factory looking at a monitor screen
t=44.3s: arafed man in a factory lookin...
2025-12-31 14:02:06,548 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #334 at t=44.5: 4 samples, timeline=t=44.4s: arafed man in blue shirt standing in a factory with machines
t=44.4s: arafed man in a facto...
2025-12-31 14:02:06,548 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #335 at t=44.63333333333333: 4 samples, timeline=t=44.5s: arafed man in blue shirt standing in a factory with a machine
t=44.6s: arafed man in a fact...
2025-12-31 14:02:06,548 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #336 at t=44.766666666666666: 4 samples, timeline=t=44.7s: arafed man in a factory looking at a machine
t=44.7s: arafed man in a factory looking at a ...
2025-12-31 14:02:06,548 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #337 at t=44.9: 4 samples, timeline=t=44.8s: arafed man in a blue shirt standing in a factory
t=44.8s: arafed man in a blue shirt standi...
2025-12-31 14:02:06,548 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #338 at t=45.03333333333333: 4 samples, timeline=t=44.9s: arafed man in a factory looking at a machine
t=45.0s: arafed man in a factory looking at a ...
2025-12-31 14:02:06,548 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #339 at t=45.166666666666664: 4 samples, timeline=t=45.1s: arafed man in a factory looking at a machine
t=45.1s: arafed man in a factory looking at a ...
2025-12-31 14:02:06,549 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #340 at t=45.3: 4 samples, timeline=t=45.2s: arafed man in a blue shirt standing in a factory
t=45.2s: arafed man in blue shirt standing...
2025-12-31 14:02:06,549 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #341 at t=45.43333333333333: 4 samples, timeline=t=45.3s: arafed man in blue shirt standing in a factory with a machine
t=45.4s: arafed man in blue s...
2025-12-31 14:02:06,549 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #342 at t=45.56666666666667: 4 samples, timeline=t=45.5s: arafed man in blue shirt standing in a factory with a machine
t=45.5s: arafed man in blue s...
2025-12-31 14:02:06,549 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #343 at t=45.7: 4 samples, timeline=t=45.6s: arafed man in blue shirt standing in a factory with a machine
t=45.6s: arafed man in blue s...
2025-12-31 14:02:06,549 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #344 at t=45.833333333333336: 4 samples, timeline=t=45.7s: arafed man in blue shirt standing in a factory with a machine
t=45.8s: arafed man working i...
2025-12-31 14:02:06,549 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #345 at t=45.96666666666667: 4 samples, timeline=t=45.9s: arafed man standing in a factory with a lot of machines
t=45.9s: arafed man standing in a f...
2025-12-31 14:02:06,549 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #346 at t=46.1: 4 samples, timeline=t=46.0s: arafed man standing in a factory with a lot of machines
t=46.0s: arafed man standing in a f...
2025-12-31 14:02:06,549 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #347 at t=46.233333333333334: 4 samples, timeline=t=46.1s: arafed man standing in a factory with a lot of machines
t=46.2s: arafed man standing in a f...
2025-12-31 14:02:06,549 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #348 at t=46.36666666666667: 4 samples, timeline=t=46.3s: arafed man standing in a factory with a lot of machines
t=46.3s: arafed man standing in a f...
2025-12-31 14:02:06,549 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #349 at t=46.5: 4 samples, timeline=t=46.4s: arafed man standing in a factory with a lot of machines
t=46.4s: arafed man standing in a f...
2025-12-31 14:02:06,550 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #350 at t=46.63333333333333: 4 samples, timeline=t=46.5s: arafed man standing in a factory with a lot of machines
t=46.6s: arafed man standing in a f...
2025-12-31 14:02:06,550 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #351 at t=46.766666666666666: 4 samples, timeline=t=46.7s: arafed man standing in a factory with a lot of machines
t=46.7s: arafed man standing in a f...
2025-12-31 14:02:06,550 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #352 at t=46.9: 4 samples, timeline=t=46.8s: arafed man standing in a factory with a lot of machines
t=46.8s: arafed man standing in a f...
2025-12-31 14:02:06,550 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #353 at t=47.03333333333333: 4 samples, timeline=t=46.9s: arafed man standing in a factory with a lot of machines
t=47.0s: arafed man standing in a f...
2025-12-31 14:02:06,550 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #354 at t=47.166666666666664: 4 samples, timeline=t=47.1s: arafed man standing in a factory with a lot of machines
t=47.1s: arafed man standing in a f...
2025-12-31 14:02:06,550 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #355 at t=47.3: 4 samples, timeline=t=47.2s: arafed man standing in a factory with a lot of machines
t=47.2s: arafed man standing in a f...
2025-12-31 14:02:06,550 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #356 at t=47.43333333333333: 4 samples, timeline=t=47.3s: arafed man standing in a factory with a lot of machines
t=47.4s: arafed man standing in a f...
2025-12-31 14:02:06,550 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #357 at t=47.56666666666667: 4 samples, timeline=t=47.5s: arafed man in blue shirt standing in factory with luggage
t=47.5s: arafed man in blue shirt...
2025-12-31 14:02:06,550 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #358 at t=47.7: 4 samples, timeline=t=47.6s: arafed man in a factory with a carton of boxes
t=47.6s: arafed man in blue shirt standing i...
2025-12-31 14:02:06,551 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #359 at t=47.833333333333336: 4 samples, timeline=t=47.7s: arafed man in blue shirt standing in a factory with a cart
t=47.8s: arafed man in blue shir...
2025-12-31 14:02:06,551 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #360 at t=47.96666666666667: 4 samples, timeline=t=47.9s: arafed man in a factory with a large machine in the background
t=47.9s: arafed man in a fac...
2025-12-31 14:02:06,551 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #361 at t=48.1: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=48.0s: arafed man in blue shirt s...
2025-12-31 14:02:06,551 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #362 at t=48.233333333333334: 4 samples, timeline=t=48.1s: arafed worker in a factory with a large machine in the background
t=48.2s: arafed worker in...
2025-12-31 14:02:06,551 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #363 at t=48.36666666666667: 4 samples, timeline=t=48.3s: arafed worker in a factory with a large machine
t=48.3s: arafed worker in a factory with a ...
2025-12-31 14:02:06,551 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #364 at t=48.5: 4 samples, timeline=t=48.4s: arafed worker in a factory with a mask on
t=48.4s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,551 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #365 at t=48.63333333333333: 4 samples, timeline=t=48.5s: arafed man in a blue shirt and mask standing in a factory
t=48.6s: arafed man in a blue shi...
2025-12-31 14:02:06,551 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #366 at t=48.766666666666666: 4 samples, timeline=t=48.7s: arafed man in a blue shirt and mask holding a suitcase
t=48.7s: arafed man in a blue shirt ...
2025-12-31 14:02:06,551 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #367 at t=48.9: 4 samples, timeline=t=48.8s: arafed man in a blue shirt and glasses standing in a factory
t=48.8s: arafed man in a facto...
2025-12-31 14:02:06,552 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #368 at t=49.03333333333333: 4 samples, timeline=t=48.9s: arafed man in a blue shirt and mask standing in a factory
t=49.0s: arafed man in a blue shi...
2025-12-31 14:02:06,552 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #369 at t=49.166666666666664: 4 samples, timeline=t=49.1s: arafed man in a blue shirt and mask standing in a factory
t=49.1s: arafed man in a blue shi...
2025-12-31 14:02:06,552 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #370 at t=49.3: 4 samples, timeline=t=49.2s: arafed man in a blue shirt and mask standing in a factory
t=49.2s: arafed man in a blue shi...
2025-12-31 14:02:06,552 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #371 at t=49.43333333333333: 4 samples, timeline=t=49.3s: arafed man in a blue shirt and mask standing in a factory
t=49.4s: arafed man in a blue shi...
2025-12-31 14:02:06,552 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #372 at t=49.56666666666667: 4 samples, timeline=t=49.5s: arafed man in a blue shirt and mask standing in a factory
t=49.5s: arafed man in a factory ...
2025-12-31 14:02:06,552 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #373 at t=49.7: 4 samples, timeline=t=49.6s: arafed man in a factory wearing a face mask and a blue shirt
t=49.6s: arafed man in a blue ...
2025-12-31 14:02:06,553 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #374 at t=49.833333333333336: 4 samples, timeline=t=49.7s: arafed worker in a factory wearing a mask and blue shirt
t=49.8s: arafed worker in a factor...
2025-12-31 14:02:06,553 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #375 at t=49.96666666666667: 4 samples, timeline=t=49.9s: arafed man in a blue shirt and mask in a factory
t=49.9s: arafed man in a factory wearing a...
2025-12-31 14:02:06,553 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #376 at t=50.1: 4 samples, timeline=t=50.0s: arafed man in a factory with a mask on talking on a cell phone
t=50.0s: arafed man in a blu...
2025-12-31 14:02:06,553 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #377 at t=50.233333333333334: 4 samples, timeline=t=50.1s: arafed man in a blue shirt and mask standing in a factory
t=50.2s: arafed man in a blue shi...
2025-12-31 14:02:06,553 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #378 at t=50.36666666666667: 4 samples, timeline=t=50.3s: arafed man in a blue shirt and mask in a factory
t=50.3s: arafed man in a mask and blue shi...
2025-12-31 14:02:06,553 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #379 at t=50.5: 4 samples, timeline=t=50.4s: arafed man in blue shirt talking on cell phone in factory
t=50.4s: arafed man in blue shirt...
2025-12-31 14:02:06,554 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #380 at t=50.63333333333333: 4 samples, timeline=t=50.5s: arafed man in a mask and blue shirt in a factory
t=50.6s: arafed man in blue shirt and mask...
2025-12-31 14:02:06,554 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #381 at t=50.766666666666666: 4 samples, timeline=t=50.7s: arafed man in blue shirt and mask standing in factory
t=50.7s: arafed man standing in a fac...
2025-12-31 14:02:06,554 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #382 at t=50.9: 4 samples, timeline=t=50.8s: arafed man standing in a factory with a lot of machines
t=50.8s: arafed man standing in a f...
2025-12-31 14:02:06,554 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #383 at t=51.03333333333333: 4 samples, timeline=t=50.9s: arafed man standing in a factory with a lot of machines
t=51.0s: arafed man standing in a f...
2025-12-31 14:02:06,554 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #384 at t=51.166666666666664: 4 samples, timeline=t=51.1s: arafed man standing in a factory with a lot of machines
t=51.1s: arafed man standing in a f...
2025-12-31 14:02:06,554 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #385 at t=51.3: 4 samples, timeline=t=51.2s: arafed man standing in a factory with a lot of machines
t=51.2s: arafed man standing in a f...
2025-12-31 14:02:06,554 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #386 at t=51.43333333333333: 4 samples, timeline=t=51.3s: arafed man standing in a factory with a lot of machines
t=51.4s: arafed man standing in a f...
2025-12-31 14:02:06,554 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #387 at t=51.56666666666667: 4 samples, timeline=t=51.5s: arafed man standing in a factory with a lot of machines
t=51.5s: arafed man standing in a f...
2025-12-31 14:02:06,554 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #388 at t=51.7: 4 samples, timeline=t=51.6s: arafed man standing in a factory with a lot of machines
t=51.6s: arafed man standing in a f...
2025-12-31 14:02:06,554 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #389 at t=51.833333333333336: 4 samples, timeline=t=51.7s: arafed man standing in a factory with a lot of machines
t=51.8s: arafed man standing in a f...
2025-12-31 14:02:06,555 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #390 at t=51.96666666666667: 4 samples, timeline=t=51.9s: arafed man standing in a factory with a lot of machines
t=51.9s: arafed man standing in a f...
2025-12-31 14:02:06,555 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #391 at t=52.1: 4 samples, timeline=t=52.0s: arafed man standing in a factory with a lot of machines
t=52.0s: arafed man standing in a f...
2025-12-31 14:02:06,555 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #392 at t=52.233333333333334: 4 samples, timeline=t=52.1s: arafed man standing in a factory with a lot of machines
t=52.2s: arafed man standing in a f...
2025-12-31 14:02:06,555 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #393 at t=52.36666666666667: 4 samples, timeline=t=52.3s: arafed man standing in a factory with a lot of machines
t=52.3s: arafed man standing in a f...
2025-12-31 14:02:06,555 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #394 at t=52.5: 4 samples, timeline=t=52.4s: arafed man standing in a factory with a lot of machines
t=52.4s: arafed man standing in a f...
2025-12-31 14:02:06,555 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #395 at t=52.63333333333333: 4 samples, timeline=t=52.5s: arafed man standing in a factory with a lot of machines
t=52.6s: arafed man standing in a f...
2025-12-31 14:02:06,556 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #396 at t=52.766666666666666: 4 samples, timeline=t=52.7s: arafed man standing in a factory with a lot of machines
t=52.7s: arafed man standing in a f...
2025-12-31 14:02:06,556 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #397 at t=52.9: 4 samples, timeline=t=52.8s: arafed man standing in a factory with a lot of machines
t=52.8s: arafed man standing in a f...
2025-12-31 14:02:06,556 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #398 at t=53.03333333333333: 4 samples, timeline=t=52.9s: arafed man standing in a factory with a lot of machines
t=53.0s: arafed man standing in a f...
2025-12-31 14:02:06,556 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #399 at t=53.166666666666664: 4 samples, timeline=t=53.1s: arafed man in a factory with a blue shirt and tan pants
t=53.1s: arafed man standing in a f...
2025-12-31 14:02:06,557 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #400 at t=53.3: 4 samples, timeline=t=53.2s: arafed man standing in a factory with a lot of machines
t=53.2s: arafed man standing in a f...
2025-12-31 14:02:06,557 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #401 at t=53.43333333333333: 4 samples, timeline=t=53.3s: arafed man standing in a factory with a lot of machines
t=53.4s: arafed man standing in a f...
2025-12-31 14:02:06,557 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #402 at t=53.56666666666667: 4 samples, timeline=t=53.5s: arafed man standing in a factory with a lot of machines
t=53.5s: arafed man standing in a f...
2025-12-31 14:02:06,557 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #403 at t=53.7: 4 samples, timeline=t=53.6s: arafed man in a blue shirt is walking through a store
t=53.6s: arafed man in a factory look...
2025-12-31 14:02:06,558 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #404 at t=53.833333333333336: 4 samples, timeline=t=53.7s: arafed image of a man in a factory with a machine
t=53.8s: arafed worker in a factory with ...
2025-12-31 14:02:06,558 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #405 at t=53.96666666666667: 4 samples, timeline=t=53.9s: arafed worker in a factory with a machine in the background
t=53.9s: arafed image of a man ...
2025-12-31 14:02:06,558 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #406 at t=54.1: 4 samples, timeline=t=54.0s: arafed worker in a factory with a lot of machines
t=54.0s: araffe worker in a factory with ...
2025-12-31 14:02:06,559 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #407 at t=54.233333333333334: 4 samples, timeline=t=54.1s: araffe worker in a factory with a blue bag
t=54.2s: arafed worker in a factory working on a...
2025-12-31 14:02:06,559 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #408 at t=54.36666666666667: 4 samples, timeline=t=54.3s: araffe worker in a factory with a blue apron
t=54.3s: araffes in a factory with a lot of ma...
2025-12-31 14:02:06,559 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #409 at t=54.5: 4 samples, timeline=t=54.4s: araffe worker in a factory with a lot of machines
t=54.4s: araffe worker in a factory worki...
2025-12-31 14:02:06,559 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #410 at t=54.63333333333333: 4 samples, timeline=t=54.5s: arafed worker in a factory working on a machine
t=54.6s: araffe worker working in a factory...
2025-12-31 14:02:06,560 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #411 at t=54.766666666666666: 4 samples, timeline=t=54.7s: araffe worker in a factory working on a machine
t=54.7s: araffe worker in a factory working...
2025-12-31 14:02:06,560 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #412 at t=54.9: 4 samples, timeline=t=54.8s: there are two men standing in a store looking at items
t=54.8s: arafed worker in a factory ...
2025-12-31 14:02:06,560 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #413 at t=55.03333333333333: 4 samples, timeline=t=54.9s: arafed image of a man working in a factory with a clock
t=55.0s: arafed man in a blue shirt...
2025-12-31 14:02:06,560 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #414 at t=55.166666666666664: 4 samples, timeline=t=55.1s: arafed image of a man working in a factory with a lot of machines
t=55.1s: arafed man in a ...
2025-12-31 14:02:06,560 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #415 at t=55.3: 4 samples, timeline=t=55.2s: arafed worker in a factory with a mask on
t=55.2s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,560 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #416 at t=55.43333333333333: 4 samples, timeline=t=55.3s: arafed worker in a factory working on a machine
t=55.4s: arafed worker in a factory with a ...
2025-12-31 14:02:06,561 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #417 at t=55.56666666666667: 4 samples, timeline=t=55.5s: arafed worker in a factory with a mask on
t=55.5s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,561 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #418 at t=55.7: 4 samples, timeline=t=55.6s: arafed worker in a factory with a mask on
t=55.6s: arafed worker in a factory with a face m...
2025-12-31 14:02:06,561 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #419 at t=55.833333333333336: 4 samples, timeline=t=55.7s: arafed worker in a factory with a mask on
t=55.8s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,561 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #420 at t=55.96666666666667: 4 samples, timeline=t=55.9s: arafed worker in a factory with a mask on
t=55.9s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,561 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #421 at t=56.1: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=56.0s: arafed worker in a factory with face mas...
2025-12-31 14:02:06,561 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #422 at t=56.233333333333334: 4 samples, timeline=t=56.1s: arafed worker in a factory with a mask on
t=56.2s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,561 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #423 at t=56.36666666666667: 4 samples, timeline=t=56.3s: arafed worker in a factory with a mask on
t=56.3s: arafed worker in a factory working on a ...
2025-12-31 14:02:06,561 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #424 at t=56.5: 4 samples, timeline=t=56.4s: arafed worker in a factory working on a machine
t=56.4s: arafed worker in a factory working...
2025-12-31 14:02:06,562 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #425 at t=56.63333333333333: 4 samples, timeline=t=56.5s: arafed worker in a factory working on a machine
t=56.6s: arafed worker in a factory working...
2025-12-31 14:02:06,562 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #426 at t=56.766666666666666: 4 samples, timeline=t=56.7s: arafed worker in a factory working on a machine
t=56.7s: arafed worker in a factory working...
2025-12-31 14:02:06,562 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #427 at t=56.9: 4 samples, timeline=t=56.8s: arafed worker in a factory working on a machine
t=56.8s: arafed worker in a factory with a ...
2025-12-31 14:02:06,562 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #428 at t=57.03333333333333: 4 samples, timeline=t=56.9s: arafed worker in a factory working on a machine
t=57.0s: arafed worker in a factory working...
2025-12-31 14:02:06,562 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #429 at t=57.166666666666664: 4 samples, timeline=t=57.1s: arafed worker in a factory working on a machine
t=57.1s: arafed worker in a factory working...
2025-12-31 14:02:06,562 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #430 at t=57.3: 4 samples, timeline=t=57.2s: arafed worker in a factory working on a machine
t=57.2s: arafed worker in a factory working...
2025-12-31 14:02:06,562 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #431 at t=57.43333333333333: 4 samples, timeline=t=57.3s: arafed worker in a factory working on a machine
t=57.4s: arafed man in a blue shirt and mas...
2025-12-31 14:02:06,562 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #432 at t=57.56666666666667: 4 samples, timeline=t=57.5s: arafed worker in a factory working on a machine
t=57.5s: arafed man in a factory working on...
2025-12-31 14:02:06,563 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #433 at t=57.7: 4 samples, timeline=t=57.6s: arafed man in a factory working on a machine
t=57.6s: arafed man in a factory working on a ...
2025-12-31 14:02:06,563 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #434 at t=57.833333333333336: 4 samples, timeline=t=57.7s: arafed man in a blue shirt and mask working on a machine
t=57.8s: arafed man in a blue shir...
2025-12-31 14:02:06,563 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #435 at t=57.96666666666667: 4 samples, timeline=t=57.9s: there is a man that is standing in a store with a cat
t=57.9s: there is a man that is stand...
2025-12-31 14:02:06,563 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #436 at t=58.1: 4 samples, timeline=t=58.0s: there is a man that is standing in a store with a plate
t=58.0s: there is a man that is sta...
2025-12-31 14:02:06,563 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #437 at t=58.233333333333334: 4 samples, timeline=t=58.1s: there is a man standing in a store with a cat on the counter
t=58.2s: there is a man that i...
2025-12-31 14:02:06,563 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #438 at t=58.36666666666667: 4 samples, timeline=t=58.3s: there is a man that is standing in a store with a bottle
t=58.3s: there is a man standing i...
2025-12-31 14:02:06,563 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #439 at t=58.5: 4 samples, timeline=t=58.4s: there is a man standing in a store with a dog on the counter
t=58.4s: arafed man in a blue ...
2025-12-31 14:02:06,563 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #440 at t=58.63333333333333: 4 samples, timeline=t=58.5s: arafed man in a factory with a mask on and gloves on
t=58.6s: arafed man in a factory with ...
2025-12-31 14:02:06,564 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #441 at t=58.766666666666666: 4 samples, timeline=t=58.7s: arafed man in a factory with a mask and gloves
t=58.7s: arafed worker in a factory with a m...
2025-12-31 14:02:06,564 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #442 at t=58.9: 4 samples, timeline=t=58.8s: arafed man in a blue shirt and face mask holding a box
t=58.8s: arafed man in a blue shirt ...
2025-12-31 14:02:06,564 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #443 at t=59.03333333333333: 4 samples, timeline=t=58.9s: arafed worker in a factory with a box of boxes
t=59.0s: arafed worker in a factory with a b...
2025-12-31 14:02:06,564 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #444 at t=59.166666666666664: 4 samples, timeline=t=59.1s: arafed worker in a factory with a box and a machine
t=59.1s: arafed worker in a factory wit...
2025-12-31 14:02:06,564 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #445 at t=59.3: 4 samples, timeline=t=59.2s: there is a man standing in a factory with a machine
t=59.2s: there is a man in a blue shirt...
2025-12-31 14:02:06,564 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #446 at t=59.43333333333333: 4 samples, timeline=t=59.3s: arafed worker in a factory with a mask and gloves
t=59.4s: arafed worker in a factory with ...
2025-12-31 14:02:06,564 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #447 at t=59.56666666666667: 4 samples, timeline=t=59.5s: arafed worker in a factory with a machine in the background
t=59.5s: arafed worker in a fac...
2025-12-31 14:02:06,564 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #448 at t=59.7: 4 samples, timeline=t=59.6s: there is a man standing in a factory with boxes and a machine
t=59.6s: arafed worker in a f...
2025-12-31 14:02:06,565 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #449 at t=59.833333333333336: 4 samples, timeline=t=59.7s: arafed man in a factory with a mask on and a face mask on
t=59.8s: arafed man in a blue shi...
2025-12-31 14:02:06,565 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #450 at t=59.96666666666667: 4 samples, timeline=t=59.9s: arafed worker in a factory with a mask on and gloves on
t=59.9s: arafed worker in a factory...
2025-12-31 14:02:06,565 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #451 at t=60.1: 4 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=60.0s: arafed worker in a factory wit...
2025-12-31 14:02:06,565 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #452 at t=60.233333333333334: 4 samples, timeline=t=60.1s: arafed worker in a factory with boxes and a mask on
t=60.2s: arafed man in a mask and blue ...
2025-12-31 14:02:06,565 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #453 at t=60.36666666666667: 4 samples, timeline=t=60.3s: arafed man in a factory with a mask on and a box
t=60.3s: arafed worker in a factory with b...
2025-12-31 14:02:06,565 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #454 at t=60.5: 4 samples, timeline=t=60.4s: arafed worker in a factory with a mask on and gloves on
t=60.4s: arafed worker in a factory...
2025-12-31 14:02:06,565 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #455 at t=60.63333333333333: 4 samples, timeline=t=60.5s: arafed worker in a factory with a mask on
t=60.6s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,565 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #456 at t=60.766666666666666: 4 samples, timeline=t=60.7s: arafed worker in a factory with a laptop computer
t=60.7s: arafed worker in a factory with ...
2025-12-31 14:02:06,565 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #457 at t=60.9: 4 samples, timeline=t=60.8s: arafed worker in a factory with a box of food
t=60.8s: arafed worker in a factory with a bo...
2025-12-31 14:02:06,565 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #458 at t=61.03333333333333: 4 samples, timeline=t=60.9s: arafed worker in a factory with a box of food
t=61.0s: arafed worker in a factory with a bo...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #459 at t=61.166666666666664: 4 samples, timeline=t=61.1s: arafed worker in a factory with a box of food
t=61.1s: arafed worker in a factory with a ma...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #460 at t=61.3: 4 samples, timeline=t=61.2s: arafed worker in a factory with a mask on
t=61.2s: arafed worker in a factory with a box of...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #461 at t=61.43333333333333: 4 samples, timeline=t=61.3s: arafed worker in a factory with a mask on
t=61.4s: arafed worker in a factory with a laptop...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #462 at t=61.56666666666667: 4 samples, timeline=t=61.5s: arafed worker in a factory with a laptop computer
t=61.5s: arafed worker in a factory with ...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #463 at t=61.7: 4 samples, timeline=t=61.6s: arafed worker in a factory with a mask on and gloves on
t=61.6s: arafed worker in a factory...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #464 at t=61.833333333333336: 4 samples, timeline=t=61.7s: arafed worker in a factory with a mask on
t=61.8s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #465 at t=61.96666666666667: 4 samples, timeline=t=61.9s: arafed worker in a factory with a mask on
t=61.9s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #466 at t=62.1: 4 samples, timeline=t=62.0s: arafed worker in a factory with a mask on and gloves on
t=62.0s: arafed worker in a factory...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #467 at t=62.233333333333334: 4 samples, timeline=t=62.1s: arafed worker in a factory with a mask on and gloves on
t=62.2s: arafed worker in a factory...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #468 at t=62.36666666666667: 4 samples, timeline=t=62.3s: arafed worker in a factory with a mask on
t=62.3s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #469 at t=62.5: 4 samples, timeline=t=62.4s: arafed worker in a factory with a mask on
t=62.4s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #470 at t=62.63333333333333: 4 samples, timeline=t=62.5s: arafed worker in a factory with a mask on
t=62.6s: arafed worker in a factory with a mask o...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #471 at t=62.766666666666666: 4 samples, timeline=t=62.7s: arafed worker in a factory with a mask on
t=62.7s: arafed man in a factory with a mask on
t...
2025-12-31 14:02:06,566 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #472 at t=62.9: 4 samples, timeline=t=62.8s: arafed man in a blue shirt and a mask standing in a factory
t=62.8s: arafed man in a blue s...
2025-12-31 14:02:06,567 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #473 at t=63.03333333333333: 4 samples, timeline=t=62.9s: arafed man in a mask and blue shirt working in a factory
t=63.0s: arafed man in a mask and ...
2025-12-31 14:02:06,567 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #474 at t=63.166666666666664: 4 samples, timeline=t=63.1s: arafed man in a blue shirt and a mask standing in a factory
t=63.1s: arafed man in a blue s...
2025-12-31 14:02:06,567 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #475 at t=63.3: 4 samples, timeline=t=63.2s: arafed man in a blue shirt and a mask standing in a factory
t=63.2s: arafed image of a man ...
2025-12-31 14:02:06,567 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #476 at t=63.43333333333333: 4 samples, timeline=t=63.3s: arafed image of a man standing in a factory with a camera
t=63.4s: arafed image of a man st...
2025-12-31 14:02:06,567 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #477 at t=63.56666666666667: 4 samples, timeline=t=63.5s: arafed man standing in a factory with a lot of machines
t=63.5s: arafed image of a man stan...
2025-12-31 14:02:06,567 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #478 at t=63.7: 4 samples, timeline=t=63.6s: arafed man standing in a factory with a lot of machines
t=63.6s: arafed man standing in a f...
2025-12-31 14:02:06,567 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #479 at t=63.833333333333336: 4 samples, timeline=t=63.7s: arafed man standing in a factory with a lot of machines
t=63.8s: arafed man standing in a f...
2025-12-31 14:02:06,567 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #480 at t=63.96666666666667: 4 samples, timeline=t=63.9s: arafed man standing in a factory with a camera in his hand
t=63.9s: arafed man in a factory...
2025-12-31 14:02:06,567 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #481 at t=64.1: 4 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background
t=64.0s: arafed man in a factory w...
2025-12-31 14:02:06,567 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #482 at t=64.23333333333333: 4 samples, timeline=t=64.1s: arafed man standing in a factory with a machine in the background
t=64.2s: arafed man in a ...
2025-12-31 14:02:06,567 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #483 at t=final_flush: 1 samples, timeline=t=64.3s: arafed man in a factory with a machine in the background...
2025-12-31 14:02:06,608 backend.db - INFO [STATS] samples=1865 duration=64.30 fps=30.00 work=63.70s idle=46.93s unclass=0.00s work%=99.1 idle%=73.0 unclass%=0.0
2025-12-31 14:02:06,608 backend.db - INFO [STATS_SAVE] analysis=1d4e8e80-a082-4efc-8406-2b8a354ab7ee duration=64.30 fps=30.00 work=63.70s idle=46.93s unclass=0.00s work%=99.1 idle%=73.0 unclass%=0.0
2025-12-31 14:02:06,611 backend.db - INFO [DB_SAVE] analysis 1d4e8e80-a082-4efc-8406-2b8a354ab7ee saved to database
2025-12-31 14:02:06,611 backend.db - INFO [DB_SAVE] analysis 1d4e8e80-a082-4efc-8406-2b8a354ab7ee saving 1929 samples to database
2025-12-31 14:02:06,626 backend.db - INFO [DB_SAVE] analysis 1d4e8e80-a082-4efc-8406-2b8a354ab7ee samples saved to database
2025-12-31 14:02:06,626 backend.db - INFO [DB_SAVE] analysis 1d4e8e80-a082-4efc-8406-2b8a354ab7ee saving 648 segments to database
2025-12-31 14:02:06,660 backend.db - INFO [DB_SAVE_COMPLETE] analysis 1d4e8e80-a082-4efc-8406-2b8a354ab7ee saved to database
2026-01-02 10:34:22,309 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.00s with 4 samples
2026-01-02 10:34:28,836 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-1.00: work with 2 captions
2026-01-02 10:34:28,837 backend.stream_utils - INFO [PARSE_LLM] Created segment 2.00-2.00: idle with 1 captions
2026-01-02 10:34:28,837 backend.stream_utils - INFO [PARSE_LLM] Created segment 3.00-3.00: work with 1 captions
2026-01-02 10:34:31,147 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.00s with 4 samples
2026-01-02 10:34:34,586 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-5.00: work with 2 captions
2026-01-02 10:34:34,586 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.00-7.00: work with 2 captions
2026-01-02 10:34:34,586 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-5.00: work with 2 captions
2026-01-02 10:34:34,587 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.00-7.00: work with 2 captions
2026-01-02 10:34:34,587 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-5.00: work with 2 captions
2026-01-02 10:34:34,587 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.00-7.00: work with 2 captions
2026-01-02 10:34:34,588 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2026-01-02 10:34:37,539 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=11.00s with 4 samples
2026-01-02 10:34:41,289 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-9.00: work with 2 captions
2026-01-02 10:34:41,291 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-11.00: work with 2 captions
2026-01-02 10:34:41,292 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-9.00: work with 2 captions
2026-01-02 10:34:41,292 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-11.00: work with 2 captions
2026-01-02 10:34:41,293 backend.stream_utils - INFO [PARSE_LLM] Created segment 8.00-9.00: work with 2 captions
2026-01-02 10:34:41,294 backend.stream_utils - INFO [PARSE_LLM] Created segment 10.00-11.00: work with 2 captions
2026-01-02 10:34:41,295 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window
2026-01-02 10:34:44,030 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2026-01-02 10:34:48,124 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-12.00: work with 1 captions
2026-01-02 10:34:48,124 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.00-13.00: work with 1 captions
2026-01-02 10:34:48,125 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.00-14.00: work with 1 captions
2026-01-02 10:34:48,125 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 1 captions
2026-01-02 10:34:48,125 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-12.00: work with 1 captions
2026-01-02 10:34:48,125 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.00-13.00: work with 1 captions
2026-01-02 10:34:48,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.00-14.00: work with 1 captions
2026-01-02 10:34:48,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 1 captions
2026-01-02 10:34:48,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-12.00: work with 1 captions
2026-01-02 10:34:48,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 13.00-13.00: work with 1 captions
2026-01-02 10:34:48,126 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.00-14.00: work with 1 captions
2026-01-02 10:34:48,127 backend.stream_utils - INFO [PARSE_LLM] Created segment 15.00-15.00: idle with 1 captions
2026-01-02 10:34:48,127 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window
2026-01-02 10:34:50,177 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=19.00s with 4 samples
2026-01-02 10:34:54,108 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-17.00: work with 2 captions
2026-01-02 10:34:54,108 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.00-18.00: idle with 2 captions
2026-01-02 10:34:54,108 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-19.00: work with 2 captions
2026-01-02 10:34:54,108 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-17.00: work with 2 captions
2026-01-02 10:34:54,108 backend.stream_utils - INFO [PARSE_LLM] Created segment 17.00-18.00: idle with 2 captions
2026-01-02 10:34:54,109 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-19.00: work with 2 captions
2026-01-02 10:34:54,109 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2026-01-02 10:34:56,388 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.00s with 4 samples
2026-01-02 10:35:03,451 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.00s with 4 samples
2026-01-02 10:35:10,512 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=31.00s with 4 samples
2026-01-02 10:35:15,737 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=35.00s with 4 samples
2026-01-02 10:35:20,839 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=39.00s with 4 samples
2026-01-02 10:35:23,560 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 10:35:23,560 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 10:35:25,451 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=43.00s with 4 samples
2026-01-02 10:35:42,532 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.00s with 4 samples
2026-01-02 10:35:45,512 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 10:35:45,512 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 10:35:47,695 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=51.00s with 4 samples
2026-01-02 10:35:52,136 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 10:35:52,137 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 10:35:54,083 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=55.00s with 4 samples
2026-01-02 10:35:56,988 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 10:35:56,988 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 10:35:58,916 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=59.00s with 4 samples
2026-01-02 10:36:03,973 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=63.00s with 4 samples
2026-01-02 10:36:08,024 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-63.00: work with 4 captions
2026-01-02 10:36:08,026 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-63.00: work with 4 captions
2026-01-02 10:36:08,027 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-63.00: work with 4 captions
2026-01-02 10:36:08,028 backend.stream_utils - INFO [PARSE_LLM] Created segment 60.00-63.00: work with 4 captions
2026-01-02 10:36:08,028 backend.stream_utils - INFO [PARSE_LLM] Removed 3 duplicate segment(s) in window
2026-01-02 10:36:08,574 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2026-01-02 10:36:10,750 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 1 captions.
2026-01-02 10:36:10,751 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 10:36:10,753 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 65
2026-01-02 10:36:10,753 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 17
2026-01-02 10:36:10,753 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (1.0, 'arafed man standing in a factory with a '), (2.0, 'someone is working on a laptop with a lo'), (3.0, 'arafed man working on a computer in a fa'), (4.0, 'arafed worker working on a machine in a '), (5.0, 'araffe worker in a factory working on a '), (6.0, 'arafed man standing in a factory with a '), (7.0, 'there is a man standing at a counter wit'), (8.0, 'there is a man standing in front of a co'), (9.0, 'there is a man that is working on a mach')]...
2026-01-02 10:36:10,753 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=3.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=1.0s: arafed man standing in a f...
2026-01-02 10:36:10,754 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=7.0: 4 samples, timeline=t=4.0s: arafed worker working on a machine in a factory
t=5.0s: araffe worker in a factory working o...
2026-01-02 10:36:10,754 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=11.0: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=9.0s: there is a man...
2026-01-02 10:36:10,754 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=15.0: 4 samples, timeline=t=12.0s: arafed man standing in a factory with a tablet computer
t=13.0s: arafed man working on a co...
2026-01-02 10:36:10,755 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=19.0: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=17.0s: there is a computer monitor sitting on...
2026-01-02 10:36:10,755 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=23.0: 4 samples, timeline=t=20.0s: arafed worker in a factory working on a machine
t=21.0s: arafed worker in a factory working...
2026-01-02 10:36:10,755 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=27.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=25.0s: there are two men in blue shirts are wor...
2026-01-02 10:36:10,756 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=31.0: 4 samples, timeline=t=28.0s: arafed man in a factory working on a machine
t=29.0s: arafed man in a factory with a camera...
2026-01-02 10:36:10,756 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=35.0: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=33.0s: there is a man in a blue shirt and...
2026-01-02 10:36:10,756 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #10 at t=39.0: 4 samples, timeline=t=36.0s: there is a man that is standing in a factory with a machine
t=37.0s: arafed man standing in...
2026-01-02 10:36:10,758 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #11 at t=43.0: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=41.0s: arafed man in a blue shirt...
2026-01-02 10:36:10,759 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #12 at t=47.0: 4 samples, timeline=t=44.0s: arafed man in a factory looking at machinery in a factory
t=45.0s: arafed man in a factory ...
2026-01-02 10:36:10,760 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #13 at t=51.0: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=49.0s: arafed man in a blue shirt...
2026-01-02 10:36:10,760 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #14 at t=55.0: 4 samples, timeline=t=52.0s: arafed man standing in a factory with a lot of machines
t=53.0s: arafed man standing in a f...
2026-01-02 10:36:10,761 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #15 at t=59.0: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=57.0s: arafed worker in a factory working on a ...
2026-01-02 10:36:10,761 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #16 at t=63.0: 4 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=61.0s: arafed worker in a factory wit...
2026-01-02 10:36:10,761 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #17 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2026-01-02 10:36:10,789 backend.db - INFO [STATS] samples=41 duration=64.30 fps=30.00 work=16.00s idle=14.00s unclass=34.30s work%=24.9 idle%=21.8 unclass%=53.3
2026-01-02 10:36:10,790 backend.db - INFO [STATS_SAVE] analysis=a7984a8a-24d8-4657-b05d-95f349f623c3 duration=64.30 fps=30.00 work=16.00s idle=14.00s unclass=34.30s work%=24.9 idle%=21.8 unclass%=53.3
2026-01-02 10:36:10,792 backend.db - INFO [DB_SAVE] analysis a7984a8a-24d8-4657-b05d-95f349f623c3 saved to database
2026-01-02 10:36:10,793 backend.db - INFO [DB_SAVE] analysis a7984a8a-24d8-4657-b05d-95f349f623c3 saving 65 samples to database
2026-01-02 10:36:10,793 backend.db - INFO [DB_SAVE] analysis a7984a8a-24d8-4657-b05d-95f349f623c3 samples saved to database
2026-01-02 10:36:10,793 backend.db - INFO [DB_SAVE] analysis a7984a8a-24d8-4657-b05d-95f349f623c3 saving 20 segments to database
2026-01-02 10:36:10,794 backend.db - INFO [DB_SAVE_COMPLETE] analysis a7984a8a-24d8-4657-b05d-95f349f623c3 saved to database
2026-01-02 11:03:29,470 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.00s with 4 samples
2026-01-02 11:03:49,604 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.50-2.30: work with 2 captions
2026-01-02 11:04:17,971 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.00s with 4 samples
2026-01-02 11:04:37,375 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=0.86s with 4 samples
2026-01-02 11:04:41,536 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-5.00: work with 2 captions
2026-01-02 11:04:41,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.00-7.00: idle with 2 captions
2026-01-02 11:04:41,537 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-5.00: work with 2 captions
2026-01-02 11:04:41,538 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.00-7.00: idle with 2 captions
2026-01-02 11:04:41,539 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-5.00: work with 2 captions
2026-01-02 11:04:41,539 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.00-7.00: idle with 2 captions
2026-01-02 11:04:41,540 backend.stream_utils - INFO [PARSE_LLM] Created segment 4.00-5.00: work with 2 captions
2026-01-02 11:04:41,540 backend.stream_utils - INFO [PARSE_LLM] Created segment 6.00-7.00: idle with 2 captions
2026-01-02 11:04:41,541 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window
2026-01-02 11:04:53,754 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=11.00s with 4 samples
2026-01-02 11:04:58,918 backend.stream_utils - INFO [PARSE_LLM] Created segment 0.00-0.90: idle with 4 captions
2026-01-02 11:05:14,226 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 11:05:14,227 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 11:05:45,394 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=15.00s with 4 samples
2026-01-02 11:06:18,354 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-13.00: work with 2 captions
2026-01-02 11:06:18,354 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.00-15.00: work with 2 captions
2026-01-02 11:06:18,355 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-13.00: work with 2 captions
2026-01-02 11:06:18,355 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.00-15.00: work with 2 captions
2026-01-02 11:06:18,357 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-13.00: work with 2 captions
2026-01-02 11:06:18,357 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.00-15.00: idle with 2 captions
2026-01-02 11:06:18,358 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-13.00: work with 2 captions
2026-01-02 11:06:18,358 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.00-15.00: idle with 2 captions
2026-01-02 11:06:18,358 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-13.00: work with 2 captions
2026-01-02 11:06:18,359 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.00-15.00: idle with 2 captions
2026-01-02 11:06:18,359 backend.stream_utils - INFO [PARSE_LLM] Created segment 12.00-13.00: work with 2 captions
2026-01-02 11:06:18,360 backend.stream_utils - INFO [PARSE_LLM] Created segment 14.00-15.00: idle with 2 captions
2026-01-02 11:06:18,361 backend.stream_utils - INFO [PARSE_LLM] Removed 9 duplicate segment(s) in window
2026-01-02 11:06:49,318 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=19.00s with 4 samples
2026-01-02 11:07:10,906 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-17.00: work with 2 captions
2026-01-02 11:07:10,907 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-19.00: idle with 2 captions
2026-01-02 11:07:10,907 backend.stream_utils - INFO [PARSE_LLM] Created segment 16.00-17.00: work with 2 captions
2026-01-02 11:07:10,907 backend.stream_utils - INFO [PARSE_LLM] Created segment 18.00-19.00: idle with 2 captions
2026-01-02 11:07:10,908 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window
2026-01-02 11:07:50,724 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=23.00s with 4 samples
2026-01-02 11:08:01,542 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 11:08:01,542 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 11:08:25,951 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.00s with 4 samples
2026-01-02 11:08:37,690 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 11:08:37,690 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 11:09:03,796 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=31.00s with 4 samples
2026-01-02 11:09:21,851 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 11:09:21,852 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 11:09:25,583 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.03s with 4 samples
2026-01-02 11:09:34,737 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=35.00s with 4 samples
2026-01-02 11:10:33,809 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.00-33.00: work with 2 captions
2026-01-02 11:10:33,809 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.00-35.00: work with 2 captions
2026-01-02 11:10:33,810 backend.stream_utils - INFO [PARSE_LLM] Created segment 32.00-33.00: work with 2 captions
2026-01-02 11:10:33,810 backend.stream_utils - INFO [PARSE_LLM] Created segment 34.00-35.00: idle with 2 captions
2026-01-02 11:10:33,810 backend.stream_utils - INFO [PARSE_LLM] Created segment 35.00-35.00: work with 1 captions
2026-01-02 11:10:33,811 backend.stream_utils - INFO [PARSE_LLM] Removed 1 duplicate segment(s) in window
2026-01-02 11:11:14,271 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=39.00s with 4 samples
2026-01-02 11:13:32,858 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.19s with 4 samples
2026-01-02 11:14:01,576 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 11:14:01,576 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 11:17:37,786 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.35s with 4 samples
2026-01-02 11:17:49,484 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 11:17:49,485 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 11:21:08,830 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.52s with 4 samples
2026-01-02 11:24:42,251 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.68s with 4 samples
2026-01-02 11:25:00,229 backend.stream_utils - INFO [PARSE_LLM] Created segment 5.80-6.70: idle with 4 captions
2026-01-02 11:28:15,608 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.84s with 4 samples
2026-01-02 11:28:38,814 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 11:28:38,814 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 11:32:19,232 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=18.00s with 4 samples
2026-01-02 11:32:35,762 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window (3 unique)
2026-01-02 11:32:37,161 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=42.00s with 4 samples
2026-01-02 11:32:54,094 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 3 samples
2026-01-02 11:33:24,029 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 11
2026-01-02 11:33:24,029 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 3
2026-01-02 11:33:24,029 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (6.0, 'arafed man standing in a factory with a '), (12.0, 'arafed man standing in a factory with a '), (18.0, 'there is a computer monitor sitting on a'), (24.0, 'araffes in a factory with a dog and a ma'), (30.0, 'arafed man standing in a factory with a '), (36.0, 'there is a man that is standing in a fac'), (42.0, 'arafed man in a blue shirt and mask work'), (48.0, 'arafed man in blue shirt standing in fro'), (54.0, 'arafed worker in a factory with a lot of')]...
2026-01-02 11:33:24,029 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=18.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=6.0s: arafed man standing in a f...
2026-01-02 11:33:24,029 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=42.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=30.0s: arafed man standing in a factory with a ...
2026-01-02 11:33:24,029 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=final_flush: 3 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=54.0s: arafed worker in a factory...
2026-01-02 11:33:24,044 backend.db - INFO [STATS] samples=4 duration=64.30 fps=30.00 work=12.00s idle=0.00s unclass=52.30s work%=18.7 idle%=0.0 unclass%=81.3
2026-01-02 11:33:24,044 backend.db - INFO [STATS_SAVE] analysis=1a815329-ed25-45d6-bcf9-aa17b4988bfb duration=64.30 fps=30.00 work=12.00s idle=0.00s unclass=52.30s work%=18.7 idle%=0.0 unclass%=81.3
2026-01-02 11:33:24,049 backend.db - INFO [DB_SAVE] analysis 1a815329-ed25-45d6-bcf9-aa17b4988bfb saved to database
2026-01-02 11:33:24,049 backend.db - INFO [DB_SAVE] analysis 1a815329-ed25-45d6-bcf9-aa17b4988bfb saving 11 samples to database
2026-01-02 11:33:24,050 backend.db - INFO [DB_SAVE] analysis 1a815329-ed25-45d6-bcf9-aa17b4988bfb samples saved to database
2026-01-02 11:33:24,050 backend.db - INFO [DB_SAVE] analysis 1a815329-ed25-45d6-bcf9-aa17b4988bfb saving 3 segments to database
2026-01-02 11:33:24,051 backend.db - INFO [DB_SAVE_COMPLETE] analysis 1a815329-ed25-45d6-bcf9-aa17b4988bfb saved to database
2026-01-02 11:35:56,189 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.00s with 4 samples
2026-01-02 11:36:19,957 backend.stream_utils - INFO [PARSE_LLM] Removed 16 duplicate segment(s) in window (4 unique)
2026-01-02 11:36:21,263 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.00s with 4 samples
2026-01-02 11:36:37,555 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 11:36:37,555 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 11:36:38,711 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.00s with 4 samples
2026-01-02 11:36:52,213 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.00s with 4 samples
2026-01-02 11:37:07,942 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 11:37:07,942 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 11:37:09,574 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.00s with 4 samples
2026-01-02 11:37:39,719 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.00s with 4 samples
2026-01-02 11:38:08,703 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.00s with 4 samples
2026-01-02 11:38:26,500 backend.stream_utils - INFO [PARSE_LLM] Removed 4 duplicate segment(s) in window (4 unique)
2026-01-02 11:38:27,794 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.00s with 4 samples
2026-01-02 11:38:52,622 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2026-01-02 11:39:16,977 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 33
2026-01-02 11:39:16,979 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 9
2026-01-02 11:39:16,979 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.0, 'someone is working on a laptop with a lo'), (4.0, 'arafed worker working on a machine in a '), (6.0, 'arafed man standing in a factory with a '), (8.0, 'there is a man standing in front of a co'), (10.0, 'someone is holding a cat in a glove whil'), (12.0, 'arafed man standing in a factory with a '), (14.0, 'arafed worker working on a machine in a '), (16.0, 'there is a truck that is parked in a gar'), (18.0, 'there is a computer monitor sitting on a')]...
2026-01-02 11:39:16,979 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.0s: someone is working on a la...
2026-01-02 11:39:16,979 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=14.0: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=10.0s: someone is ho...
2026-01-02 11:39:16,979 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=22.0: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=18.0s: there is a computer monitor sitting on...
2026-01-02 11:39:16,979 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=30.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=26.0s: there are people standing in a bus with ...
2026-01-02 11:39:16,979 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=38.0: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=34.0s: arafed man in a factory holding a ...
2026-01-02 11:39:16,982 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=46.0: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.0s: arafed man in a blue shirt...
2026-01-02 11:39:16,982 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=54.0: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=50.0s: arafed man in a factory wi...
2026-01-02 11:39:16,982 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=62.0: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=58.0s: there is a man that is standing in a sto...
2026-01-02 11:39:16,982 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2026-01-02 11:39:16,982 backend.db - INFO [STATS] samples=16 duration=64.30 fps=30.00 work=2.00s idle=16.00s unclass=46.30s work%=3.1 idle%=24.9 unclass%=72.0
2026-01-02 11:39:16,984 backend.db - INFO [STATS_SAVE] analysis=bc19406d-6769-47f9-a5d5-1130382fa352 duration=64.30 fps=30.00 work=2.00s idle=16.00s unclass=46.30s work%=3.1 idle%=24.9 unclass%=72.0
2026-01-02 11:39:16,986 backend.db - INFO [DB_SAVE] analysis bc19406d-6769-47f9-a5d5-1130382fa352 saved to database
2026-01-02 11:39:16,986 backend.db - INFO [DB_SAVE] analysis bc19406d-6769-47f9-a5d5-1130382fa352 saving 33 samples to database
2026-01-02 11:39:16,986 backend.db - INFO [DB_SAVE] analysis bc19406d-6769-47f9-a5d5-1130382fa352 samples saved to database
2026-01-02 11:39:16,986 backend.db - INFO [DB_SAVE] analysis bc19406d-6769-47f9-a5d5-1130382fa352 saving 10 segments to database
2026-01-02 11:39:16,986 backend.db - INFO [DB_SAVE_COMPLETE] analysis bc19406d-6769-47f9-a5d5-1130382fa352 saved to database
2026-01-02 12:02:34,907 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.00s with 4 samples
2026-01-02 12:02:47,323 backend.stream_utils - INFO [PARSE_LLM] Removed 22 duplicate segment(s) in window (5 unique)
2026-01-02 12:02:48,572 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.00s with 4 samples
2026-01-02 12:02:52,121 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 12:02:52,121 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 12:02:53,182 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.00s with 4 samples
2026-01-02 12:02:57,774 backend.stream_utils - INFO [PARSE_LLM] Removed 8 duplicate segment(s) in window (2 unique)
2026-01-02 12:02:58,913 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.00s with 4 samples
2026-01-02 12:03:07,514 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.00s with 4 samples
2026-01-02 12:03:09,491 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-02 12:03:10,603 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.00s with 4 samples
2026-01-02 12:03:13,221 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 12:03:13,221 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 12:03:14,435 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.00s with 4 samples
2026-01-02 12:03:20,570 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.00s with 4 samples
2026-01-02 12:03:28,559 backend.stream_utils - INFO [PARSE_LLM] Removed 13 duplicate segment(s) in window (3 unique)
2026-01-02 12:03:28,832 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2026-01-02 12:03:33,064 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 1 captions.
2026-01-02 12:03:33,065 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 33
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 9
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.0, 'someone is working on a laptop with a lo'), (4.0, 'arafed worker working on a machine in a '), (6.0, 'arafed man standing in a factory with a '), (8.0, 'there is a man standing in front of a co'), (10.0, 'someone is holding a cat in a glove whil'), (12.0, 'arafed man standing in a factory with a '), (14.0, 'arafed worker working on a machine in a '), (16.0, 'there is a truck that is parked in a gar'), (18.0, 'there is a computer monitor sitting on a')]...
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.0s: someone is working on a la...
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=14.0: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=10.0s: someone is ho...
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=22.0: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=18.0s: there is a computer monitor sitting on...
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=30.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=26.0s: there are people standing in a bus with ...
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=38.0: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=34.0s: arafed man in a factory holding a ...
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=46.0: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.0s: arafed man in a blue shirt...
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=54.0: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=50.0s: arafed man in a factory wi...
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=62.0: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=58.0s: there is a man that is standing in a sto...
2026-01-02 12:03:33,065 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2026-01-02 12:03:33,073 backend.db - INFO [STATS] samples=25 duration=64.30 fps=30.00 work=22.00s idle=14.00s unclass=28.30s work%=34.2 idle%=21.8 unclass%=44.0
2026-01-02 12:03:33,073 backend.db - INFO [STATS_SAVE] analysis=530770db-8129-4e04-8e83-db655df4da85 duration=64.30 fps=30.00 work=22.00s idle=14.00s unclass=28.30s work%=34.2 idle%=21.8 unclass%=44.0
2026-01-02 12:03:33,076 backend.db - INFO [DB_SAVE] analysis 530770db-8129-4e04-8e83-db655df4da85 saved to database
2026-01-02 12:03:33,076 backend.db - INFO [DB_SAVE] analysis 530770db-8129-4e04-8e83-db655df4da85 saving 33 samples to database
2026-01-02 12:03:33,076 backend.db - INFO [DB_SAVE] analysis 530770db-8129-4e04-8e83-db655df4da85 samples saved to database
2026-01-02 12:03:33,076 backend.db - INFO [DB_SAVE] analysis 530770db-8129-4e04-8e83-db655df4da85 saving 15 segments to database
2026-01-02 12:03:33,076 backend.db - INFO [DB_SAVE_COMPLETE] analysis 530770db-8129-4e04-8e83-db655df4da85 saved to database
2026-01-02 12:09:56,388 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.00s with 4 samples
2026-01-02 12:10:02,973 backend.stream_utils - INFO [PARSE_LLM] Removed 2 duplicate segment(s) in window (2 unique)
2026-01-02 12:10:03,961 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.00s with 4 samples
2026-01-02 12:10:06,652 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 12:10:06,652 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 12:10:07,618 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.00s with 4 samples
2026-01-02 12:10:10,789 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 12:10:10,789 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 12:10:11,828 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.00s with 4 samples
2026-01-02 12:10:16,875 backend.stream_utils - INFO [PARSE_LLM] Removed 6 duplicate segment(s) in window (2 unique)
2026-01-02 12:10:17,898 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.00s with 4 samples
2026-01-02 12:10:21,533 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 12:10:21,533 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 12:10:22,578 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.00s with 4 samples
2026-01-02 12:10:25,734 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 12:10:25,734 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 12:10:27,002 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.00s with 4 samples
2026-01-02 12:10:30,728 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-02 12:10:30,728 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 12:10:31,871 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.00s with 4 samples
2026-01-02 12:10:36,397 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2026-01-02 12:10:38,736 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 1 captions.
2026-01-02 12:10:38,736 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 33
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 9
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.0, 'someone is working on a laptop with a lo'), (4.0, 'arafed worker working on a machine in a '), (6.0, 'arafed man standing in a factory with a '), (8.0, 'there is a man standing in front of a co'), (10.0, 'someone is holding a cat in a glove whil'), (12.0, 'arafed man standing in a factory with a '), (14.0, 'arafed worker working on a machine in a '), (16.0, 'there is a truck that is parked in a gar'), (18.0, 'there is a computer monitor sitting on a')]...
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.0s: someone is working on a la...
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=14.0: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=10.0s: someone is ho...
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=22.0: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=18.0s: there is a computer monitor sitting on...
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=30.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=26.0s: there are people standing in a bus with ...
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=38.0: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=34.0s: arafed man in a factory holding a ...
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=46.0: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.0s: arafed man in a blue shirt...
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=54.0: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=50.0s: arafed man in a factory wi...
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=62.0: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=58.0s: there is a man that is standing in a sto...
2026-01-02 12:10:38,742 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2026-01-02 12:10:38,742 backend.db - INFO [STATS] samples=29 duration=64.30 fps=30.00 work=4.00s idle=44.00s unclass=16.30s work%=6.2 idle%=68.4 unclass%=25.3
2026-01-02 12:10:38,742 backend.db - INFO [STATS_SAVE] analysis=5ed082a3-5106-414b-b6c2-e7364d80811a duration=64.30 fps=30.00 work=4.00s idle=44.00s unclass=16.30s work%=6.2 idle%=68.4 unclass%=25.3
2026-01-02 12:10:38,748 backend.db - INFO [DB_SAVE] analysis 5ed082a3-5106-414b-b6c2-e7364d80811a saved to database
2026-01-02 12:10:38,748 backend.db - INFO [DB_SAVE] analysis 5ed082a3-5106-414b-b6c2-e7364d80811a saving 33 samples to database
2026-01-02 12:10:38,748 backend.db - INFO [DB_SAVE] analysis 5ed082a3-5106-414b-b6c2-e7364d80811a samples saved to database
2026-01-02 12:10:38,748 backend.db - INFO [DB_SAVE] analysis 5ed082a3-5106-414b-b6c2-e7364d80811a saving 10 segments to database
2026-01-02 12:10:38,748 backend.db - INFO [DB_SAVE_COMPLETE] analysis 5ed082a3-5106-414b-b6c2-e7364d80811a saved to database
2026-01-05 09:05:51,245 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=0.86s with 4 samples
2026-01-05 09:06:10,508 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-05 09:06:10,508 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-05 09:06:27,065 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.03s with 4 samples
2026-01-05 09:07:10,174 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.19s with 4 samples
2026-01-05 09:07:53,515 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.35s with 4 samples
2026-01-05 09:08:22,138 backend.stream_utils - INFO [PARSE_LLM] Skipped 6 duplicate line(s) during parsing (4 unique lines kept)
2026-01-05 09:08:22,139 backend.stream_utils - INFO [PARSE_LLM] Parsed 3 unique segment(s) from LLM output
2026-01-05 09:08:38,066 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.52s with 4 samples
2026-01-05 09:08:50,318 backend.stream_utils - INFO [PARSE_LLM] Parsed 1 unique segment(s) from LLM output
2026-01-05 09:09:06,438 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.68s with 4 samples
2026-01-05 09:09:18,244 backend.stream_utils - INFO [PARSE_LLM] Parsed 1 unique segment(s) from LLM output
2026-01-05 09:09:34,581 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.84s with 4 samples
2026-01-05 09:09:50,767 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2026-01-05 09:10:23,034 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2026-01-05 09:10:23,036 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-05 09:10:23,039 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2026-01-05 09:10:23,039 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2026-01-05 09:10:23,041 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'The main person is assembling a mechanic'), (0.2658555133079848, 'The main person is assembling a mechanic'), (0.5649429657794677, 'The main person in the image is engaged '), (0.8640304182509505, 'The main person is holding a wooden mech'), (1.1631178707224334, 'The main person is assembling a wooden m'), (1.4289733840304182, 'The main person is holding a wooden toy '), (1.728060836501901, 'The main person is holding a mechanical '), (2.027148288973384, 'The main person is holding a small elect'), (2.326235741444867, 'The main person is holding a small elect'), (2.5920912547528516, 'The main person is holding a small piece')]...
2026-01-05 09:10:23,042 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=0.8640304182509505: 4 samples, timeline=t=0.0s: The main person is assembling a mechanical model. They are using their hands to connect wire...
2026-01-05 09:10:23,043 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=2.027148288973384: 4 samples, timeline=t=1.2s: The main person is assembling a wooden mechanical model. They are using their hands to conne...
2026-01-05 09:10:23,043 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=3.1902661596958173: 4 samples, timeline=t=2.3s: The main person is holding a small electronic circuit board with their fingers. They are usi...
2026-01-05 09:10:23,044 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=4.353384030418251: 4 samples, timeline=t=3.5s: The main person is engaged in assembling a mechanical device. They are using their hands to ...
2026-01-05 09:10:23,044 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=5.516501901140685: 4 samples, timeline=t=4.7s: The main person is holding a small device with their hands. They are using a pair of tweezer...
2026-01-05 09:10:23,045 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=6.679619771863118: 4 samples, timeline=t=5.8s: The main person is assembling a wooden toy. They are using a small piece of wood to attach a...
2026-01-05 09:10:23,045 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=7.8427376425855515: 4 samples, timeline=t=7.0s: The main person is assembling a wooden drone. They are using a screwdriver to attach the com...
2026-01-05 09:10:23,046 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=8.1s: The main person is holding a small drone. They are holding the drone with both hands, and it...
2026-01-05 09:10:23,072 backend.db - INFO [STATS] samples=8 duration=8.74 fps=30.09 work=0.00s idle=2.92s unclass=5.82s work%=0.0 idle%=33.5 unclass%=66.5
2026-01-05 09:10:23,073 backend.db - INFO [STATS_SAVE] analysis=feb8c06c-8554-4249-860a-846492f64177 duration=8.74 fps=30.09 work=0.00s idle=2.92s unclass=5.82s work%=0.0 idle%=33.5 unclass%=66.5
2026-01-05 09:10:23,076 backend.db - INFO [DB_SAVE] analysis feb8c06c-8554-4249-860a-846492f64177 saved to database
2026-01-05 09:10:23,076 backend.db - INFO [DB_SAVE] analysis feb8c06c-8554-4249-860a-846492f64177 saving 30 samples to database
2026-01-05 09:10:23,077 backend.db - INFO [DB_SAVE] analysis feb8c06c-8554-4249-860a-846492f64177 samples saved to database
2026-01-05 09:10:23,077 backend.db - INFO [DB_SAVE] analysis feb8c06c-8554-4249-860a-846492f64177 saving 7 segments to database
2026-01-05 09:10:23,078 backend.db - INFO [DB_SAVE_COMPLETE] analysis feb8c06c-8554-4249-860a-846492f64177 saved to database
2026-01-05 09:32:17,543 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.50s with 4 samples
2026-01-05 09:33:28,665 backend.stream_utils - INFO [PARSE_LLM] Skipped 5 duplicate line(s) during parsing (4 unique lines kept)
2026-01-05 09:33:28,668 backend.stream_utils - INFO [PARSE_LLM] Parsed 4 unique segment(s) from LLM output
2026-01-05 09:33:40,465 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=17.50s with 4 samples
2026-01-05 09:33:54,047 backend.stream_utils - INFO [PARSE_LLM] Skipped 6 duplicate line(s) during parsing (3 unique lines kept)
2026-01-05 09:34:05,493 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.50s with 4 samples
2026-01-05 09:34:44,792 backend.stream_utils - INFO [PARSE_LLM] Skipped 19 duplicate line(s) during parsing (5 unique lines kept)
2026-01-05 09:34:44,793 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-05 09:34:56,935 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.50s with 4 samples
2026-01-05 09:35:19,517 backend.stream_utils - INFO [PARSE_LLM] Skipped 8 duplicate line(s) during parsing (5 unique lines kept)
2026-01-05 09:35:19,517 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-05 09:35:31,039 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.50s with 4 samples
2026-01-05 09:35:40,604 backend.stream_utils - INFO [PARSE_LLM] Skipped 4 duplicate line(s) during parsing (2 unique lines kept)
2026-01-05 09:35:40,604 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-05 09:35:52,269 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.50s with 4 samples
2026-01-05 09:36:03,481 backend.stream_utils - INFO [PARSE_LLM] Skipped 4 duplicate line(s) during parsing (2 unique lines kept)
2026-01-05 09:36:03,481 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-05 09:36:09,424 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2026-01-05 09:36:22,465 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2026-01-05 09:36:22,465 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-05 09:36:22,469 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 26
2026-01-05 09:36:22,469 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 7
2026-01-05 09:36:22,469 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.5, 'someone is working on a laptop in a fact'), (5.0, 'araffe worker in a factory working on a '), (7.5, 'there is a man standing at a counter wit'), (10.0, 'someone is holding a cat in a glove whil'), (12.5, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.5, 'there is a computer monitor sitting on a'), (20.0, 'arafed worker in a factory working on a '), (22.5, 'arafed worker in a factory working on a ')]...
2026-01-05 09:36:22,471 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=7.5: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.5s: someone is working on a la...
2026-01-05 09:36:22,471 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=17.5: 4 samples, timeline=t=10.0s: someone is holding a cat in a glove while it is sitting on a table
t=12.5s: arafed man stan...
2026-01-05 09:36:22,471 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=27.5: 4 samples, timeline=t=20.0s: arafed worker in a factory working on a machine
t=22.5s: arafed worker in a factory working...
2026-01-05 09:36:22,471 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=37.5: 4 samples, timeline=t=30.0s: arafed man standing in a factory with a machine behind him
t=32.5s: arafed man in a factory...
2026-01-05 09:36:22,471 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=47.5: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.5s: arafed man in a factory wo...
2026-01-05 09:36:22,472 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=57.5: 4 samples, timeline=t=50.0s: arafed man in a factory with a mask on talking on a cell phone
t=52.5s: arafed man standing...
2026-01-05 09:36:22,472 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.5s: arafed worker in a factory wit...
2026-01-05 09:36:22,474 backend.db - INFO [STATS] samples=20 duration=64.30 fps=30.00 work=25.00s idle=7.50s unclass=31.80s work%=38.9 idle%=11.7 unclass%=49.5
2026-01-05 09:36:22,475 backend.db - INFO [STATS_SAVE] analysis=68302028-aba0-4f1e-8058-7563a40078b3 duration=64.30 fps=30.00 work=25.00s idle=7.50s unclass=31.80s work%=38.9 idle%=11.7 unclass%=49.5
2026-01-05 09:36:22,478 backend.db - INFO [DB_SAVE] analysis 68302028-aba0-4f1e-8058-7563a40078b3 saved to database
2026-01-05 09:36:22,478 backend.db - INFO [DB_SAVE] analysis 68302028-aba0-4f1e-8058-7563a40078b3 saving 26 samples to database
2026-01-05 09:36:22,478 backend.db - INFO [DB_SAVE] analysis 68302028-aba0-4f1e-8058-7563a40078b3 samples saved to database
2026-01-05 09:36:22,479 backend.db - INFO [DB_SAVE] analysis 68302028-aba0-4f1e-8058-7563a40078b3 saving 13 segments to database
2026-01-05 09:36:22,480 backend.db - INFO [DB_SAVE_COMPLETE] analysis 68302028-aba0-4f1e-8058-7563a40078b3 saved to database
2026-01-05 10:55:13,986 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.50s with 4 samples
2026-01-05 10:55:41,432 backend.stream_utils - INFO [PARSE_LLM] Skipped 12 duplicate line(s) during parsing (3 unique lines kept)
2026-01-05 10:55:41,432 backend.stream_utils - INFO [PARSE_LLM] Parsed 3 unique segment(s) from LLM output
2026-01-05 10:55:53,546 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=17.50s with 4 samples
2026-01-05 10:56:11,724 backend.stream_utils - INFO [PARSE_LLM] Skipped 10 duplicate line(s) during parsing (5 unique lines kept)
2026-01-05 10:56:11,725 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-05 10:56:23,127 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=27.50s with 4 samples
2026-01-05 10:56:33,679 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-05 10:56:33,680 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-05 10:56:46,091 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=37.50s with 4 samples
2026-01-05 10:56:55,457 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-05 10:56:55,457 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-05 10:57:07,279 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=47.50s with 4 samples
2026-01-05 10:57:31,823 backend.stream_utils - INFO [PARSE_LLM] Skipped 5 duplicate line(s) during parsing (5 unique lines kept)
2026-01-05 10:57:31,824 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-05 10:57:44,278 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=57.50s with 4 samples
2026-01-05 10:58:03,684 backend.stream_utils - INFO [PARSE_LLM] Skipped 7 duplicate line(s) during parsing (5 unique lines kept)
2026-01-05 10:58:03,685 backend.stream_utils - INFO [PARSE_LLM] Parsed 3 unique segment(s) from LLM output
2026-01-05 10:58:10,306 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2026-01-05 10:58:16,765 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 2 captions.
2026-01-05 10:58:16,766 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-05 10:58:16,767 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 26
2026-01-05 10:58:16,768 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 7
2026-01-05 10:58:16,768 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.5, 'someone is working on a laptop in a fact'), (5.0, 'araffe worker in a factory working on a '), (7.5, 'there is a man standing at a counter wit'), (10.0, 'someone is holding a cat in a glove whil'), (12.5, 'arafed man standing in a factory with a '), (15.0, 'there is a man that is standing in a roo'), (17.5, 'there is a computer monitor sitting on a'), (20.0, 'arafed worker in a factory working on a '), (22.5, 'arafed worker in a factory working on a ')]...
2026-01-05 10:58:16,768 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=7.5: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.5s: someone is working on a la...
2026-01-05 10:58:16,768 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=17.5: 4 samples, timeline=t=10.0s: someone is holding a cat in a glove while it is sitting on a table
t=12.5s: arafed man stan...
2026-01-05 10:58:16,768 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=27.5: 4 samples, timeline=t=20.0s: arafed worker in a factory working on a machine
t=22.5s: arafed worker in a factory working...
2026-01-05 10:58:16,768 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=37.5: 4 samples, timeline=t=30.0s: arafed man standing in a factory with a machine behind him
t=32.5s: arafed man in a factory...
2026-01-05 10:58:16,770 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=47.5: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.5s: arafed man in a factory wo...
2026-01-05 10:58:16,770 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=57.5: 4 samples, timeline=t=50.0s: arafed man in a factory with a mask on talking on a cell phone
t=52.5s: arafed man standing...
2026-01-05 10:58:16,770 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=final_flush: 2 samples, timeline=t=60.0s: arafed worker in a factory with boxes and a mask on
t=62.5s: arafed worker in a factory wit...
2026-01-05 10:58:16,771 backend.db - INFO [STATS] samples=26 duration=64.30 fps=30.00 work=25.00s idle=25.00s unclass=14.30s work%=38.9 idle%=38.9 unclass%=22.2
2026-01-05 10:58:16,771 backend.db - INFO [STATS_SAVE] analysis=746a8b39-d3e7-4f37-82b1-06c4e6de5f3f duration=64.30 fps=30.00 work=25.00s idle=25.00s unclass=14.30s work%=38.9 idle%=38.9 unclass%=22.2
2026-01-05 10:58:16,776 backend.db - INFO [DB_SAVE] analysis 746a8b39-d3e7-4f37-82b1-06c4e6de5f3f saved to database
2026-01-05 10:58:16,776 backend.db - INFO [DB_SAVE] analysis 746a8b39-d3e7-4f37-82b1-06c4e6de5f3f saving 26 samples to database
2026-01-05 10:58:16,776 backend.db - INFO [DB_SAVE] analysis 746a8b39-d3e7-4f37-82b1-06c4e6de5f3f samples saved to database
2026-01-05 10:58:16,778 backend.db - INFO [DB_SAVE] analysis 746a8b39-d3e7-4f37-82b1-06c4e6de5f3f saving 13 segments to database
2026-01-05 10:58:16,780 backend.db - INFO [DB_SAVE_COMPLETE] analysis 746a8b39-d3e7-4f37-82b1-06c4e6de5f3f saved to database
2026-01-07 10:35:03,613 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=0.86s with 4 samples
2026-01-07 10:35:36,579 backend.stream_utils - INFO [PARSE_LLM] Parsed 1 unique segment(s) from LLM output
2026-01-07 10:35:53,602 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=2.03s with 4 samples
2026-01-07 10:36:08,793 backend.stream_utils - INFO [PARSE_LLM] Skipped 1 duplicate line(s) during parsing (1 unique lines kept)
2026-01-07 10:36:26,547 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=3.19s with 4 samples
2026-01-07 10:36:42,922 backend.stream_utils - INFO [PARSE_LLM] Skipped 3 duplicate line(s) during parsing (1 unique lines kept)
2026-01-07 10:36:42,923 backend.stream_utils - INFO [PARSE_LLM] Parsed 1 unique segment(s) from LLM output
2026-01-07 10:37:01,036 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=4.35s with 4 samples
2026-01-07 10:37:24,647 backend.stream_utils - INFO [PARSE_LLM] Skipped 4 duplicate line(s) during parsing (2 unique lines kept)
2026-01-07 10:37:24,648 backend.stream_utils - INFO [PARSE_LLM] Parsed 1 unique segment(s) from LLM output
2026-01-07 10:37:42,299 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=5.52s with 4 samples
2026-01-07 10:38:09,576 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.68s with 4 samples
2026-01-07 10:38:17,748 backend.stream_utils - INFO [PARSE_LLM] Parsed 1 unique segment(s) from LLM output
2026-01-07 10:38:35,218 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=7.84s with 4 samples
2026-01-07 10:39:01,612 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 2 samples
2026-01-07 10:39:07,315 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 30
2026-01-07 10:39:07,316 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 8
2026-01-07 10:39:07,316 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'The main person is assembling a mechanic'), (0.2658555133079848, 'The main person is assembling a mechanic'), (0.5649429657794677, 'The main person in the image is engaged '), (0.8640304182509505, 'The main person is holding a wooden mech'), (1.1631178707224334, 'The main person is assembling a wooden m'), (1.4289733840304182, 'The main person is holding a wooden toy '), (1.728060836501901, 'The main person is holding a mechanical '), (2.027148288973384, 'The main person is holding a small elect'), (2.326235741444867, 'The main person is holding a small elect'), (2.5920912547528516, 'The main person is holding a small piece')]...
2026-01-07 10:39:07,317 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=0.8640304182509505: 4 samples, timeline=t=0.0s: The main person is assembling a mechanical model. They are using their hands to connect wire...
2026-01-07 10:39:07,317 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=2.027148288973384: 4 samples, timeline=t=1.2s: The main person is assembling a wooden mechanical model. They are using their hands to conne...
2026-01-07 10:39:07,317 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=3.1902661596958173: 4 samples, timeline=t=2.3s: The main person is holding a small electronic circuit board with their fingers. They are usi...
2026-01-07 10:39:07,318 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=4.353384030418251: 4 samples, timeline=t=3.5s: The main person is engaged in assembling a mechanical device. They are using their hands to ...
2026-01-07 10:39:07,318 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=5.516501901140685: 4 samples, timeline=t=4.7s: The main person is holding a small device with their hands. They are using a pair of tweezer...
2026-01-07 10:39:07,319 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=6.679619771863118: 4 samples, timeline=t=5.8s: The main person is assembling a wooden toy. They are using a small piece of wood to attach a...
2026-01-07 10:39:07,319 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=7.8427376425855515: 4 samples, timeline=t=7.0s: The main person is assembling a wooden drone. They are using a screwdriver to attach the com...
2026-01-07 10:39:07,319 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=final_flush: 2 samples, timeline=t=8.1s: The main person is holding a small drone. They are holding the drone with both hands, and it...
2026-01-07 10:39:07,342 backend.db - INFO [STATS] samples=11 duration=8.74 fps=30.09 work=0.00s idle=2.33s unclass=6.41s work%=0.0 idle%=26.6 unclass%=73.4
2026-01-07 10:39:07,343 backend.db - INFO [STATS_SAVE] analysis=c69405fc-51c6-4c6d-b4c7-7ccb8a1e0d55 duration=8.74 fps=30.09 work=0.00s idle=2.33s unclass=6.41s work%=0.0 idle%=26.6 unclass%=73.4
2026-01-07 10:39:07,346 backend.db - INFO [DB_SAVE] analysis c69405fc-51c6-4c6d-b4c7-7ccb8a1e0d55 saved to database
2026-01-07 10:39:07,346 backend.db - INFO [DB_SAVE] analysis c69405fc-51c6-4c6d-b4c7-7ccb8a1e0d55 saving 30 samples to database
2026-01-07 10:39:07,347 backend.db - INFO [DB_SAVE] analysis c69405fc-51c6-4c6d-b4c7-7ccb8a1e0d55 samples saved to database
2026-01-07 10:39:07,348 backend.db - INFO [DB_SAVE] analysis c69405fc-51c6-4c6d-b4c7-7ccb8a1e0d55 saving 4 segments to database
2026-01-07 10:39:07,349 backend.db - INFO [DB_SAVE_COMPLETE] analysis c69405fc-51c6-4c6d-b4c7-7ccb8a1e0d55 saved to database
2026-01-07 12:10:30,121 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.00s with 4 samples
2026-01-07 12:10:46,413 backend.stream_utils - INFO [PARSE_LLM] Parsed 3 unique segment(s) from LLM output
2026-01-07 12:11:00,114 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.00s with 4 samples
2026-01-07 12:11:49,459 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.00s with 4 samples
2026-01-07 12:12:10,056 backend.stream_utils - INFO [PARSE_LLM] Skipped 6 duplicate line(s) during parsing (6 unique lines kept)
2026-01-07 12:12:10,057 backend.stream_utils - INFO [PARSE_LLM] Parsed 3 unique segment(s) from LLM output
2026-01-07 12:12:25,877 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.00s with 4 samples
2026-01-07 12:12:45,012 backend.stream_utils - INFO [PARSE_LLM] Skipped 6 duplicate line(s) during parsing (5 unique lines kept)
2026-01-07 12:12:45,012 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-07 12:12:58,734 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.00s with 4 samples
2026-01-07 12:13:13,999 backend.stream_utils - INFO [PARSE_LLM] Skipped 3 duplicate line(s) during parsing (3 unique lines kept)
2026-01-07 12:13:28,114 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.00s with 4 samples
2026-01-07 12:13:54,706 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.00s with 4 samples
2026-01-07 12:14:12,643 backend.stream_utils - INFO [PARSE_LLM] Skipped 3 duplicate line(s) during parsing (3 unique lines kept)
2026-01-07 12:14:12,643 backend.stream_utils - INFO [PARSE_LLM] Parsed 3 unique segment(s) from LLM output
2026-01-07 12:14:26,129 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.00s with 4 samples
2026-01-07 12:14:35,105 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-07 12:14:38,606 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2026-01-07 12:14:49,450 backend.stream_utils - INFO [PARSE_LLM] Skipped 2 duplicate line(s) during parsing (3 unique lines kept)
2026-01-07 12:14:49,451 backend.stream_utils - INFO [PARSE_LLM] Parsed 1 unique segment(s) from LLM output
2026-01-07 12:14:49,454 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 33
2026-01-07 12:14:49,455 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 9
2026-01-07 12:14:49,455 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.0, 'someone is working on a laptop with a lo'), (4.0, 'arafed worker working on a machine in a '), (6.0, 'arafed man standing in a factory with a '), (8.0, 'there is a man standing in front of a co'), (10.0, 'someone is holding a cat in a glove whil'), (12.0, 'arafed man standing in a factory with a '), (14.0, 'arafed worker working on a machine in a '), (16.0, 'there is a truck that is parked in a gar'), (18.0, 'there is a computer monitor sitting on a')]...
2026-01-07 12:14:49,456 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.0s: someone is working on a la...
2026-01-07 12:14:49,456 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=14.0: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=10.0s: someone is ho...
2026-01-07 12:14:49,456 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=22.0: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=18.0s: there is a computer monitor sitting on...
2026-01-07 12:14:49,457 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=30.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=26.0s: there are people standing in a bus with ...
2026-01-07 12:14:49,457 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=38.0: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=34.0s: arafed man in a factory holding a ...
2026-01-07 12:14:49,457 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=46.0: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.0s: arafed man in a blue shirt...
2026-01-07 12:14:49,457 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=54.0: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=50.0s: arafed man in a factory wi...
2026-01-07 12:14:49,458 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=62.0: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=58.0s: there is a man that is standing in a sto...
2026-01-07 12:14:49,458 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2026-01-07 12:14:49,484 backend.db - INFO [STATS] samples=21 duration=64.30 fps=30.00 work=20.00s idle=4.00s unclass=40.30s work%=31.1 idle%=6.2 unclass%=62.7
2026-01-07 12:14:49,485 backend.db - INFO [STATS_SAVE] analysis=72985439-f9b1-4c17-a7bc-e582cddfef19 duration=64.30 fps=30.00 work=20.00s idle=4.00s unclass=40.30s work%=31.1 idle%=6.2 unclass%=62.7
2026-01-07 12:14:49,493 backend.db - INFO [DB_SAVE] analysis 72985439-f9b1-4c17-a7bc-e582cddfef19 saved to database
2026-01-07 12:14:49,494 backend.db - INFO [DB_SAVE] analysis 72985439-f9b1-4c17-a7bc-e582cddfef19 saving 33 samples to database
2026-01-07 12:14:49,494 backend.db - INFO [DB_SAVE] analysis 72985439-f9b1-4c17-a7bc-e582cddfef19 samples saved to database
2026-01-07 12:14:49,494 backend.db - INFO [DB_SAVE] analysis 72985439-f9b1-4c17-a7bc-e582cddfef19 saving 14 segments to database
2026-01-07 12:14:49,497 backend.db - INFO [DB_SAVE_COMPLETE] analysis 72985439-f9b1-4c17-a7bc-e582cddfef19 saved to database
2026-01-08 14:00:33,522 backend.stream_processor - WARNING Failed to initialize detector: No module named 'base'. Continuing without detector.
2026-01-08 14:00:37,912 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.00s with 4 samples
2026-01-08 14:00:46,605 backend.stream_utils - INFO [PARSE_LLM] Skipped 1 duplicate line(s) during parsing (4 unique lines kept)
2026-01-08 14:00:46,605 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-08 14:00:48,429 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.00s with 4 samples
2026-01-08 14:00:52,171 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-08 14:00:52,172 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-08 14:00:53,788 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.00s with 4 samples
2026-01-08 14:01:00,810 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.00s with 4 samples
2026-01-08 14:01:03,063 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-08 14:01:03,063 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-08 14:01:05,424 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.00s with 4 samples
2026-01-08 14:01:08,381 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-08 14:01:08,383 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-08 14:01:10,866 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.00s with 4 samples
2026-01-08 14:01:14,338 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-08 14:01:17,138 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.00s with 4 samples
2026-01-08 14:01:20,615 backend.stream_utils - INFO [PARSE_LLM] Skipped 3 duplicate line(s) during parsing (3 unique lines kept)
2026-01-08 14:01:22,971 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.00s with 4 samples
2026-01-08 14:01:25,578 backend.stream_utils - INFO [PARSE_LLM] Skipped 1 duplicate line(s) during parsing (2 unique lines kept)
2026-01-08 14:01:25,578 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-08 14:01:26,026 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2026-01-08 14:01:30,372 backend.stream_utils - INFO [PARSE_LLM] Parsed 1 unique segment(s) from LLM output
2026-01-08 14:01:30,374 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 33
2026-01-08 14:01:30,374 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 9
2026-01-08 14:01:30,375 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.0, 'someone is working on a laptop with a lo'), (4.0, 'arafed worker working on a machine in a '), (6.0, 'arafed man standing in a factory with a '), (8.0, 'there is a man standing in front of a co'), (10.0, 'someone is holding a cat in a glove whil'), (12.0, 'arafed man standing in a factory with a '), (14.0, 'arafed worker working on a machine in a '), (16.0, 'there is a truck that is parked in a gar'), (18.0, 'there is a computer monitor sitting on a')]...
2026-01-08 14:01:30,375 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.0s: someone is working on a la...
2026-01-08 14:01:30,376 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=14.0: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=10.0s: someone is ho...
2026-01-08 14:01:30,376 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=22.0: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=18.0s: there is a computer monitor sitting on...
2026-01-08 14:01:30,376 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=30.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=26.0s: there are people standing in a bus with ...
2026-01-08 14:01:30,377 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=38.0: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=34.0s: arafed man in a factory holding a ...
2026-01-08 14:01:30,377 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=46.0: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.0s: arafed man in a blue shirt...
2026-01-08 14:01:30,377 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=54.0: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=50.0s: arafed man in a factory wi...
2026-01-08 14:01:30,377 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=62.0: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=58.0s: there is a man that is standing in a sto...
2026-01-08 14:01:30,378 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2026-01-08 14:01:30,411 backend.db - INFO [STATS] samples=24 duration=64.30 fps=30.00 work=14.00s idle=22.00s unclass=28.30s work%=21.8 idle%=34.2 unclass%=44.0
2026-01-08 14:01:30,411 backend.db - INFO [STATS_SAVE] analysis=485ec836-0dff-403d-9216-77865ed78759 duration=64.30 fps=30.00 work=14.00s idle=22.00s unclass=28.30s work%=21.8 idle%=34.2 unclass%=44.0
2026-01-08 14:01:30,415 backend.db - INFO [DB_SAVE] analysis 485ec836-0dff-403d-9216-77865ed78759 saved to database
2026-01-08 14:01:30,416 backend.db - INFO [DB_SAVE] analysis 485ec836-0dff-403d-9216-77865ed78759 saving 33 samples to database
2026-01-08 14:01:30,416 backend.db - INFO [DB_SAVE] analysis 485ec836-0dff-403d-9216-77865ed78759 samples saved to database
2026-01-08 14:01:30,417 backend.db - INFO [DB_SAVE] analysis 485ec836-0dff-403d-9216-77865ed78759 saving 10 segments to database
2026-01-08 14:01:30,417 backend.db - INFO [DB_SAVE_COMPLETE] analysis 485ec836-0dff-403d-9216-77865ed78759 saved to database
2026-01-09 11:48:35,034 backend.stream_processor - WARNING Failed to initialize detector: No module named 'base'. Continuing without detector.
2026-01-09 11:48:39,055 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=6.00s with 4 samples
2026-01-09 11:48:48,719 backend.stream_utils - INFO [PARSE_LLM] Skipped 4 duplicate line(s) during parsing (4 unique lines kept)
2026-01-09 11:48:48,720 backend.stream_utils - INFO [PARSE_LLM] Parsed 4 unique segment(s) from LLM output
2026-01-09 11:48:51,167 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=14.00s with 4 samples
2026-01-09 11:48:56,903 backend.stream_utils - INFO [PARSE_LLM] Skipped 12 duplicate line(s) during parsing (7 unique lines kept)
2026-01-09 11:48:56,904 backend.stream_utils - INFO [PARSE_LLM] Parsed 4 unique segment(s) from LLM output
2026-01-09 11:48:59,724 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=22.00s with 4 samples
2026-01-09 11:49:08,448 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-09 11:49:08,449 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-09 11:49:10,446 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=30.00s with 4 samples
2026-01-09 11:49:26,169 backend.stream_utils - INFO [PARSE_LLM] Skipped 36 duplicate line(s) during parsing (6 unique lines kept)
2026-01-09 11:49:26,170 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-09 11:49:28,280 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=38.00s with 4 samples
2026-01-09 11:49:32,840 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=46.00s with 4 samples
2026-01-09 11:49:38,083 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 4 captions.
2026-01-09 11:49:38,083 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-09 11:49:40,619 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=54.00s with 4 samples
2026-01-09 11:49:44,975 backend.stream_utils - INFO [PARSE_LLM] Parsed 3 unique segment(s) from LLM output
2026-01-09 11:49:47,056 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Window closed at t=62.00s with 4 samples
2026-01-09 11:49:51,275 backend.stream_utils - INFO [PARSE_LLM] Skipped 4 duplicate line(s) during parsing (2 unique lines kept)
2026-01-09 11:49:51,275 backend.stream_utils - INFO [PARSE_LLM] Parsed 2 unique segment(s) from LLM output
2026-01-09 11:49:51,768 backend.stream_processor - INFO [DEBUG_LLM_INPUT] Final window flush with 1 samples
2026-01-09 11:49:53,878 backend.stream_utils - WARNING [PARSE_LLM] No valid segments found in LLM output. Creating fallback segment with all 1 captions.
2026-01-09 11:49:53,881 backend.stream_utils - WARNING [PARSE_LLM] LLM output was: 
2026-01-09 11:49:53,885 backend.stream_processor - INFO [DEBUG_SUMMARY] Total VLM captions: 33
2026-01-09 11:49:53,885 backend.stream_processor - INFO [DEBUG_SUMMARY] Total LLM inputs: 9
2026-01-09 11:49:53,886 backend.stream_processor - INFO [DEBUG_SUMMARY] VLM captions: [(0.0, 'arafed image of a man working in a facto'), (2.0, 'someone is working on a laptop with a lo'), (4.0, 'arafed worker working on a machine in a '), (6.0, 'arafed man standing in a factory with a '), (8.0, 'there is a man standing in front of a co'), (10.0, 'someone is holding a cat in a glove whil'), (12.0, 'arafed man standing in a factory with a '), (14.0, 'arafed worker working on a machine in a '), (16.0, 'there is a truck that is parked in a gar'), (18.0, 'there is a computer monitor sitting on a')]...
2026-01-09 11:49:53,887 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #1 at t=6.0: 4 samples, timeline=t=0.0s: arafed image of a man working in a factory with a machine
t=2.0s: someone is working on a la...
2026-01-09 11:49:53,887 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #2 at t=14.0: 4 samples, timeline=t=8.0s: there is a man standing in front of a counter with a bunch of bottles
t=10.0s: someone is ho...
2026-01-09 11:49:53,887 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #3 at t=22.0: 4 samples, timeline=t=16.0s: there is a truck that is parked in a garage
t=18.0s: there is a computer monitor sitting on...
2026-01-09 11:49:53,888 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #4 at t=30.0: 4 samples, timeline=t=24.0s: araffes in a factory with a dog and a man
t=26.0s: there are people standing in a bus with ...
2026-01-09 11:49:53,888 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #5 at t=38.0: 4 samples, timeline=t=32.0s: arafed man in a factory with a laptop and a box
t=34.0s: arafed man in a factory holding a ...
2026-01-09 11:49:53,888 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #6 at t=46.0: 4 samples, timeline=t=40.0s: arafed man standing in a factory with a lot of machines
t=42.0s: arafed man in a blue shirt...
2026-01-09 11:49:53,890 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #7 at t=54.0: 4 samples, timeline=t=48.0s: arafed man in blue shirt standing in front of a machine
t=50.0s: arafed man in a factory wi...
2026-01-09 11:49:53,891 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #8 at t=62.0: 4 samples, timeline=t=56.0s: arafed worker in a factory with a mask on
t=58.0s: there is a man that is standing in a sto...
2026-01-09 11:49:53,891 backend.stream_processor - INFO [DEBUG_SUMMARY] LLM Input #9 at t=final_flush: 1 samples, timeline=t=64.0s: arafed man in a factory with a machine in the background...
2026-01-09 11:49:53,956 backend.db - INFO [STATS] samples=29 duration=64.30 fps=30.00 work=26.00s idle=12.00s unclass=26.30s work%=40.4 idle%=18.7 unclass%=40.9
2026-01-09 11:49:53,957 backend.db - INFO [STATS_SAVE] analysis=03fb0972-9435-43e5-977e-5e8103a93e24 duration=64.30 fps=30.00 work=26.00s idle=12.00s unclass=26.30s work%=40.4 idle%=18.7 unclass%=40.9
2026-01-09 11:49:53,962 backend.db - INFO [DB_SAVE] analysis 03fb0972-9435-43e5-977e-5e8103a93e24 saved to database
2026-01-09 11:49:54,047 backend.db - INFO [DB_SAVE] analysis 03fb0972-9435-43e5-977e-5e8103a93e24 saving 33 samples to database
2026-01-09 11:49:54,048 backend.db - INFO [DB_SAVE] analysis 03fb0972-9435-43e5-977e-5e8103a93e24 samples saved to database
2026-01-09 11:49:54,049 backend.db - INFO [DB_SAVE] analysis 03fb0972-9435-43e5-977e-5e8103a93e24 saving 18 segments to database
2026-01-09 11:49:54,052 backend.db - INFO [DB_SAVE_COMPLETE] analysis 03fb0972-9435-43e5-977e-5e8103a93e24 saved to database
