{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c595a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- Time Limits (in seconds) ---\n",
    "TIME_LIMIT = 20   # set as desired\n",
    "\n",
    "# Cooldown frames before resetting activity (anti-cheat)\n",
    "RESET_DELAY_FRAMES = 10\n",
    "\n",
    "activity_reset_counters = {\n",
    "    \"phone\": 0,\n",
    "    \"cup\": 0,\n",
    "    \"book\": 0,\n",
    "    \"laptop\": 0\n",
    "}\n",
    "\n",
    "# detection miss tolerance (frames) before zeroing CONFIRM counter\n",
    "DETECT_RESET_FRAMES = 50\n",
    "detection_miss_counters = {\n",
    "    \"phone\": 0,\n",
    "    \"cup\": 0,\n",
    "    \"book\": 0,\n",
    "    \"laptop\": 0\n",
    "}\n",
    "\n",
    "# Start timers when activity begins\n",
    "activity_timers = {\n",
    "    \"phone\": None,\n",
    "    \"cup\": None,\n",
    "    \"book\": None,\n",
    "    \"laptop\": None\n",
    "}\n",
    "\n",
    "# Whether the limit already exceeded (stop repeated saving)\n",
    "activity_flags = {\n",
    "    \"phone\": False,\n",
    "    \"cup\": False,\n",
    "    \"book\": False,\n",
    "    \"laptop\": False\n",
    "}\n",
    "\n",
    "# Save folder\n",
    "SAVE_FOLDER = \"exceeded_frames\"\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Initialize MediaPipe\n",
    "# -----------------------------\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2,\n",
    "                       min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# -----------------------------\n",
    "# Load YOLOv8 object detection model\n",
    "# -----------------------------\n",
    "object_model = YOLO(\"yolov8l.pt\")  # COCO trained (adjust to your model path)\n",
    "\n",
    "# -----------------------------\n",
    "# Webcam and motion tracking\n",
    "# -----------------------------\n",
    "cap = cv2.VideoCapture(1)\n",
    "prev_keypoints = None\n",
    "movement_history = []\n",
    "\n",
    "# Thresholds\n",
    "MOTION_THRESHOLD = 5\n",
    "STATIC_FRAMES = 30  # used for movement_history window\n",
    "\n",
    "# Acting detection params\n",
    "MIN_BODY_MOTION = 3.0      # body motion threshold for \"real\" activity\n",
    "MIN_HAND_MOTION = 5.0      # hand motion threshold for \"real\" activity\n",
    "ACTING_STATIC_FRAMES = 20  # consecutive low-motion frames to mark acting\n",
    "\n",
    "acting_counters = {\n",
    "    \"phone\": 0,\n",
    "    \"cup\": 0,\n",
    "    \"book\": 0,\n",
    "    \"laptop\": 0\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def extract_keypoints(results_pose, results_hands, frame_shape):\n",
    "    keypoints = []\n",
    "\n",
    "    # -------- POSE (33 keypoints) --------\n",
    "    if results_pose.pose_landmarks:\n",
    "        for lm in results_pose.pose_landmarks.landmark:\n",
    "            x = int(lm.x * frame_shape[1])\n",
    "            y = int(lm.y * frame_shape[0])\n",
    "            keypoints.append([x, y])\n",
    "    else:\n",
    "        keypoints += [[0, 0]] * 33\n",
    "\n",
    "    # -------- HANDS (42 keypoints = 21 per hand) --------\n",
    "    hand_kps = []\n",
    "    if results_hands.multi_hand_landmarks:\n",
    "        for hand in results_hands.multi_hand_landmarks:\n",
    "            for lm in hand.landmark:\n",
    "                x = int(lm.x * frame_shape[1])\n",
    "                y = int(lm.y * frame_shape[0])\n",
    "                hand_kps.append([x, y])\n",
    "\n",
    "    # pad hand keypoints to EXACTLY 42\n",
    "    while len(hand_kps) < 42:\n",
    "        hand_kps.append([0, 0])\n",
    "\n",
    "    # combine pose+hands\n",
    "    keypoints += hand_kps\n",
    "\n",
    "    # -------- ENFORCE EXACT SIZE (75 keypoints) --------\n",
    "    keypoints = keypoints[:75]     # truncate if more\n",
    "    return np.array(keypoints)\n",
    "\n",
    "\n",
    "def draw_pose_mask(mask, keypoints):\n",
    "    \"\"\"Draw body + hands skeleton as mask\"\"\"\n",
    "    body_connections = mp_pose.POSE_CONNECTIONS\n",
    "    for connection in body_connections:\n",
    "        a, b = connection\n",
    "        if keypoints[a][0] > 0 and keypoints[b][0] > 0:\n",
    "            cv2.line(mask, tuple(keypoints[a]), tuple(keypoints[b]), (255,255,255), 2)\n",
    "\n",
    "    hand_connections = mp_hands.HAND_CONNECTIONS\n",
    "    # Left hand: indices 33:54 (21 points)\n",
    "    left_hand = keypoints[33:54]\n",
    "    for connection in hand_connections:\n",
    "        a, b = connection\n",
    "        if left_hand[a][0] > 0 and left_hand[b][0] > 0:\n",
    "            cv2.line(mask, tuple(left_hand[a]), tuple(left_hand[b]), (255,255,255), 2)\n",
    "    # Right hand: indices 54:75\n",
    "    right_hand = keypoints[54:75]\n",
    "    for connection in hand_connections:\n",
    "        a, b = connection\n",
    "        if right_hand[a][0] > 0 and right_hand[b][0] > 0:\n",
    "            cv2.line(mask, tuple(right_hand[a]), tuple(right_hand[b]), (255,255,255), 2)\n",
    "    return mask\n",
    "\n",
    "def point_to_box(point, box):\n",
    "    if point is None:\n",
    "        return 9999\n",
    "    x1, y1, x2, y2 = box\n",
    "    cx, cy = (x1 + x2)/2, (y1 + y2)/2\n",
    "    return np.hypot(point[0]-cx, point[1]-cy)\n",
    "\n",
    "# Persistent detection counters\n",
    "task_memory = {\"phone\": 0, \"cup\": 0, \"book\": 0, \"laptop\": 0}\n",
    "CONFIRM_FRAMES = 3  # required consecutive detections\n",
    "\n",
    "PHONE_DIST = 150\n",
    "BOTTLE_DIST = 150\n",
    "BOOK_DIST = 180\n",
    "LAPTOP_DIST = 200\n",
    "\n",
    "def get_hand_centroid(keypoints):\n",
    "    \"\"\"Return average HAND position (more stable than wrist).\"\"\"\n",
    "    left_hand = keypoints[33:54]\n",
    "    right_hand = keypoints[54:75]\n",
    "\n",
    "    def centroid(hand):\n",
    "        valid = [pt for pt in hand if pt[0] > 0]\n",
    "        if not valid:\n",
    "            return None\n",
    "        arr = np.array(valid)\n",
    "        return np.mean(arr, axis=0)\n",
    "\n",
    "    return centroid(left_hand), centroid(right_hand)\n",
    "\n",
    "def update_activity_timer(activity, is_active, frame):\n",
    "    global activity_timers, activity_flags, activity_reset_counters\n",
    "\n",
    "    if is_active:\n",
    "        # Detected this frame → cancel reset countdown\n",
    "        activity_reset_counters[activity] = 0\n",
    "\n",
    "        # Start timer if not already running\n",
    "        if activity_timers[activity] is None:\n",
    "            activity_timers[activity] = time.time()\n",
    "\n",
    "        elapsed = time.time() - activity_timers[activity]\n",
    "\n",
    "        # Check if time exceeded\n",
    "        if elapsed >= TIME_LIMIT:\n",
    "            if not activity_flags[activity]:\n",
    "                ts = int(time.time())\n",
    "                # Save a copy of frame to avoid race\n",
    "                if frame is not None:\n",
    "                    cv2.imwrite(f\"{SAVE_FOLDER}/{activity}_{ts}.jpg\", frame)\n",
    "                activity_flags[activity] = True\n",
    "\n",
    "            return True  # limit exceeded\n",
    "\n",
    "        return False  # still ongoing\n",
    "\n",
    "    else:\n",
    "        # Not detected → increase cooldown counter\n",
    "        activity_reset_counters[activity] += 1\n",
    "\n",
    "        # Only reset if disappeared for enough frames\n",
    "        if activity_reset_counters[activity] >= RESET_DELAY_FRAMES:\n",
    "            activity_timers[activity] = None\n",
    "            activity_flags[activity] = False\n",
    "            activity_reset_counters[activity] = 0\n",
    "\n",
    "        return False\n",
    "\n",
    "def is_acting(activity, avg_motion, avg_hand_motion):\n",
    "    \"\"\"Return True if user is likely pretending (holding object but minimal motion).\"\"\"\n",
    "    global acting_counters\n",
    "    low_body = avg_motion < MIN_BODY_MOTION\n",
    "    low_hand = avg_hand_motion < MIN_HAND_MOTION\n",
    "\n",
    "    if low_body and low_hand:\n",
    "        acting_counters[activity] += 1\n",
    "    else:\n",
    "        acting_counters[activity] = 0\n",
    "\n",
    "    return acting_counters[activity] >= ACTING_STATIC_FRAMES\n",
    "\n",
    "def detect_task(objects, keypoints, avg_motion, avg_hand_motion, frame):\n",
    "    \"\"\"\n",
    "    Detect tasks and incorporate:\n",
    "    - object proximity checks\n",
    "    - persistent detection (task_memory)\n",
    "    - acting detection (using avg_motion & avg_hand_motion)\n",
    "    - activity timers (update_activity_timer)\n",
    "    \"\"\"\n",
    "    global task_memory, detection_miss_counters\n",
    "\n",
    "    left_hand, right_hand = get_hand_centroid(keypoints)\n",
    "    nose = keypoints[0] if keypoints[0][0] > 0 else None\n",
    "\n",
    "    # Detected flags for this frame\n",
    "    detected_phone = False\n",
    "    detected_cup = False\n",
    "    detected_book = False\n",
    "    detected_laptop = False\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1️⃣ Using Phone (PRIORITY)\n",
    "    # -----------------------------\n",
    "    if \"cell phone\" in objects:\n",
    "        phone = objects[\"cell phone\"]\n",
    "        if (left_hand is not None and point_to_box(left_hand, phone) < PHONE_DIST) or \\\n",
    "           (right_hand is not None and point_to_box(right_hand, phone) < PHONE_DIST):\n",
    "            detected_phone = True\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2️⃣ Bottle / Cup\n",
    "    # -----------------------------\n",
    "    cup = objects.get(\"cup\") if objects.get(\"cup\") is not None else objects.get(\"bottle\")\n",
    "\n",
    "    drinking = False\n",
    "    if cup is not None:\n",
    "        if (left_hand is not None and point_to_box(left_hand, cup) < BOTTLE_DIST) or \\\n",
    "           (right_hand is not None and point_to_box(right_hand, cup) < BOTTLE_DIST):\n",
    "            detected_cup = True\n",
    "\n",
    "        if nose is not None and point_to_box(nose, cup) < 150:\n",
    "            drinking = True  # don't return early — use as label\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3️⃣ Book / Notebook\n",
    "    # -----------------------------\n",
    "    nb = objects.get(\"book\")\n",
    "    reading_posture = False\n",
    "    if nb is not None:\n",
    "        if (left_hand is not None and point_to_box(left_hand, nb) < BOOK_DIST) or \\\n",
    "           (right_hand is not None and point_to_box(right_hand, nb) < BOOK_DIST):\n",
    "            detected_book = True\n",
    "\n",
    "        if nose is not None and point_to_box(nose, nb) < 200:\n",
    "            reading_posture = True\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4️⃣ Laptop\n",
    "    # -----------------------------\n",
    "    if \"laptop\" in objects:\n",
    "        lp = objects[\"laptop\"]\n",
    "        if (left_hand is not None and point_to_box(left_hand, lp) < LAPTOP_DIST) or \\\n",
    "           (right_hand is not None and point_to_box(right_hand, lp) < LAPTOP_DIST):\n",
    "            detected_laptop = True\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # Update task_memory with small miss-tolerance\n",
    "    # -----------------------------------------------\n",
    "    # PHONE\n",
    "    if detected_phone:\n",
    "        detection_miss_counters[\"phone\"] = 0\n",
    "        task_memory[\"phone\"] += 1\n",
    "    else:\n",
    "        detection_miss_counters[\"phone\"] += 1\n",
    "        if detection_miss_counters[\"phone\"] >= DETECT_RESET_FRAMES:\n",
    "            task_memory[\"phone\"] = 0\n",
    "            detection_miss_counters[\"phone\"] = 0\n",
    "\n",
    "    # CUP / BOTTLE\n",
    "    if detected_cup:\n",
    "        detection_miss_counters[\"cup\"] = 0\n",
    "        task_memory[\"cup\"] += 1\n",
    "    else:\n",
    "        detection_miss_counters[\"cup\"] += 1\n",
    "        if detection_miss_counters[\"cup\"] >= DETECT_RESET_FRAMES:\n",
    "            task_memory[\"cup\"] = 0\n",
    "            detection_miss_counters[\"cup\"] = 0\n",
    "\n",
    "    # BOOK\n",
    "    if detected_book:\n",
    "        detection_miss_counters[\"book\"] = 0\n",
    "        task_memory[\"book\"] += 1\n",
    "    else:\n",
    "        detection_miss_counters[\"book\"] += 1\n",
    "        if detection_miss_counters[\"book\"] >= DETECT_RESET_FRAMES:\n",
    "            task_memory[\"book\"] = 0\n",
    "            detection_miss_counters[\"book\"] = 0\n",
    "\n",
    "    # LAPTOP\n",
    "    if detected_laptop:\n",
    "        detection_miss_counters[\"laptop\"] = 0\n",
    "        task_memory[\"laptop\"] += 1\n",
    "    else:\n",
    "        detection_miss_counters[\"laptop\"] += 1\n",
    "        if detection_miss_counters[\"laptop\"] >= DETECT_RESET_FRAMES:\n",
    "            task_memory[\"laptop\"] = 0\n",
    "            detection_miss_counters[\"laptop\"] = 0\n",
    "\n",
    "    # -----------------------------\n",
    "    # PRIORITY LOGIC with acting detection\n",
    "    # -----------------------------\n",
    "    # PHONE\n",
    "    if task_memory[\"phone\"] >= CONFIRM_FRAMES:\n",
    "        if is_acting(\"phone\", avg_motion, avg_hand_motion):\n",
    "            # Do not start/continue timer when acting; show explicit label\n",
    "            return \"Acting\"\n",
    "        if update_activity_timer(\"phone\", True, frame):\n",
    "            return \"⚠ Time limit exceeded\"\n",
    "        return \"Using mobile phone\"\n",
    "    else:\n",
    "        update_activity_timer(\"phone\", False, None)\n",
    "\n",
    "    # CUP\n",
    "    if task_memory[\"cup\"] >= CONFIRM_FRAMES:\n",
    "        if is_acting(\"cup\", avg_motion, avg_hand_motion):\n",
    "            return \"Acting\"\n",
    "        if update_activity_timer(\"cup\", True, frame):\n",
    "            return \"⚠ Time limit exceeded\"\n",
    "        return \"Drinking\" if drinking else \"Holding cup\"\n",
    "    else:\n",
    "        update_activity_timer(\"cup\", False, None)\n",
    "\n",
    "    # BOOK\n",
    "    if task_memory[\"book\"] >= CONFIRM_FRAMES:\n",
    "        if is_acting(\"book\", avg_motion, avg_hand_motion):\n",
    "            return \"Acting\"\n",
    "        if update_activity_timer(\"book\", True, frame):\n",
    "            return \"⚠ Time limit exceeded\"\n",
    "        return \"Reading\" if reading_posture else \"Holding notebook\"\n",
    "    else:\n",
    "        update_activity_timer(\"book\", False, None)\n",
    "\n",
    "    # LAPTOP\n",
    "    if task_memory[\"laptop\"] >= CONFIRM_FRAMES:\n",
    "        if is_acting(\"laptop\", avg_motion, avg_hand_motion):\n",
    "            return \"Acting\"\n",
    "        if update_activity_timer(\"laptop\", True, frame):\n",
    "            return \"⚠ Time limit exceeded\"\n",
    "        return \"using Laptop\"\n",
    "    else:\n",
    "        update_activity_timer(\"laptop\", False, None)\n",
    "\n",
    "    return \"Idle\"\n",
    "\n",
    "# -----------------------------\n",
    "# Main loop\n",
    "# -----------------------------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process pose and hands\n",
    "    results_pose = pose.process(frame_rgb)\n",
    "    results_hands = hands.process(frame_rgb)\n",
    "\n",
    "    # Extract keypoints\n",
    "    kps = extract_keypoints(results_pose, results_hands, frame.shape)\n",
    "\n",
    "    # Draw skeleton mask\n",
    "    mask = np.zeros_like(frame)\n",
    "    mask = draw_pose_mask(mask, kps)\n",
    "\n",
    "    # Motion calculation (body-wide)\n",
    "    if prev_keypoints is not None:\n",
    "        # Only consider valid keypoints (non-zero)\n",
    "        valid = (kps[:,0] > 0) & (prev_keypoints[:,0] > 0)\n",
    "\n",
    "        if np.any(valid):\n",
    "            diff = np.linalg.norm(kps[valid] - prev_keypoints[valid], axis=1)\n",
    "            movement = np.mean(diff)\n",
    "        else:\n",
    "            movement = 0\n",
    "\n",
    "        movement_history.append(movement)\n",
    "\n",
    "    prev_keypoints = kps.copy()\n",
    "\n",
    "    if len(movement_history) > STATIC_FRAMES:\n",
    "        movement_history.pop(0)\n",
    "\n",
    "    avg_motion = np.mean(movement_history) if movement_history else 0\n",
    "\n",
    "    # -----------------------------\n",
    "    # Hand-specific motion\n",
    "    # -----------------------------\n",
    "    # left_hand_indices = 33..53, right_hand_indices = 54..74\n",
    "    if prev_keypoints is not None:\n",
    "        # compute per-keypoint movement for hands; filter zeros\n",
    "        left_idx = list(range(33, 54))\n",
    "        right_idx = list(range(54, 75))\n",
    "\n",
    "        # ensure prev_keypoints exists earlier than current (we copy above)\n",
    "        # here prev_keypoints is current frame's previous stored state, but we've already set prev_keypoints = kps.copy()\n",
    "        # so we need a separate previous variable; to avoid complicating, we compute hand motion using movement_history approach:\n",
    "        # We'll approximate hand motion from the most recent two stored frames in movement_history by recomputing using last two kps snapshots.\n",
    "        # Simpler: keep last_kps variable. Let's implement last_kps variable outside loop. (We'll add it dynamically.)\n",
    "\n",
    "        pass\n",
    "\n",
    "    # To compute hand motion robustly we need the previous keypoints from the prior frame.\n",
    "    # We'll implement last_kps to hold the previous frame's keypoints.\n",
    "    # (Define last_kps if not present.)\n",
    "    try:\n",
    "        last_kps\n",
    "    except NameError:\n",
    "        last_kps = None\n",
    "\n",
    "    # compute avg_hand_motion using last_kps (previous frame) and current kps\n",
    "    if last_kps is not None:\n",
    "        left_idx = list(range(33, 54))\n",
    "        right_idx = list(range(54, 75))\n",
    "\n",
    "        left_valid = (kps[left_idx,0] > 0) & (last_kps[left_idx,0] > 0)\n",
    "        right_valid = (kps[right_idx,0] > 0) & (last_kps[right_idx,0] > 0)\n",
    "\n",
    "        if np.any(left_valid):\n",
    "            left_motion = np.linalg.norm(kps[left_idx][left_valid] - last_kps[left_idx][left_valid], axis=1)\n",
    "            avg_left_hand_motion = np.mean(left_motion)\n",
    "        else:\n",
    "            avg_left_hand_motion = 0.0\n",
    "\n",
    "        if np.any(right_valid):\n",
    "            right_motion = np.linalg.norm(kps[right_idx][right_valid] - last_kps[right_idx][right_valid], axis=1)\n",
    "            avg_right_hand_motion = np.mean(right_motion)\n",
    "        else:\n",
    "            avg_right_hand_motion = 0.0\n",
    "\n",
    "        avg_hand_motion = (avg_left_hand_motion + avg_right_hand_motion) / 2.0\n",
    "    else:\n",
    "        avg_hand_motion = 0.0\n",
    "\n",
    "    # update last_kps for next iteration\n",
    "    last_kps = kps.copy()\n",
    "\n",
    "    # -----------------------------\n",
    "    # YOLO Object Detection\n",
    "    # -----------------------------\n",
    "    CONF_THRESH = 0.7\n",
    "    # include both cup and bottle class names\n",
    "    SELECTED_CLASSES = [\"cell phone\", \"laptop\"]\n",
    "    obj_results = object_model(frame)[0]\n",
    "    objects = {}\n",
    "    for box, cls, conf in zip(obj_results.boxes.xyxy, obj_results.boxes.cls, obj_results.boxes.conf):\n",
    "        clss = object_model.names[int(cls)]\n",
    "        conf = float(conf)\n",
    "\n",
    "        if conf < CONF_THRESH or clss not in SELECTED_CLASSES:\n",
    "            continue\n",
    "\n",
    "        label = clss\n",
    "        objects[label] = box.cpu().numpy()\n",
    "\n",
    "        # Draw detected objects\n",
    "        x1, y1, x2, y2 = box.cpu().numpy()\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255,0,0), 2)\n",
    "        cv2.putText(frame, label, (int(x1), int(y1)-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0,0), 2)\n",
    "\n",
    "    frame_global = frame.copy()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Detect task (pass motion metrics)\n",
    "    # -----------------------------\n",
    "    task = detect_task(objects, kps, avg_motion, avg_hand_motion, frame_global)\n",
    "\n",
    "    # If motion too low, mark as Not Working / Working only when Idle\n",
    "    if task == \"Idle\":\n",
    "        if avg_motion < MOTION_THRESHOLD:\n",
    "            task = \"Not Working\"\n",
    "        else:\n",
    "            task = \"Working\"\n",
    "\n",
    "    # Draw detailed status (you can also show avg motions for debugging)\n",
    "    status_text = f\"Task: {task}\"\n",
    "    debug_text = f\"BodyM: {avg_motion:.2f} HandM: {avg_hand_motion:.2f}\"\n",
    "    cv2.putText(frame, status_text, (30,50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,0),4)\n",
    "    # cv2.putText(frame, debug_text, (30,80), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255),2)\n",
    "\n",
    "    overlay = cv2.addWeighted(frame, 0.7, mask, 0.3, 0)\n",
    "    cv2.imshow(\"Task + Pose\", overlay)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "pose.close()\n",
    "hands.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
