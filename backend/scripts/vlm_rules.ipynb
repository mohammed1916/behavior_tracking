{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fade6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1432bf018541568c087d2796ccea8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         unknown\n",
      "Motion - Overall: 12.37, Work Area: 16.69, Hand Score: 14, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 6.10, Work Area: 6.77, Hand Score: 14, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 4.12, Work Area: 4.97, Hand Score: 14, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 15.02, Work Area: 20.01, Hand Score: 10, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 8.12, Work Area: 8.61, Hand Score: 17, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 8.86, Work Area: 12.42, Hand Score: 14, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 5.30, Work Area: 6.92, Hand Score: 18, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 4.11, Work Area: 4.91, Hand Score: 12, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.39, Work Area: 2.44, Hand Score: 0, Productive: True\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.89, Work Area: 3.14, Hand Score: 2, Productive: True\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.30, Work Area: 2.27, Hand Score: 0, Productive: True\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         unknown\n",
      "Motion - Overall: 12.83, Work Area: 16.88, Hand Score: 12, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         unknown\n",
      "Motion - Overall: 10.38, Work Area: 13.53, Hand Score: 18, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 3.11, Work Area: 3.53, Hand Score: 6, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.37, Work Area: 2.41, Hand Score: 1, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.29, Work Area: 2.31, Hand Score: 1, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.26, Work Area: 2.21, Hand Score: 0, Productive: True\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 4.02, Work Area: 4.91, Hand Score: 11, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.85, Work Area: 3.21, Hand Score: 2, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.17, Work Area: 2.08, Hand Score: 0, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.11, Work Area: 1.98, Hand Score: 0, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.67, Work Area: 2.87, Hand Score: 1, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.31, Work Area: 2.31, Hand Score: 0, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         unknown\n",
      "Motion - Overall: 5.80, Work Area: 7.24, Hand Score: 13, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         unknown\n",
      "Motion - Overall: 3.94, Work Area: 4.39, Hand Score: 9, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 20.94, Work Area: 28.60, Hand Score: 14, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 16.99, Work Area: 22.62, Hand Score: 18, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         unknown\n",
      "Motion - Overall: 11.68, Work Area: 13.71, Hand Score: 21, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         unknown\n",
      "Motion - Overall: 12.79, Work Area: 11.86, Hand Score: 15, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 16.81, Work Area: 18.06, Hand Score: 17, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 9.38, Work Area: 11.70, Hand Score: 16, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         unknown\n",
      "Motion - Overall: 9.37, Work Area: 9.85, Hand Score: 22, Productive: True\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 11.66, Work Area: 11.06, Hand Score: 14, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 3.66, Work Area: 4.04, Hand Score: 9, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 3.06, Work Area: 3.44, Hand Score: 2, Productive: True\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 4.08, Work Area: 4.97, Hand Score: 7, Productive: False\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 3.26, Work Area: 3.79, Hand Score: 2, Productive: True\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 3.12, Work Area: 3.62, Hand Score: 3, Productive: True\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.79, Work Area: 3.07, Hand Score: 4, Productive: True\n",
      "######################### you are an expert activity recognition model.\n",
      "\n",
      "        look only at the main person in the image. ignore all other people or objects.\n",
      "\n",
      "        classify their current action into exactly one label from the following:\n",
      "\n",
      "        1. assembling_drone → the person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
      "        2. idle → the person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
      "        3. using_phone → the person is clearly holding or interacting with a phone.\n",
      "        4. unknown → if the activity cannot be confidently identified.\n",
      "\n",
      "        rules:\n",
      "        - do not guess.\n",
      "        - only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
      "        - do not add any extra text, explanations, or repeats.\n",
      "        - end your answer with \"\"\n",
      "\n",
      "        answer:\n",
      "         idle\n",
      "Motion - Overall: 2.64, Work Area: 2.80, Hand Score: 3, Productive: True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 265\u001b[0m\n\u001b[0;32m    262\u001b[0m phone_missing_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from PIL import Image\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "# ------------------------------------------------------\n",
    "# Load Qwen2-VL 2B (CORRECT)\n",
    "# ------------------------------------------------------\n",
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").to(device)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Enhanced Motion Detection for Productive Work\n",
    "# ------------------------------------------------------\n",
    "prev_frame_gray = None\n",
    "motion_history = []\n",
    "MOTION_HISTORY_SIZE = 10\n",
    "\n",
    "def analyze_motion_pattern(frame_gray, prev_gray):\n",
    "    \"\"\"Enhanced motion analysis with region-based detection\"\"\"\n",
    "    h, w = frame_gray.shape\n",
    "    \n",
    "    # Calculate overall motion\n",
    "    diff = cv2.absdiff(frame_gray, prev_gray)\n",
    "    overall_motion = np.sum(diff) / (h * w)\n",
    "    \n",
    "    # Region-based motion analysis (work area detection)\n",
    "    # Bottom half = work area (hands, tools, desk)\n",
    "    # Top half = upper body (less relevant for work detection)\n",
    "    work_area = diff[h//2:, :]\n",
    "    upper_area = diff[:h//2, :]\n",
    "    \n",
    "    work_motion = np.sum(work_area) / work_area.size\n",
    "    upper_motion = np.sum(upper_area) / upper_area.size\n",
    "    \n",
    "    # Detect localized motion (small, precise movements = productive work)\n",
    "    # Apply threshold to get significant motion pixels\n",
    "    _, motion_mask = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours of motion regions\n",
    "    contours, _ = cv2.findContours(motion_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Analyze motion characteristics\n",
    "    num_motion_regions = len([c for c in contours if cv2.contourArea(c) > 50])\n",
    "    \n",
    "    # Hand-like motion detection (small to medium regions)\n",
    "    hand_motion_regions = [c for c in contours if 100 < cv2.contourArea(c) < 5000]\n",
    "    hand_motion_score = len(hand_motion_regions)\n",
    "    \n",
    "    return {\n",
    "        'overall': overall_motion,\n",
    "        'work_area': work_motion,\n",
    "        'upper_area': upper_motion,\n",
    "        'num_regions': num_motion_regions,\n",
    "        'hand_score': hand_motion_score,\n",
    "        'work_ratio': work_motion / (upper_motion + 0.1)  # Avoid division by zero\n",
    "    }\n",
    "\n",
    "def classify_motion_as_productive(motion_stats, motion_history):\n",
    "    \"\"\"Determine if motion pattern indicates productive work\"\"\"\n",
    "    \n",
    "    # Thresholds (tune these based on your environment)\n",
    "    WORK_MOTION_MIN = 2.0      # Minimum motion in work area\n",
    "    WORK_MOTION_MAX = 15.0     # Maximum (too much = not focused)\n",
    "    HAND_SCORE_MIN = 2         # Minimum hand-like motion regions\n",
    "    WORK_RATIO_MIN = 1.2       # Work area should have more motion than upper body\n",
    "    \n",
    "    # Add current stats to history\n",
    "    motion_history.append(motion_stats)\n",
    "    if len(motion_history) > MOTION_HISTORY_SIZE:\n",
    "        motion_history.pop(0)\n",
    "    \n",
    "    # Analyze recent motion pattern (smoothing)\n",
    "    if len(motion_history) >= 3:\n",
    "        avg_work_motion = np.mean([m['work_area'] for m in motion_history[-5:]])\n",
    "        avg_hand_score = np.mean([m['hand_score'] for m in motion_history[-5:]])\n",
    "        avg_work_ratio = np.mean([m['work_ratio'] for m in motion_history[-5:]])\n",
    "        consistency = np.std([m['work_area'] for m in motion_history[-5:]])\n",
    "        \n",
    "        # Productive work indicators:\n",
    "        # 1. Moderate, consistent motion in work area\n",
    "        # 2. Multiple small motion regions (hands working)\n",
    "        # 3. More motion in lower half than upper half\n",
    "        # 4. Consistent pattern (not erratic)\n",
    "        \n",
    "        is_productive = (\n",
    "            WORK_MOTION_MIN < avg_work_motion < WORK_MOTION_MAX and\n",
    "            avg_hand_score >= HAND_SCORE_MIN and\n",
    "            avg_work_ratio >= WORK_RATIO_MIN and\n",
    "            consistency < 5.0  # Consistent motion pattern\n",
    "        )\n",
    "        \n",
    "        return is_productive, avg_work_motion, avg_hand_score\n",
    "    \n",
    "    return False, 0, 0\n",
    "\n",
    "def classify_activity(frame):\n",
    "    global prev_frame_gray, motion_history\n",
    "\n",
    "    # Convert frame to PIL image\n",
    "    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    prompt = \"\"\"<|vision_start|><|image_pad|><|vision_end|>\n",
    "\n",
    "        You are an expert activity recognition model.\n",
    "\n",
    "        Look ONLY at the MAIN PERSON in the image. Ignore all other people or objects.\n",
    "\n",
    "        Classify their CURRENT ACTION into exactly ONE label from the following:\n",
    "\n",
    "        1. assembling_drone → The person is working with tools, touching a drone, handling drone parts, connecting wires, tightening screws, or performing assembly actions.\n",
    "        2. idle → The person is standing or sitting without doing any task, arms resting, not interacting with objects.\n",
    "        3. using_phone → The person is clearly holding or interacting with a phone.\n",
    "        4. unknown → If the activity cannot be confidently identified.\n",
    "\n",
    "        Rules:\n",
    "        - Do NOT guess.\n",
    "        - Only output exactly one label: assembling_drone, idle, using_phone, or unknown.\n",
    "        - Do not add any extra text, explanations, or repeats.\n",
    "        - End your answer with \"<|endoftext|>\"\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "\n",
    "    inputs = processor(text=prompt, images=img, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # output_ids = model.generate(**inputs, max_new_tokens=20)\n",
    "        output_ids = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=5,  # Only need \"assembling_drone\", \"idle\", \"using_phone\", or \"unknown\"\n",
    "            do_sample=False,   # Greedy decoding for consistency\n",
    "        )\n",
    "\n",
    "    raw_result = processor.decode(output_ids[0], skip_special_tokens=True).strip().lower()\n",
    "    print(\"#########################\", raw_result)\n",
    "\n",
    "    # last non-empty line\n",
    "    lines = [line.strip() for line in raw_result.splitlines() if line.strip()]\n",
    "    result = lines[-1] if lines else \"unknown\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # ENHANCED MOTION DETECTION\n",
    "    # ----------------------------\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    motion_stats = None\n",
    "    is_productive_motion = False\n",
    "    \n",
    "    if prev_frame_gray is not None:\n",
    "        motion_stats = analyze_motion_pattern(frame_gray, prev_frame_gray)\n",
    "        is_productive_motion, avg_work_motion, hand_score = classify_motion_as_productive(\n",
    "            motion_stats, motion_history\n",
    "        )\n",
    "        \n",
    "        print(f\"Motion - Overall: {motion_stats['overall']:.2f}, Work Area: {motion_stats['work_area']:.2f}, \"\n",
    "              f\"Hand Score: {motion_stats['hand_score']}, Productive: {is_productive_motion}\")\n",
    "    \n",
    "    prev_frame_gray = frame_gray\n",
    "\n",
    "    # ----------------------------\n",
    "    # FINAL DECISION LOGIC (Enhanced)\n",
    "    # ----------------------------\n",
    "    if \"phone\" in result:\n",
    "        return \"using_phone\"\n",
    "\n",
    "    if \"assemble\" in result or \"drone\" in result:\n",
    "        return \"assembling_drone\"\n",
    "    \n",
    "    # Enhanced decision making with motion analysis\n",
    "    if motion_stats:\n",
    "        # Strong productive motion pattern detected\n",
    "        if is_productive_motion:\n",
    "            if \"idle\" in result or \"unknown\" in result:\n",
    "                return \"assembling_drone\"  # Override VLM with motion evidence\n",
    "            return \"assembling_drone\"\n",
    "        \n",
    "        # Minimal motion detected\n",
    "        if motion_stats['overall'] < 2.0:\n",
    "            return \"idle\"\n",
    "        \n",
    "        # Medium motion but not productive pattern\n",
    "        if 2.0 <= motion_stats['overall'] < 8.0:\n",
    "            if \"idle\" in result:\n",
    "                return \"simply_sitting\"  # Some movement but not working\n",
    "            elif \"unknown\" in result:\n",
    "                return \"simply_sitting\"\n",
    "        \n",
    "        # High overall motion but not in work area (body movement)\n",
    "        if motion_stats['overall'] > 8.0 and motion_stats['work_ratio'] < 1.0:\n",
    "            return \"simply_sitting\"  # Moving but not working\n",
    "    \n",
    "    # Fallback to simple logic\n",
    "    if \"idle\" in result:\n",
    "        return \"idle\"\n",
    "    elif \"unknown\" in result:\n",
    "        return \"simply_sitting\"\n",
    "    else:\n",
    "        return \"idle\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Activity tracking + CSV logging setup\n",
    "# ------------------------------------------------------\n",
    "current_activity = \"unknown\"\n",
    "activity_start_time = time.time()\n",
    "\n",
    "log_data = []\n",
    "CSV_FILE = \"activity_log.csv\"\n",
    "\n",
    "IDLE_LIMIT = 10\n",
    "PHONE_LIMIT = 10\n",
    "drone_limit=20\n",
    "\n",
    "def log_activity(activity, start, end):\n",
    "    duration = round(end - start, 2)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    log_data.append([timestamp, activity, duration])\n",
    "\n",
    "    df = pd.DataFrame(log_data, columns=[\"timestamp\", \"activity\", \"duration_sec\"])\n",
    "    df.to_csv(CSV_FILE, index=False)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Real-time video stream\n",
    "# ------------------------------------------------------\n",
    "# cap = cv2.VideoCapture(\"drone.mp4\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "# Get video properties\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define VideoWriter for output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 'XVID' or 'mp4v'\n",
    "out = cv2.VideoWriter(\"data_collection_.mp4\", fourcc, 30.0, (width, height))\n",
    "\n",
    "prev_classify_time = time.time()\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "alert_message = \"\"\n",
    "\n",
    "PHONE_RESET_FRAMES = 5\n",
    "phone_missing_frames = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Run VLM once per second (important)\n",
    "    if current_time - prev_classify_time >= 1.0:\n",
    "        new_activity = classify_activity(frame)\n",
    "        prev_classify_time = current_time\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # PHONE TIMER RESET LOGIC\n",
    "        # ----------------------------------------------------\n",
    "        if current_activity == \"using_phone\":\n",
    "            if new_activity != \"using_phone\":\n",
    "                phone_missing_frames += 1\n",
    "            else:\n",
    "                phone_missing_frames = 0\n",
    "\n",
    "            # Reset only if phone is missing for enough frames\n",
    "            if phone_missing_frames >= PHONE_RESET_FRAMES:\n",
    "                log_activity(current_activity, activity_start_time, current_time)\n",
    "                current_activity = new_activity\n",
    "                activity_start_time = current_time\n",
    "                phone_missing_frames = 0\n",
    "\n",
    "        else:\n",
    "            # Normal activity change\n",
    "            if new_activity != current_activity:\n",
    "                log_activity(current_activity, activity_start_time, current_time)\n",
    "                current_activity = new_activity\n",
    "                activity_start_time = current_time\n",
    "                phone_missing_frames = 0\n",
    "\n",
    "\n",
    "    elapsed = current_time - activity_start_time\n",
    "    alert_message = \"\"\n",
    "\n",
    "    if current_activity == \"working\" and elapsed > IDLE_LIMIT:\n",
    "        alert_message = f\"pls assemble drone\"\n",
    "\n",
    "    if current_activity == \"simply_sitting\" and elapsed > IDLE_LIMIT:\n",
    "        alert_message = f\" simply_sitting for {int(elapsed)} sec\"\n",
    "\n",
    "    if current_activity == \"idle\" and elapsed > IDLE_LIMIT:\n",
    "        alert_message = f\"Idle for {int(elapsed)} sec\"\n",
    "\n",
    "    if current_activity == \"using_phone\" and elapsed > PHONE_LIMIT:\n",
    "        alert_message = f\"Phone usage for {int(elapsed)} sec\"\n",
    "\n",
    "    if current_activity == \"assembling_drone\" and elapsed > drone_limit:\n",
    "        alert_message = f\"drone usage limit exceeded\"\n",
    "\n",
    "    cv2.putText(frame, f\"Activity: {current_activity}\", (30, 40), font, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Time: {int(elapsed)} sec\", (30, 80), font, 1, (255, 255, 0), 2)\n",
    "\n",
    "    if alert_message:\n",
    "        cv2.putText(frame, alert_message, (30, 120), font, 1, (0, 255, 0), 4)\n",
    "\n",
    "    cv2.imshow(\"Drone Assembly Monitoring\", frame)\n",
    "    out.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "log_activity(current_activity, activity_start_time, time.time())\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1983c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save_pretrained(\"qwen_vlm_2b_activity_model\")\n",
    "# processor.save_pretrained(\"qwen_vlm_2b_activity_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
